{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZcTqGWH6JW9"
      },
      "source": [
        "0) Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Hj2eX-A6KOG",
        "outputId": "3e7103b9-b116-4392-eafb-4f36603b4dcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m260.1/260.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "dataproc-spark-connect 0.8.3 requires tqdm>=4.67, but you have tqdm 4.66.5 which is incompatible.\n",
            "firebase-admin 6.9.0 requires httpx[http2]==0.28.1, but you have httpx 0.26.0 which is incompatible.\n",
            "mcp 1.20.0 requires httpx>=0.27.1, but you have httpx 0.26.0 which is incompatible.\n",
            "google-genai 1.49.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.26.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mâœ… Deps installed.\n"
          ]
        }
      ],
      "source": [
        "# Use one pinned version to avoid mid-run upgrades\n",
        "!pip -q install --upgrade openai==1.53.0 requests moviepy==1.0.3 \\\n",
        "  numpy librosa==0.10.2.post1 soundfile==0.12.1 pillow==10.4.0 \\\n",
        "  tqdm==4.66.5 httpx==0.26.0 google-api-python-client google-auth \\\n",
        "  google-auth-oauthlib google-auth-httplib2\n",
        "!apt-get -y install -qq ffmpeg > /dev/null\n",
        "print(\"âœ… Deps installed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bP88qNw16h8e"
      },
      "source": [
        "1) Config & secrets (paste keys here)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcINonUq6iTc",
        "outputId": "d9c8968a-b1d6-4b2e-9441-161a2bd6d98e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Output: /content/shorts_run_20251111-183255\n"
          ]
        }
      ],
      "source": [
        "# @title 1) Config & Secrets\n",
        "import os, json, time, math, random, pathlib, re\n",
        "from pathlib import Path\n",
        "\n",
        "# ==== ðŸ”‘ PASTE KEYS HERE ====\n",
        "OPENAI_API_KEY  = \"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\"   # <-- TODO\n",
        "SUNO_API_KEY    = \"413d61e0196dac7de59956736545a8a0\" # <-- TODO (sunoapi.org)\n",
        "# ============================\n",
        "\n",
        "# Basic runtime params\n",
        "RUN_ID           = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "OUT              = Path(f\"/content/shorts_run_{RUN_ID}\"); OUT.mkdir(parents=True, exist_ok=True)\n",
        "VIDEO_W, VIDEO_H = 720, 1280\n",
        "FPS              = 30\n",
        "BG_IMAGES_N      = 2         # 1â€“3\n",
        "CAP_WORDS_MIN    = 3\n",
        "CAP_WORDS_MAX    = 5\n",
        "USE_AENEAS       = False     # optional heavy alignment\n",
        "SUNO_MODEL       = \"V5\"      # see docs for options\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "os.environ[\"SUNO_API_KEY\"]   = SUNO_API_KEY\n",
        "\n",
        "print(\"âœ… Output:\", OUT)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeLR682O8ESl"
      },
      "source": [
        "2) Helpers & OpenAI client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Tup9d1ov8Eol",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "742b4f70-ff93-46ef-fce8-94be1bfdfb28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/moviepy/config_defaults.py:47: SyntaxWarning: invalid escape sequence '\\P'\n",
            "  IMAGEMAGICK_BINARY = r\"C:\\Program Files\\ImageMagick-6.8.8-Q16\\magick.exe\"\n",
            "/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:294: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  lines_video = [l for l in lines if ' Video: ' in l and re.search('\\d+x\\d+', l)]\n",
            "/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:367: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  rotation_lines = [l for l in lines if 'rotate          :' in l and re.search('\\d+$', l)]\n",
            "/usr/local/lib/python3.12/dist-packages/moviepy/video/io/ffmpeg_reader.py:370: SyntaxWarning: invalid escape sequence '\\d'\n",
            "  match = re.search('\\d+$', rotation_line)\n",
            "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with 'str' literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title 2) Helpers & OpenAI client (fixed)\n",
        "import os\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path  # <-- missing import added\n",
        "from moviepy.editor import ImageClip, concatenate_videoclips, AudioFileClip\n",
        "import librosa, numpy as np, soundfile as sf\n",
        "\n",
        "# OpenAI v1 SDK: read key from env; don't pass api_key explicitly\n",
        "# Make sure OPENAI_API_KEY was set in your config cell.\n",
        "from openai import OpenAI\n",
        "\n",
        "def _assert_api_key():\n",
        "    if not os.getenv(\"OPENAI_API_KEY\"):\n",
        "        raise EnvironmentError(\n",
        "            \"OPENAI_API_KEY is not set. Paste your key in the config cell or do: os.environ['OPENAI_API_KEY']='sk-...'\"\n",
        "        )\n",
        "\n",
        "_assert_api_key()\n",
        "oai = OpenAI()  # <-- no api_key kwarg; avoids unexpected 'proxies' issue\n",
        "\n",
        "def save_bytes(url_or_bytes, out_path: Path):\n",
        "    out_path = Path(out_path)\n",
        "    if isinstance(url_or_bytes, (bytes, bytearray)):\n",
        "        out_path.write_bytes(url_or_bytes)\n",
        "        return out_path\n",
        "    r = requests.get(url_or_bytes, timeout=120)\n",
        "    r.raise_for_status()\n",
        "    out_path.write_bytes(r.content)\n",
        "    return out_path\n",
        "\n",
        "def audio_info(path: Path):\n",
        "    dur = float(librosa.get_duration(filename=str(path)))\n",
        "    y, sr = librosa.load(path, sr=None, mono=True)\n",
        "    return {\"duration\": dur, \"sr\": sr, \"path\": str(path)}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 2) Topic Generator: 10 matchup lines â†’ pick 1 â†’ TOPIC (place before Suno Block 3)\n",
        "import os, re, random, json\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from zoneinfo import ZoneInfo\n",
        "from openai import OpenAI, BadRequestError, AuthenticationError, RateLimitError\n",
        "\n",
        "# â”€â”€ Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "assert os.getenv(\"OPENAI_API_KEY\"), \"OPENAI_API_KEY not set\"\n",
        "oai = OpenAI()\n",
        "\n",
        "OUT = OUT if \"OUT\" in globals() else Path(\"/content/shorts_run\")\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Force a specific theme by setting one of these (leave None for auto daily rotation)\n",
        "FORCE_CATEGORY   = None   # e.g., \"anime\" | \"athletes\" | \"politics\" | \"gaming\" | \"fantasy\" | \"scifi\" | \"myth\"\n",
        "MANUAL_BRIEF     = None   # e.g., \"Give me matchups of European football legends with spicy tactical angles\"\n",
        "\n",
        "# Deterministic daily seed (Europe/Copenhagen) so each day you get a new set automatically\n",
        "dk_now = datetime.now(ZoneInfo(\"Europe/Copenhagen\"))\n",
        "DAILY_SEED = int(dk_now.strftime(\"%Y%m%d\"))\n",
        "random.seed(DAILY_SEED)\n",
        "\n",
        "# Theme pool (short briefs to hand the LLM). Extend freely.\n",
        "THEME_POOL = {\n",
        "    \"anime\":    \"Give me matchups of anime characters, mostly shonen, high-energy contrasts and iconic catchphrases.\",\n",
        "    \"athletes\": \"Give me matchups of famous athletes across different sports, focusing on rivalry, clutch moments, and legacy.\",\n",
        "    \"politics\": \"Give me matchups of political figures from different eras or ideologies, witty contrasts and policy jabs.\",\n",
        "    \"gaming\":   \"Give me matchups of gaming icons and esports personalities, highlight mechanics, metas, and signature plays.\",\n",
        "    \"fantasy\":  \"Give me matchups of fantasy heroes and villains, magic systems, artifacts, and epic duels.\",\n",
        "    \"scifi\":    \"Give me matchups of sci-fi protagonists and antagonists, tech, starfleets, AI ethics, and time loops.\",\n",
        "    \"myth\":     \"Give me matchups of mythological gods and heroes from different cultures, domains, symbols, and legends.\",\n",
        "}\n",
        "\n",
        "# Pick category & brief\n",
        "if MANUAL_BRIEF:\n",
        "    short_brief = MANUAL_BRIEF.strip()\n",
        "    picked_category = \"manual\"\n",
        "else:\n",
        "    cats = list(THEME_POOL.keys())\n",
        "    picked_category = FORCE_CATEGORY if FORCE_CATEGORY in cats else random.choice(cats)\n",
        "    short_brief = THEME_POOL[picked_category]\n",
        "\n",
        "print(f\"ðŸŽ¯ Topic category: {picked_category}\")\n",
        "print(f\"ðŸ§¾ Short brief: {short_brief}\\n\")\n",
        "\n",
        "# Your (tightened) system prompt â€” identical intent/format, with a couple guardrails for consistency\n",
        "SYSTEM_PROMPT = (\n",
        "    \"This GPT generates tightly formatted prompt packages for an AI song generator. \"\n",
        "    \"It takes a short brief (themes/genres/moods/figures) and outputs a structured list of 10 creative rap battle matchups, \"\n",
        "    \"in the spirit of 'Epic Rap Battles of History'. \"\n",
        "    \"Return exactly 10 bullets; each bullet is a SINGLE LINE string (no newlines inside). \"\n",
        "    \"Strict format: Title: [A vs B] | Context: [...] | Style A: [...] | Style B: [...] | Beat: [...] | Hook: [...] | \"\n",
        "    \"Angles: [...] | Prompt A: [...] | Prompt B: [...] | One-shot: [...]. \"\n",
        "    \"Each full line MUST be under 400 characters total. Compress aggressively; use short phrases, no full sentences. \"\n",
        "    \"No extra commentary, no code fences, no numberingâ€”just 10 bullet lines. \"\n",
        "    \"If needed, assume defaults for missing info and keep it creative and musical.\"\n",
        ")\n",
        "\n",
        "USER_PROMPT = short_brief\n",
        "\n",
        "def _normalize_one_line(s: str) -> str:\n",
        "    s = s.strip()\n",
        "    s = s.replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
        "    s = re.sub(r\"\\s{2,}\", \" \", s)\n",
        "    # Ensure starts with \"Title:\" to be parsable downstream\n",
        "    if not s.lower().startswith(\"title:\"):\n",
        "        s = re.sub(r\"^[â€¢\\-*\\d\\.\\)\\s]*\", \"\", s)\n",
        "    return s\n",
        "\n",
        "def _clip_400(s: str) -> str:\n",
        "    if len(s) <= 400:\n",
        "        return s\n",
        "    s = s[:400]\n",
        "    # avoid chopping mid-token ugly; trim to last separator if present\n",
        "    cut = max(s.rfind(\" | \"), s.rfind(\"] | \"), s.rfind(\"|\"))\n",
        "    if cut >= 300:  # only if we found a reasonable place near the end\n",
        "        s = s[:cut].rstrip()\n",
        "    return s\n",
        "\n",
        "def generate_matchups(brief: str, max_retries=2):\n",
        "    for attempt in range(1, max_retries+1):\n",
        "        try:\n",
        "            resp = oai.chat.completions.create(\n",
        "                model=\"gpt-4o-mini\",\n",
        "                temperature=0.9,\n",
        "                top_p=0.9,\n",
        "                max_tokens=1800,\n",
        "                messages=[\n",
        "                    {\"role\":\"system\",\"content\": SYSTEM_PROMPT},\n",
        "                    {\"role\":\"user\",  \"content\": brief},\n",
        "                ],\n",
        "            )\n",
        "            text = resp.choices[0].message.content.strip()\n",
        "            # Split into lines; keep only non-empty; normalize; clip\n",
        "            lines = [l for l in text.split(\"\\n\") if l.strip()]\n",
        "            # Remove any list bullets like \"-\" or numbering\n",
        "            lines = [re.sub(r\"^[â€¢\\-*\\d\\.\\)\\s]+\", \"\", l).strip() for l in lines]\n",
        "            # Only lines that start with Title:\n",
        "            lines = [l for l in lines if l.lower().startswith(\"title:\")]\n",
        "            # Normalize and clip length\n",
        "            lines = [_clip_400(_normalize_one_line(l)) for l in lines]\n",
        "            # Keep exactly 10 if possible\n",
        "            if len(lines) >= 10:\n",
        "                return lines[:10]\n",
        "            # If not enough lines, try to salvage by splitting on \"Title:\" occurrences in one line\n",
        "            if len(lines) < 10:\n",
        "                merged = \" \".join(lines)\n",
        "                parts = re.findall(r\"(Title:\\s*\\[[^\\]]+\\][^\\n]+?)(?=Title:|\\Z)\", merged, flags=re.IGNORECASE)\n",
        "                parts = [_clip_400(_normalize_one_line(p)) for p in parts if p.strip()]\n",
        "                if len(parts) >= 10:\n",
        "                    return parts[:10]\n",
        "            # If still short and we have retries left, try again\n",
        "            if attempt < max_retries:\n",
        "                continue\n",
        "            return lines  # may be <10; weâ€™ll handle gracefully\n",
        "        except (BadRequestError, AuthenticationError, RateLimitError) as e:\n",
        "            if attempt >= max_retries:\n",
        "                raise\n",
        "    return []\n",
        "\n",
        "MATCHUPS = generate_matchups(USER_PROMPT)\n",
        "if not MATCHUPS:\n",
        "    raise RuntimeError(\"LLM did not return any matchups. Try another brief or rerun.\")\n",
        "\n",
        "# Save all 10 for auditing\n",
        "(OUT / \"matchups.txt\").write_text(\"\\n\".join(MATCHUPS), encoding=\"utf-8\")\n",
        "\n",
        "# Pick 1 randomly (but deterministically per day)\n",
        "idx = random.randrange(len(MATCHUPS))\n",
        "TOPIC = MATCHUPS[idx]\n",
        "\n",
        "# Print a compact preview\n",
        "print(\"ðŸ“œ Generated matchups (first 3 shown):\")\n",
        "for i, line in enumerate(MATCHUPS[:3], 1):\n",
        "    print(f\"{i:02d}. {line}  ({len(line)} chars)\")\n",
        "print(f\"\\nðŸŽ² Selected index: {idx}  â†’  TOPIC (len {len(TOPIC)}):\\n{TOPIC}\")\n",
        "\n",
        "# Persist the chosen topic as well\n",
        "(OUT / \"topic.txt\").write_text(TOPIC, encoding=\"utf-8\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iTMONEJQ9Fs",
        "outputId": "cfa9ee3e-1422-4a13-9462-3e3baddc2669"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŽ¯ Topic category: myth\n",
            "ðŸ§¾ Short brief: Give me matchups of mythological gods and heroes from different cultures, domains, symbols, and legends.\n",
            "\n",
            "ðŸ“œ Generated matchups (first 3 shown):\n",
            "01. Title: Zeus vs Thor | Context: Greek vs Norse god of thunder | Style A: Epic, authoritative | Style B: Fierce, braggadocious | Beat: Heavy bass, orchestral | Hook: \"Lightning strikes, clash of titans!\" | Angles: Power, rivalry, legacy | Prompt A: \"King of Olympus, storm on high\" | Prompt B: \"MjÃ¶lnir's might, Asgard's pride\" | One-shot: \"Who reigns supreme in the skies?\"  (372 chars)\n",
            "02. Title: Anubis vs Hades | Context: Egyptian vs Greek god of the underworld | Style A: Mysterious, dark | Style B: Cunning, brooding | Beat: Sinister, haunting | Hook: \"Life and death, who holds the key?\" | Angles: Afterlife, judgment, fear | Prompt A: \"Guardian of souls, jackalâ€™s guise\" | Prompt B: \"Underworld king, with shadowed eyes\" | One-shot: \"Whose domain is the darkest?\"  (379 chars)\n",
            "03. Title: Athena vs Sun Wukong | Context: Greek goddess of wisdom vs Chinese monkey king | Style A: Strategic, eloquent | Style B: Playful, rebellious | Beat: Upbeat, energetic | Hook: \"Wisdom and mischief, clash of brains!\" | Angles: Intelligence, trickery, culture | Prompt A: \"Battle of the mind, wisdom's might\" | Prompt B: \"Chaos incarnate, ready to fight\" | One-shot: \"Who outsmarts who?\"  (391 chars)\n",
            "\n",
            "ðŸŽ² Selected index: 2  â†’  TOPIC (len 391):\n",
            "Title: Athena vs Sun Wukong | Context: Greek goddess of wisdom vs Chinese monkey king | Style A: Strategic, eloquent | Style B: Playful, rebellious | Beat: Upbeat, energetic | Hook: \"Wisdom and mischief, clash of brains!\" | Angles: Intelligence, trickery, culture | Prompt A: \"Battle of the mind, wisdom's might\" | Prompt B: \"Chaos incarnate, ready to fight\" | One-shot: \"Who outsmarts who?\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "391"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0lxSPng9aHF"
      },
      "source": [
        "3) Topic â†’ Suno generate + poll + download audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LuLomZs9aeu",
        "outputId": "34138a16-f710-49e9-9b5a-e75bd48a7344"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŽ¼ Suno task: 0cbb09a45f5f55cd7cfdfae710a175ae\n",
            "âœ… Downloaded: /content/shorts_run_20251111-183255/song.mp3 | Title: Athena vs Sun Wukong | AudioId: 108a4cbf-5564-4bdf-869a-e0eaf77584f1\n"
          ]
        }
      ],
      "source": [
        "# @title 3) Topic â†’ Suno generate + poll + download\n",
        "TOPIC = TOPIC\n",
        "\n",
        "SUNO_BASE = \"https://api.sunoapi.org/api/v1\"\n",
        "\n",
        "def suno_headers():\n",
        "    return {\n",
        "        \"Authorization\": f\"Bearer {os.environ['SUNO_API_KEY']}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "def suno_generate(prompt:str, model:str=\"V5\"):\n",
        "    # Non-custom mode: prompt only; API returns two songs per request\n",
        "    payload = {\n",
        "        \"customMode\": False,\n",
        "        \"instrumental\": False,\n",
        "        \"model\": model,\n",
        "        \"prompt\": prompt[:500],  # Non-custom prompt limit (docs)\n",
        "        # In docs, callBackUrl is listed; we poll instead. Many tenants accept omit.\n",
        "        # If your tenant requires it, set a dummy URL:\n",
        "        \"callBackUrl\": \"https://example.com/callback\"\n",
        "    }\n",
        "    r = requests.post(f\"{SUNO_BASE}/generate\", headers=suno_headers(), json=payload, timeout=60)\n",
        "    r.raise_for_status()\n",
        "    j = r.json()\n",
        "    if j.get(\"code\") != 200:\n",
        "        raise RuntimeError(f\"Suno generate error: {j}\")\n",
        "    return j[\"data\"][\"taskId\"]\n",
        "\n",
        "def suno_record_info(task_id:str):\n",
        "    r = requests.get(f\"{SUNO_BASE}/generate/record-info\", headers=suno_headers(), params={\"taskId\": task_id}, timeout=60)\n",
        "    r.raise_for_status()\n",
        "    return r.json()\n",
        "\n",
        "def wait_for_songs(task_id:str, timeout_s=360, poll_every=5):\n",
        "    import time\n",
        "    t0 = time.time()\n",
        "    status=\"PENDING\"\n",
        "    last=None\n",
        "    while time.time()-t0 < timeout_s:\n",
        "        last = suno_record_info(task_id)\n",
        "        data = last.get(\"data\", {})\n",
        "        status = data.get(\"status\")\n",
        "        if status in (\"SUCCESS\",\"FIRST_SUCCESS\"):\n",
        "            return last\n",
        "        time.sleep(poll_every)\n",
        "    raise TimeoutError(f\"Suno task timeout. Last status={status}, payload={last}\")\n",
        "\n",
        "task_id = suno_generate(TOPIC, SUNO_MODEL)\n",
        "print(\"ðŸŽ¼ Suno task:\", task_id)\n",
        "\n",
        "rec = wait_for_songs(task_id)\n",
        "suno_data = rec[\"data\"][\"response\"][\"sunoData\"]\n",
        "# Choose the first returned song by default (you can add UI later to pick)\n",
        "track = suno_data[0]\n",
        "AUDIO_URL = track[\"audioUrl\"]\n",
        "AUDIO_ID  = track[\"id\"]\n",
        "TITLE     = track.get(\"title\",\"Untitled\")\n",
        "DURATION  = track.get(\"duration\", None)\n",
        "\n",
        "audio_path = OUT/\"song.mp3\"\n",
        "save_bytes(AUDIO_URL, audio_path)\n",
        "print(\"âœ… Downloaded:\", audio_path, \"| Title:\", TITLE, \"| AudioId:\", AUDIO_ID)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PUhV85X_j2J"
      },
      "source": [
        "4) Try to fetch timestamped lyrics from Suno (best case)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkhJRBi7_kKb",
        "outputId": "be1b1f7c-8ce8-47a2-eed4-6a4afaaff846"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Using Suno aligned words: 145 tokens\n"
          ]
        }
      ],
      "source": [
        "# @title 4) Fetch Suno timestamped lyrics (best)\n",
        "def suno_aligned_words(task_id:str, audio_id:str):\n",
        "    r = requests.post(f\"{SUNO_BASE}/generate/get-timestamped-lyrics\",\n",
        "                      headers=suno_headers(),\n",
        "                      json={\"taskId\": task_id, \"audioId\": audio_id},\n",
        "                      timeout=60)\n",
        "    r.raise_for_status()\n",
        "    j = r.json()\n",
        "    if j.get(\"code\") == 200 and j.get(\"data\",{}).get(\"alignedWords\"):\n",
        "        return j[\"data\"][\"alignedWords\"]\n",
        "    return None\n",
        "\n",
        "aligned = suno_aligned_words(task_id, AUDIO_ID)\n",
        "if aligned:\n",
        "    # Normalize to our common WORDS schema\n",
        "    WORDS = [{\"w\": a[\"word\"].strip(), \"start\": float(a[\"startS\"]), \"end\": float(a[\"endS\"])}\n",
        "             for a in aligned if a.get(\"success\", True) and str(a.get(\"word\",\"\")).strip()]\n",
        "    print(f\"âœ… Using Suno aligned words: {len(WORDS)} tokens\")\n",
        "else:\n",
        "    print(\"âš ï¸ No aligned words returned. Will fall back to heuristics.\")\n",
        "    WORDS = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmrHuAGwAP9O"
      },
      "source": [
        "6) Group into 3â€“5 word caption bursts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mhb1lIEzAQNM",
        "outputId": "03708f1e-503f-4b6c-d956-f3c51dda1458"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŸ¨ Groups: 37 (first): [{'text': '[Verse 1]\\nAthena speaks in riddles', 'start': 4.46809, 'end': 7.89894}, {'text': 'sharp as swords A', 'start': 7.99468, 'end': 9.9734}, {'text': 'labyrinth of thoughts no', 'start': 10.09309, 'end': 11.96809}]\n"
          ]
        }
      ],
      "source": [
        "# @title 6) Group words into 3â€“5 word bursts\n",
        "import random, json\n",
        "\n",
        "def group_words(words, min_k=3, max_k=5, max_gap=0.15):\n",
        "    groups=[]; i=0; n=len(words)\n",
        "    while i < n:\n",
        "        k = random.randint(min_k, max_k)\n",
        "        j = min(i+k, n)\n",
        "        # if a big gap is about to cross, shrink group\n",
        "        while j-1 > i and j < n and (words[j][\"start\"] - words[j-1][\"end\"]) > max_gap:\n",
        "            j -= 1\n",
        "        chunk = words[i:j]\n",
        "        txt = \" \".join(w[\"w\"] for w in chunk)\n",
        "        start, end = chunk[0][\"start\"], chunk[-1][\"end\"]\n",
        "        groups.append({\"text\": txt, \"start\": start, \"end\": end})\n",
        "        i = j\n",
        "    return groups\n",
        "\n",
        "GROUPS = group_words(WORDS, CAP_WORDS_MIN, CAP_WORDS_MAX) if WORDS else []\n",
        "(Path(OUT/\"groups.json\")).write_text(json.dumps(GROUPS, indent=2))\n",
        "print(f\"ðŸŸ¨ Groups: {len(GROUPS)} (first):\", GROUPS[:3])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T43KwkIoAXn-"
      },
      "source": [
        "7) Background images with OpenAI Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADsMZI6AAYDt",
        "outputId": "52d12fc5-9c92-4655-ac59-1e7a6b5a9807"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… OpenAI image 1 saved: /content/shorts_run_20251111-183255/bg_1.png\n",
            "ðŸ–¼ï¸ Background image: [PosixPath('/content/shorts_run_20251111-183255/bg_1.png')]\n"
          ]
        }
      ],
      "source": [
        "# @title 7) Topic-true person-in-action image (1 image only; OpenAI-only)\n",
        "import os, re, base64, requests\n",
        "from pathlib import Path\n",
        "from openai import OpenAI, PermissionDeniedError, BadRequestError, AuthenticationError, RateLimitError\n",
        "\n",
        "assert os.getenv(\"OPENAI_API_KEY\"), \"OPENAI_API_KEY not set\"\n",
        "oai = OpenAI()\n",
        "\n",
        "IMG_MODEL   = \"gpt-image-1\"\n",
        "\n",
        "# âœ… Only one background image per run to save cost\n",
        "BG_IMAGES_N = 1\n",
        "\n",
        "TITLE       = \"Untitled\" if \"TITLE\" not in globals() else TITLE\n",
        "TOPIC       = TOPIC if \"TOPIC\" in globals() else \"theme: gamer clutch moment in esports arena\"\n",
        "\n",
        "def _clean_topic(s: str) -> str:\n",
        "    s = re.sub(r\"\\[[^\\]]+\\]\", \" \", s)                        # [Verse], [Chorus]\n",
        "    s = re.sub(r'\"[^\"]+\"', \" \", s)                           # quoted lyrics\n",
        "    s = re.sub(r\"\\b(in the style of|sounds like|like|by|feat\\.?|featuring)\\b.*\", \" \", s, flags=re.I)\n",
        "    return re.sub(r\"\\s{2,}\", \" \", s).strip()\n",
        "\n",
        "def _extract_bytes(resp):\n",
        "    try:\n",
        "        d0 = resp.data[0]\n",
        "        if getattr(d0, \"b64_json\", None):\n",
        "            return base64.b64decode(d0.b64_json)\n",
        "        if getattr(d0, \"url\", None):\n",
        "            return requests.get(d0.url, timeout=60).content\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        j = resp.model_dump(mode=\"json\")\n",
        "        cand = j.get(\"data\", [{}])[0]\n",
        "        if \"b64_json\" in cand and cand[\"b64_json\"]:\n",
        "            return base64.b64decode(cand[\"b64_json\"])\n",
        "        if \"url\" in cand and cand[\"url\"]:\n",
        "            return requests.get(cand[\"url\"], timeout=60).content\n",
        "    except Exception:\n",
        "        pass\n",
        "    raise ValueError(\"No image bytes found in response\")\n",
        "\n",
        "def build_prompt(topic_text: str, title_text: str):\n",
        "    t = _clean_topic(topic_text)\n",
        "    title_snip = re.sub(r\"[\\r\\n]+\",\" \", str(title_text))[:60]\n",
        "    return (\n",
        "        \"Vertical 9:16 2 photo-realistic characters for a short music video in an epic setting. \"\n",
        "        \"Depict 2 engaging person characters **in singing-music battle, with microphones singing at eachother fiercely** The 2 people battling are described at the beginning of this text here: \"\n",
        "        f\"{t}. \"\n",
        "        \"No logos or copyright risky things.\"\n",
        "    )\n",
        "\n",
        "BG_PATHS = []\n",
        "for i in range(BG_IMAGES_N):\n",
        "    prompt = build_prompt(TOPIC, TITLE)\n",
        "    try:\n",
        "        resp = oai.images.generate(\n",
        "            model=IMG_MODEL,\n",
        "            prompt=prompt,\n",
        "            size=\"1024x1536\",\n",
        "            n=1,              # â† still request only one image from the API\n",
        "            quality=\"medium\",   # or \"medium\" to reduce cost further\n",
        "        )\n",
        "        img_bytes = _extract_bytes(resp)\n",
        "        out = OUT / f\"bg_{i+1}.png\"\n",
        "        out.write_bytes(img_bytes)\n",
        "        BG_PATHS.append(out)\n",
        "        print(f\"âœ… OpenAI image {i+1} saved:\", out)\n",
        "        try:\n",
        "            rp = resp.model_dump(mode=\"json\")[\"data\"][0].get(\"revised_prompt\")\n",
        "            if rp: print(\"   â†³ revised_prompt:\", rp[:140], \"â€¦\")\n",
        "        except Exception:\n",
        "            pass\n",
        "    except PermissionDeniedError:\n",
        "        print(\"âŒ Permission denied â€” Images access not available for this org.\")\n",
        "        raise\n",
        "    except BadRequestError as e:\n",
        "        print(\"âŒ Bad request from Images API. Prompt used:\\n\", prompt)\n",
        "        raise\n",
        "    except AuthenticationError:\n",
        "        print(\"âŒ Invalid OpenAI API key.\")\n",
        "        raise\n",
        "    except RateLimitError:\n",
        "        print(\"âŒ Rate limited; try again later.\")\n",
        "        raise\n",
        "    except Exception as e:\n",
        "        print(\"âŒ Unexpected error:\", e)\n",
        "        raise\n",
        "\n",
        "print(\"ðŸ–¼ï¸ Background image:\", BG_PATHS)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leBiZ9e_zV5M",
        "outputId": "6154ab7b-6e8a-4f5b-dfb8-0cebebeed391"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/tmp/ipython-input-1574833288.py:33: FutureWarning: get_duration() keyword argument 'filename' has been renamed to 'path' in version 0.10.0.\n",
            "\tThis alias will be removed in version 1.0.\n",
            "  dur = float(librosa.get_duration(filename=str(path)))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Building video /content/shorts_run_20251111-183255/bg.mp4.\n",
            "Moviepy - Writing video /content/shorts_run_20251111-183255/bg.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /content/shorts_run_20251111-183255/bg.mp4\n",
            "ðŸŽ¬ BG: /content/shorts_run_20251111-183255/bg.mp4\n"
          ]
        }
      ],
      "source": [
        "# @title 8) Build background video\n",
        "from moviepy.editor import CompositeVideoClip\n",
        "\n",
        "def build_bg_video(image_paths, duration_s, w=VIDEO_W, h=VIDEO_H, fps=FPS, crossfade=0.2):\n",
        "    per = max(2.0, duration_s/ max(1,len(image_paths)))\n",
        "    clips=[ImageClip(str(p)).resize((w,h)).set_duration(per) for p in image_paths]\n",
        "    clip = concatenate_videoclips(clips, method=\"compose\", padding=-crossfade)\n",
        "    # Repeat to cover duration\n",
        "    reps = math.ceil(duration_s/clip.duration)\n",
        "    clip = concatenate_videoclips([clip]*reps, method=\"compose\").subclip(0, duration_s)\n",
        "    out = OUT/\"bg.mp4\"\n",
        "    clip.write_videofile(str(out), fps=fps, codec=\"libx264\",\n",
        "                         audio=False, bitrate=\"3000k\",\n",
        "                         threads=2, preset=\"veryfast\")\n",
        "    clip.close()\n",
        "    return out\n",
        "\n",
        "aud_dur = audio_info(audio_path)[\"duration\"]\n",
        "BG_MP4 = build_bg_video(BG_PATHS, duration_s=aud_dur)\n",
        "print(\"ðŸŽ¬ BG:\", BG_MP4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fskf8ZNdzXVj",
        "outputId": "2a43c085-a10d-45f8-b5e7-c8e02877eb3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/tmp/ipython-input-2629041258.py:51: FutureWarning: get_duration() keyword argument 'filename' has been renamed to 'path' in version 0.10.0.\n",
            "\tThis alias will be removed in version 1.0.\n",
            "  aud_dur = float(librosa.get_duration(filename=str(audio_path)))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ Wrote ASS: /content/shorts_run_20251111-183255/subs.ass\n",
            "[Script Info]\n",
            "ScriptType: v4.00+\n",
            "PlayResX: 720\n",
            "PlayResY: 1280\n",
            "\n",
            "[V4+ Styles]\n",
            "Format: Name,Fontname,Fontsize,PrimaryColour,SecondaryColour,OutlineColour,BackColour,Bold,Italic,Underline,StrikeOut,ScaleX,ScaleY,Spacing,Angle,BorderStyle,Outline,Shadow,Alignment,MarginL,MarginR,MarginV,Encoding\n",
            "Style: Cap,DejaVu Sans,56,&H00FFFFFF,&H000000FF,&HAA000000,&H32000000,-1,0,0,0,100,100,0,0,1,4,0,2,30,30,70,1\n",
            "\n",
            "[Events]\n",
            "Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\n",
            "\n",
            "Dialogue: 0,0:00:04.47,0:00:07.90,Cap,,0,0,0,,{\\an2}[Verse 1] Athena speaks in riddles\n",
            "Dialogue: 0,0:00:07.99,0:00:09.97,Cap,,0,0,0,,{\\an2}sharp as swords A\n",
            "Dialogue: 0,0:00:10.09,0:00:11.97,Cap,,0,0,0,,{\\an2}labyrinth of thoughts no\n"
          ]
        }
      ],
      "source": [
        "# @title 9) Write ASS subtitles (fixed: dot decimals, validator)\n",
        "from pathlib import Path\n",
        "import math, json\n",
        "\n",
        "ASS_PATH = OUT / \"subs.ass\"\n",
        "\n",
        "def ass_time(t: float) -> str:\n",
        "    # ASS expects H:MM:SS.CS (centiseconds) with dot as decimal separator\n",
        "    if t < 0: t = 0.0\n",
        "    # limit to two decimals safely without rolling to 60.00\n",
        "    cs = int(round((t - math.floor(t)) * 100))\n",
        "    sec = int(t) % 60\n",
        "    m = (int(t) // 60) % 60\n",
        "    h = int(t) // 3600\n",
        "    # guard occasional 59.995â†’60.00 rounding\n",
        "    if cs == 100:\n",
        "        cs = 0\n",
        "        sec += 1\n",
        "        if sec == 60:\n",
        "            sec = 0\n",
        "            m += 1\n",
        "            if m == 60:\n",
        "                m = 0\n",
        "                h += 1\n",
        "    return f\"{h}:{m:02d}:{sec:02d}.{cs:02d}\"\n",
        "\n",
        "ASS_HEADER = f\"\"\"[Script Info]\n",
        "ScriptType: v4.00+\n",
        "PlayResX: {VIDEO_W}\n",
        "PlayResY: {VIDEO_H}\n",
        "\n",
        "[V4+ Styles]\n",
        "Format: Name,Fontname,Fontsize,PrimaryColour,SecondaryColour,OutlineColour,BackColour,Bold,Italic,Underline,StrikeOut,ScaleX,ScaleY,Spacing,Angle,BorderStyle,Outline,Shadow,Alignment,MarginL,MarginR,MarginV,Encoding\n",
        "Style: Cap,DejaVu Sans,56,&H00FFFFFF,&H000000FF,&HAA000000,&H32000000,-1,0,0,0,100,100,0,0,1,4,0,2,30,30,70,1\n",
        "\n",
        "[Events]\n",
        "Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\n",
        "\"\"\"\n",
        "\n",
        "def write_ass(groups):\n",
        "    lines = [ASS_HEADER]\n",
        "    for g in groups:\n",
        "        start = ass_time(float(g[\"start\"]))\n",
        "        end   = ass_time(float(g[\"end\"]))\n",
        "        txt   = str(g[\"text\"]).replace(\"\\n\", \" \").strip()\n",
        "        # Put all commas BEFORE text field; text is the last field so commas in txt are fine\n",
        "        lines.append(f\"Dialogue: 0,{start},{end},Cap,,0,0,0,,{{\\\\an2}}{txt}\")\n",
        "    ASS_PATH.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
        "\n",
        "# Optional: clamp last cue to audio duration (prevents running past EOF)\n",
        "aud_dur = float(librosa.get_duration(filename=str(audio_path)))\n",
        "SAFE_EPS = 0.02\n",
        "for g in GROUPS:\n",
        "    g[\"start\"] = max(0.0, min(g[\"start\"], aud_dur - SAFE_EPS))\n",
        "    g[\"end\"]   = max(0.0, min(g[\"end\"],   aud_dur - 0.0))\n",
        "\n",
        "# Ensure monotonic cues (no negative or reversed intervals)\n",
        "GROUPS = [g for g in GROUPS if g[\"end\"] > g[\"start\"] + 0.01]\n",
        "\n",
        "write_ass(GROUPS)\n",
        "print(\"ðŸ“ Wrote ASS:\", ASS_PATH)\n",
        "\n",
        "# Quick validator: print first 3 dialogue lines\n",
        "print(\"\\n\".join(ASS_PATH.read_text().splitlines()[:15]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3kjGtp4zYrR",
        "outputId": "a74b1d03-0867-4c1d-bd48-0ced0b1067c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ffmpeg -y -i \"/content/shorts_run_20251111-183255/bg.mp4\" -i \"/content/shorts_run_20251111-183255/song.mp3\"   -vf \"ass='/content/shorts_run_20251111-183255/subs.ass',scale=720:1280\"   -r 30 -c:v libx264 -preset veryfast -profile:v high -pix_fmt yuv420p   -c:a aac -b:a 192k -shortest \"/content/shorts_run_20251111-183255/shorts_final.mp4\"\n",
            "\n",
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/shorts_run_20251111-183255/bg.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2avc1mp41\n",
            "    encoder         : Lavf61.1.100\n",
            "  Duration: 00:01:58.70, start: 0.000000, bitrate: 933 kb/s\n",
            "  Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 720x1280, 930 kb/s, 30 fps, 30 tbr, 15360 tbn, 60 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "      vendor_id       : [0][0][0][0]\n",
            "      encoder         : Lavc61.3.100 libx264\n",
            "Input #1, mp3, from '/content/shorts_run_20251111-183255/song.mp3':\n",
            "  Metadata:\n",
            "    encoder         : Lavf60.16.100\n",
            "  Duration: 00:01:58.70, start: 0.023021, bitrate: 179 kb/s\n",
            "  Stream #1:0: Audio: mp3, 48000 Hz, stereo, fltp, 179 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc60.31\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (h264 (native) -> h264 (libx264))\n",
            "  Stream #1:0 -> #0:1 (mp3 (mp3float) -> aac (native))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;32m[Parsed_ass_0 @ 0x585fd977fc80] \u001b[0mlibass API version: 0x1502000\n",
            "\u001b[1;32m[Parsed_ass_0 @ 0x585fd977fc80] \u001b[0mlibass source: tarball: 0.15.2\n",
            "\u001b[1;32m[Parsed_ass_0 @ 0x585fd977fc80] \u001b[0mShaper: FriBidi 1.0.8 (SIMPLE) HarfBuzz-ng 2.7.4 (COMPLEX)\n",
            "\u001b[1;32m[Parsed_ass_0 @ 0x585fd977fc80] \u001b[0mUsing font provider fontconfig\n",
            "\u001b[1;32m[Parsed_ass_0 @ 0x585fd977fc80] \u001b[0mAdded subtitle file: '/content/shorts_run_20251111-183255/subs.ass' (2 styles, 37 events)\n",
            "\u001b[1;36m[libx264 @ 0x585fd973d440] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
            "\u001b[1;36m[libx264 @ 0x585fd973d440] \u001b[0mprofile High, level 3.1, 4:2:0, 8-bit\n",
            "\u001b[1;36m[libx264 @ 0x585fd973d440] \u001b[0m264 - core 163 r3060 5db6aa6 - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=1 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=2 psy=1 psy_rd=1.00:0.00 mixed_ref=0 me_range=16 chroma_me=1 trellis=0 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=0 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=1 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=10 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to '/content/shorts_run_20251111-183255/shorts_final.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2avc1mp41\n",
            "    encoder         : Lavf58.76.100\n",
            "  Stream #0:0(und): Video: h264 (avc1 / 0x31637661), yuv420p(progressive), 720x1280, q=2-31, 30 fps, 15360 tbn (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "      vendor_id       : [0][0][0][0]\n",
            "      encoder         : Lavc58.134.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
            "  Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 192 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 aac\n",
            "\u001b[1;32m[Parsed_ass_0 @ 0x585fd977fc80] \u001b[0mfontselect: (DejaVu Sans, 700, 0) -> /usr/share/fonts/truetype/humor-sans/Humor-Sans.ttf, 0, HumorSans\n",
            "frame= 3561 fps= 85 q=-1.0 Lsize=    5207kB time=00:01:58.67 bitrate= 359.4kbits/s speed=2.84x    \n",
            "video:2279kB audio:2799kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 2.542799%\n",
            "\u001b[1;36m[libx264 @ 0x585fd973d440] \u001b[0mframe I:15    Avg QP:19.15  size:124738\n",
            "\u001b[1;36m[libx264 @ 0x585fd973d440] \u001b[0mframe P:907   Avg QP:17.82  size:   390\n",
            "\u001b[1;36m[libx264 @ 0x585fd973d440] \u001b[0mframe B:2639  Avg QP:28.31  size:    41\n",
            "\u001b[1;36m[libx264 @ 0x585fd973d440] \u001b[0mconsecutive B-frames:  0.8%  1.2%  0.1% 98.0%\n",
            "\u001b[1;36m[libx264 @ 0x585fd973d440] \u001b[0mmb I  I16..4:  2.6% 28.3% 69.0%\n",
            "\u001b[1;36m[libx264 @ 0x585fd973d440] \u001b[0mmb P  I16..4:  0.0%  0.1%  0.1%  P16..4:  0.9%  0.0%  0.0%  0.0%  0.0%    skip:98.8%\n",
            "\u001b[1;36m[libx264 @ 0x585fd973d440] \u001b[0mmb B  I16..4:  0.0%  0.0%  0.0%  B16..8:  0.1%  0.0%  0.0%  direct: 0.0%  skip:99.9%  L0:44.1% L1:55.5% BI: 0.4%\n",
            "\u001b[1;36m[libx264 @ 0x585fd973d440] \u001b[0m8x8 transform intra:29.7% inter:17.0%\n",
            "\u001b[1;36m[libx264 @ 0x585fd973d440] \u001b[0mcoded y,uvDC,uvAC intra: 94.0% 87.3% 64.8% inter: 0.0% 0.2% 0.0%\n",
            "\u001b[1;36m[libx264 @ 0x585fd973d440] \u001b[0mi16 v,h,dc,p: 17% 18% 16% 49%\n",
            "\u001b[1;36m[libx264 @ 0x585fd973d440] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 22% 24% 10%  8%  6%  7%  7%  9%  8%\n",
            "\u001b[1;36m[libx264 @ 0x585fd973d440] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 20% 14% 10% 10%  9% 10%  8% 11%  9%\n",
            "\u001b[1;36m[libx264 @ 0x585fd973d440] \u001b[0mi8c dc,h,v,p: 40% 20% 24% 16%\n",
            "\u001b[1;36m[libx264 @ 0x585fd973d440] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n",
            "\u001b[1;36m[libx264 @ 0x585fd973d440] \u001b[0mkb/s:157.23\n",
            "\u001b[1;36m[aac @ 0x585fd976ac40] \u001b[0mQavg: 206.926\n",
            "âœ… Final: /content/shorts_run_20251111-183255/shorts_final.mp4\n"
          ]
        }
      ],
      "source": [
        "# @title 10) Render final Shorts MP4 (re-run after fixed ASS)\n",
        "FINAL_MP4 = OUT / \"shorts_final.mp4\"\n",
        "cmd = f\"\"\"\n",
        "ffmpeg -y -i \"{BG_MP4}\" -i \"{audio_path}\" \\\n",
        "  -vf \"ass='{ASS_PATH.as_posix()}',scale={VIDEO_W}:{VIDEO_H}\" \\\n",
        "  -r {FPS} -c:v libx264 -preset veryfast -profile:v high -pix_fmt yuv420p \\\n",
        "  -c:a aac -b:a 192k -shortest \"{FINAL_MP4}\"\n",
        "\"\"\"\n",
        "print(cmd)\n",
        "!bash -lc \"$cmd\"\n",
        "print(\"âœ… Final:\", FINAL_MP4)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 0) Install YouTube libraries\n",
        "!pip -q install --upgrade google-api-python-client google-auth google-auth-oauthlib google-auth-httplib2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62YKoBLrXHCA",
        "outputId": "1e789ead-3219-4fa6-db6e-8005e625df13"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m221.3/221.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.41.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "dataproc-spark-connect 0.8.3 requires tqdm>=4.67, but you have tqdm 4.66.5 which is incompatible.\n",
            "firebase-admin 6.9.0 requires httpx[http2]==0.28.1, but you have httpx 0.26.0 which is incompatible.\n",
            "google-genai 1.49.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.26.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1) YouTube secrets â†’ local files (CLIENT_SECRETS_JSON + TOKEN2_JSON)\n",
        "import os, base64, pathlib, json\n",
        "\n",
        "def _decode_and_validate(secret_name: str, out_file: str):\n",
        "    \"\"\"Decode Base64 GitHub secret and validate JSON structure.\"\"\"\n",
        "    try:\n",
        "        decoded = base64.b64decode(os.environ[secret_name]).decode('utf-8')\n",
        "        data = json.loads(decoded)\n",
        "\n",
        "        # Validate token.json structure\n",
        "        if out_file == \"token.json\":\n",
        "            required = {'token', 'refresh_token', 'scopes'}\n",
        "            if not required.issubset(data.keys()):\n",
        "                missing = required - set(data.keys())\n",
        "                raise ValueError(f\"Missing required fields in token: {missing}\")\n",
        "\n",
        "        pathlib.Path(out_file).write_text(decoded, encoding=\"utf-8\")\n",
        "        print(f\"âœ… {secret_name} â†’ {out_file}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error processing {secret_name}: {e}\")\n",
        "        raise\n",
        "\n",
        "try:\n",
        "    _decode_and_validate(\"CLIENT_SECRETS_JSON\", \"client_secrets.json\")\n",
        "    _decode_and_validate(\"TOKEN2_JSON\", \"token.json\")\n",
        "except Exception:\n",
        "    print(\"âŒ Failed to initialize YouTube secrets\")\n",
        "    raise\n",
        "\n",
        "print(\"âœ… YouTube auth secrets decoded and validated.\")\n"
      ],
      "metadata": {
        "id": "_afdV6sRXFLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 2) Build YouTube client (upload scope)\n",
        "from google.oauth2.credentials import Credentials\n",
        "from google.auth.transport.requests import Request\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "import json\n",
        "\n",
        "SCOPE = \"https://www.googleapis.com/auth/youtube.upload\"\n",
        "\n",
        "def get_authenticated_service():\n",
        "    try:\n",
        "        with open(\"token.json\") as f:\n",
        "            token_data = json.load(f)\n",
        "\n",
        "        if 'scopes' not in token_data or SCOPE not in token_data['scopes']:\n",
        "            raise ValueError(f\"Token missing required scope: {SCOPE}\")\n",
        "\n",
        "        creds = Credentials.from_authorized_user_info(token_data, [SCOPE])\n",
        "\n",
        "        if creds and creds.expired and creds.refresh_token:\n",
        "            try:\n",
        "                creds.refresh(Request())\n",
        "                with open(\"token.json\", \"w\") as f:\n",
        "                    json.dump(json.loads(creds.to_json()), f)\n",
        "            except Exception as refresh_error:\n",
        "                print(f\"âš ï¸ Token refresh failed: {refresh_error}\")\n",
        "                if not creds.token:\n",
        "                    raise\n",
        "\n",
        "        return build(\"youtube\", \"v3\", credentials=creds)\n",
        "    except HttpError as e:\n",
        "        print(f\"âŒ YouTube API error: {e}\")\n",
        "        raise\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Authentication failed: {e}\")\n",
        "        raise\n",
        "\n",
        "youtube = get_authenticated_service()\n",
        "print(f\"âœ… YouTube API authenticated with scope: {SCOPE}\")\n"
      ],
      "metadata": {
        "id": "dFjwNOSQXUq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3) Generate metadata (Title/Description/Tags) from TOPIC + Suno TITLE\n",
        "import json, re\n",
        "from openai import OpenAI, BadRequestError, AuthenticationError, RateLimitError\n",
        "\n",
        "# Inputs expected from your pipeline:\n",
        "#  - TOPIC (matchup line from your topic generator)\n",
        "#  - TITLE (from Suno; optional)\n",
        "#  - OUT (run folder path)\n",
        "\n",
        "TITLE = TITLE if \"TITLE\" in globals() and TITLE else \"Rap Battle Shorts\"\n",
        "topic_text = TOPIC if \"TOPIC\" in globals() else \"Title: [A vs B] | Context: ...\"\n",
        "\n",
        "oai = OpenAI()  # reads OPENAI_API_KEY from env\n",
        "\n",
        "SYS = \"You are an expert YouTube Shorts music marketer. Output concise, high-converting metadata.\"\n",
        "USR = f\"\"\"\n",
        "Create metadata for a vertical YouTube Shorts rap-battle style music video.\n",
        "\n",
        "Constraints:\n",
        "- Title: max 85 chars; punchy, curiosity, includes the matchup; no punctuation spam.\n",
        "- Description: <3500 chars. Start with a keyphrase. 1â€“2 sentence hook. Include CTA (Like/Comment/Subscribe).\n",
        "  End with a question. Then add 15â€“25 relevant hashtags (music/shorts/theme).\n",
        "- Tags: 25â€“30 items, comma-separated. Mix keywords: characters, genre, mood, \"rap battle\", \"music\", \"ai music\",\n",
        "  language, #shorts. Each tag <=25 chars.\n",
        "\n",
        "Context:\n",
        "- Suno Title: {TITLE}\n",
        "- Prompt line: {topic_text}\n",
        "\n",
        "Return JSON ONLY with keys: title, description, tags (array).\n",
        "\"\"\"\n",
        "\n",
        "def _heuristic_fallback(topic_text: str):\n",
        "    m = re.search(r\"\\[(.+?)\\]\", topic_text)\n",
        "    duo = m.group(1) if m else \"Epic Matchup\"\n",
        "    title = f\"{duo} â€” Rap Battle (AI Music) #shorts\"\n",
        "    description = (\n",
        "        f\"{duo} â€¢ AI music rap battle.\\n\"\n",
        "        \"Like, comment, and subscribe for more!\\n\"\n",
        "        \"What should the next matchup be?\\n\\n\"\n",
        "        \"#shorts #music #rapbattle #aimusic\"\n",
        "    )\n",
        "    tags = [\"#shorts\",\"rap battle\",\"ai music\",\"music\",\"hip hop\",\"epic\",\"versus\",\n",
        "            \"battle\",\"lyrics\",\"hook\",\"beat\",\"viral\",\"trending\",\"shorts\"]\n",
        "    return title, description, tags\n",
        "\n",
        "def _parse_md(s: str):\n",
        "    try:\n",
        "        j = json.loads(s)\n",
        "        t = j.get(\"title\",\"\").strip()\n",
        "        d = j.get(\"description\",\"\").strip()\n",
        "        tags = [x.strip() for x in j.get(\"tags\",[]) if isinstance(x,str) and x.strip()]\n",
        "        if not t or not d or not tags:\n",
        "            raise ValueError(\"Missing keys\")\n",
        "        return t, d, tags\n",
        "    except Exception:\n",
        "        return _heuristic_fallback(topic_text)\n",
        "\n",
        "try:\n",
        "    resp = oai.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        temperature=0.7,\n",
        "        max_tokens=900,\n",
        "        messages=[{\"role\":\"system\",\"content\":SYS},{\"role\":\"user\",\"content\":USR}],\n",
        "    )\n",
        "    t, d, tags = _parse_md(resp.choices[0].message.content.strip())\n",
        "except (BadRequestError, AuthenticationError, RateLimitError, Exception) as e:\n",
        "    print(\"âš ï¸ LLM metadata error:\", e)\n",
        "    t, d, tags = _heuristic_fallback(topic_text)\n",
        "\n",
        "# Enforce limits/requirements\n",
        "def _clip(s, n):\n",
        "    return s if len(s)<=n else s[:n].rstrip()\n",
        "\n",
        "title = _clip(t, 85)\n",
        "tags = [x for x in tags if x]\n",
        "if \"#shorts\" not in [x.lower() for x in tags]:\n",
        "    tags.append(\"#shorts\")\n",
        "# trim each tag to 25 chars, max 30 total, dedupe (preserve order)\n",
        "tags = [x[:25] for x in tags]\n",
        "seen=set(); final_tags=[]\n",
        "for x in tags:\n",
        "    k=x.lower()\n",
        "    if k not in seen:\n",
        "        final_tags.append(x)\n",
        "        seen.add(k)\n",
        "tags = final_tags[:30]\n",
        "\n",
        "# Persist for auditing\n",
        "(OUT/\"metadata.json\").write_text(json.dumps({\"title\":title,\"description\":d,\"tags\":tags}, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "print(\"ðŸ“ Title:\", title)\n",
        "print(\"ðŸ“„ Description (preview):\", d[:220].replace(\"\\n\",\" \") + (\"...\" if len(d)>220 else \"\"))\n",
        "print(\"ðŸ·ï¸ Tags:\", tags)\n"
      ],
      "metadata": {
        "id": "VV4tp-6fXWc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 4) Upload to YouTube (no clipping; resumable; retries)\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "from googleapiclient.errors import HttpError\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "# Use your final render path\n",
        "UPLOAD_PATH = str(OUT/\"shorts_final.mp4\")\n",
        "assert Path(UPLOAD_PATH).exists(), f\"Video not found: {UPLOAD_PATH}\"\n",
        "\n",
        "def upload_video_to_youtube(\n",
        "    file_path, title, description, tags,\n",
        "    category_id=10,          # 10 = Music; 24 = Entertainment\n",
        "    privacy=\"public\",\n",
        "    chunk_size=1024*1024*8,  # 8MB chunks\n",
        "    max_retries=5\n",
        "):\n",
        "    if isinstance(tags, str):\n",
        "        tags = [t.strip() for t in tags.split(\",\") if t.strip()]\n",
        "    if \"#shorts\" not in [t.lower() for t in tags]:\n",
        "        tags.append(\"#shorts\")\n",
        "\n",
        "    body = {\n",
        "        \"snippet\": {\n",
        "            \"title\": title,\n",
        "            \"description\": description + (\"\\n\\n#shorts\" if \"#shorts\" not in description.lower() else \"\"),\n",
        "            \"tags\": tags,\n",
        "            \"categoryId\": str(category_id)\n",
        "        },\n",
        "        \"status\": {\n",
        "            \"privacyStatus\": privacy,\n",
        "            \"selfDeclaredMadeForKids\": False\n",
        "        }\n",
        "    }\n",
        "\n",
        "    media = MediaFileUpload(file_path, mimetype=\"video/mp4\", chunksize=chunk_size, resumable=True)\n",
        "    req = youtube.videos().insert(part=\"snippet,status\", body=body, media_body=media)\n",
        "\n",
        "    done = False; retry = 0; resp = None\n",
        "    while not done:\n",
        "        try:\n",
        "            status, resp = req.next_chunk()\n",
        "            if status:\n",
        "                print(f\"ðŸŸ¢ {int(status.progress()*100)}% uploaded\")\n",
        "            else:\n",
        "                done = True\n",
        "        except HttpError as e:\n",
        "            if e.resp.status in [500, 502, 503, 504] and retry < max_retries:\n",
        "                retry += 1\n",
        "                sleep_s = 2**retry\n",
        "                print(f\"âš ï¸ Transient error {e.resp.status}. Retry {retry} in {sleep_s}sâ€¦\")\n",
        "                time.sleep(sleep_s)\n",
        "                continue\n",
        "            raise\n",
        "    video_id = resp.get(\"id\")\n",
        "    print(\"âœ… Upload complete! Video ID:\", video_id)\n",
        "    return resp\n",
        "\n",
        "response = upload_video_to_youtube(\n",
        "    file_path=UPLOAD_PATH,\n",
        "    title=title,\n",
        "    description=d,\n",
        "    tags=tags,\n",
        "    category_id=10,      # Music\n",
        "    privacy=\"public\"\n",
        ")\n",
        "print(\"ðŸŽ‰ https://youtu.be/\" + response[\"id\"])\n"
      ],
      "metadata": {
        "id": "CuaCQ9daYjX1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}