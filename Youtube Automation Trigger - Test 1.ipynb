{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1️⃣ Secrets & API-key bootstrap"
      ],
      "metadata": {
        "id": "Rnt1zYKUtYy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ────────────────────────────────────────────────────────────────────────\n",
        "#  SECRETS → LOCAL FILES  |  runs before any other import\n",
        "# ────────────────────────────────────────────────────────────────────────\n",
        "import os, base64, pathlib\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "\n",
        "def _decode(secret_name: str, out_file: str):\n",
        "    \"\"\"Decode a Base-64 GitHub secret onto disk.\"\"\"\n",
        "    pathlib.Path(out_file).write_bytes(\n",
        "        base64.b64decode(os.environ[secret_name])\n",
        "    )\n",
        "\n",
        "_decode(\"CLIENT_SECRETS_JSON\", \"client_secrets.json\")\n",
        "_decode(\"TOKEN_JSON\",          \"token.json\")\n",
        "\n",
        "# OpenAI key comes from the repo secret\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        "client = OpenAI()                              # <- used later for chat + TTS\n",
        "\n",
        "print(\"✅ Secrets decoded, OpenAI client ready.\")\n"
      ],
      "metadata": {
        "id": "mGMYG1pYtZ2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2️⃣ Parameter cell"
      ],
      "metadata": {
        "id": "zMHzrGLkuV5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PARAMETERS  (Papermill / run-notebook overwrites these at run-time)\n",
        "GAMEPLAY_URL = None                         # GitHub secret injects real link\n",
        "TITLE_TEXT   = \"Daily DALLE Short\"          # you can override this too\n",
        "OPENAI_MODEL = \"gpt-4o\"\n"
      ],
      "metadata": {
        "id": "7LF15yK-ucTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔐 3. Authenticate with YouTube"
      ],
      "metadata": {
        "id": "SHzZ3v0lAbeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔐 2. Authenticate with YouTube (automatic – no browser needed)\n",
        "from google.oauth2.credentials import Credentials\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "SCOPES = [\n",
        "    \"https://www.googleapis.com/auth/youtube.upload\",\n",
        "    \"https://www.googleapis.com/auth/youtube.force-ssl\",\n",
        "]\n",
        "\n",
        "creds = Credentials.from_authorized_user_file(\"token.json\", SCOPES)\n",
        "youtube = build(\"youtube\", \"v3\", credentials=creds)\n",
        "\n",
        "print(\"✅ YouTube Data API authenticated via refresh-token.\")\n"
      ],
      "metadata": {
        "id": "MPFDRFqu9iiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🚀 4.0 Cockpit: Your Customizable Inputs"
      ],
      "metadata": {
        "id": "CfoX-MBVAXVl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2kM69qQ9EbI"
      },
      "outputs": [],
      "source": [
        "# ─── 0. Cockpit: Auto‑Generated News Topic via Reddit r/worldnews ──────────\n",
        "import random, time\n",
        "import praw\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# 1) Initialize PRAW Reddit client\n",
        "reddit = praw.Reddit(\n",
        "    client_id=\"IPF2FtGAO8sLhzTUbEGSsQ\",\n",
        "    client_secret=\"RLO_IjGT9qIjnaYPxlVctFF3XL4Cjg\",\n",
        "    user_agent=\"DailyNewsMax by /u/Rexxus25\"\n",
        ")\n",
        "\n",
        "# 2) Fetch top submissions from r/worldnews in the past 48 hours\n",
        "sub = reddit.subreddit(\"worldnews\")\n",
        "now = time.time()\n",
        "two_days_ago = now - 48 * 3600\n",
        "\n",
        "# Grab the top 50 from the past week, filter to last 48 h, sort by score\n",
        "posts = list(sub.top(time_filter=\"week\", limit=50))\n",
        "recent = [p for p in posts if p.created_utc >= two_days_ago]\n",
        "recent_sorted = sorted(recent, key=lambda p: p.score, reverse=True)\n",
        "top10 = recent_sorted[:20] if recent_sorted else posts[:20]\n",
        "\n",
        "# 3) Pick one at random\n",
        "selected = random.choice(top10)\n",
        "background_topic = selected.title\n",
        "article_url      = selected.url\n",
        "\n",
        "# ─── NEW: Fetch the full article text ────────────────────────────────\n",
        "resp = requests.get(article_url, timeout=10)\n",
        "soup = BeautifulSoup(resp.text, \"html.parser\")\n",
        "paragraphs = soup.find_all(\"p\")\n",
        "article_text = \"\\n\".join(p.get_text() for p in paragraphs)\n",
        "\n",
        "print(\"🔄 Auto‑selected news topic:\", background_topic)\n",
        "print(\"🔗 Article URL:\", article_url)\n",
        "print(\"📄 Article snippet:\", article_text[:200].replace(\"\\n\", \" \"), \"…\")\n",
        "\n",
        "# === COCKPIT SETTINGS ===\n",
        "clip_duration   = 61   # seconds (you can adjust for testing)\n",
        "outro_text      = \"That's it for today! Follow for more news tomorrow.\"\n",
        "outro_fontsize  = 55\n",
        "outro_position  = (\"center\",\"center\")\n",
        "outro_duration  = 3    # seconds\n",
        "\n",
        "output_width, output_height = 1080, 1920\n",
        "pexels_per_search = 15\n",
        "\n",
        "print(\"✅ Cockpit configured:\")\n",
        "print(f\"   • Topic         = {background_topic!r}\")\n",
        "print(f\"   • URL           = {article_url}\")\n",
        "print(f\"   • Clip duration = {clip_duration}s (+ outro {outro_duration}s)\")\n",
        "print(f\"   • Resolution    = {output_width}×{output_height}\")\n",
        "print(f\"   • Pexels search = {pexels_per_search} clips tested\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🎥 4.05 Pexels Search & Download Helpers"
      ],
      "metadata": {
        "id": "YM3DO5ESAeCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "PEXELS_API_KEY = \"dF2GrslU19FhJYkOVLWNLO4Mz8Bk5UPDcmVILSCPeQDForUFqnRvX5yH\"\n",
        "\n",
        "def search_pexels_videos(query, per_page=5):\n",
        "    url = \"https://api.pexels.com/videos/search\"\n",
        "    headers = {\"Authorization\": PEXELS_API_KEY}\n",
        "    params = {\"query\": query, \"per_page\": per_page}\n",
        "    r = requests.get(url, headers=headers, params=params)\n",
        "    r.raise_for_status()\n",
        "    return r.json()[\"videos\"]\n",
        "\n",
        "def download_pexels_video(video_json, fname):\n",
        "    files = video_json.get(\"video_files\", [])\n",
        "    if not files:\n",
        "        raise RuntimeError(\"No video_files in JSON\")\n",
        "    # pick highest resolution\n",
        "    files.sort(key=lambda f: f.get(\"width\",0)*f.get(\"height\",0), reverse=True)\n",
        "    url = files[0][\"link\"]\n",
        "    with requests.get(url, stream=True) as r:\n",
        "        r.raise_for_status()\n",
        "        with open(fname, \"wb\") as f:\n",
        "            for chunk in r.iter_content(8192):\n",
        "                if chunk:\n",
        "                    f.write(chunk)\n",
        "    return fname"
      ],
      "metadata": {
        "id": "iYDB20xd9nMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔧 4.1 Generate Text Segments Cell"
      ],
      "metadata": {
        "id": "xg4ExlVZoNk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── 4.1 Generate Chunked Text Segments via ChatGPT ─────────────────────\n",
        "import json, re, random\n",
        "from datetime import datetime\n",
        "\n",
        "intros = [\n",
        "    \"Hey everyone, welcome to DailyNewsMax! Today’s story is about\",\n",
        "    \"Hello and thanks for tuning in—DailyNewsMax here with today’s headline:\",\n",
        "    \"Good day, folks! This is DailyNewsMax, covering today’s top story about\",\n",
        "    \"What’s up, NewsMaxers? Today we’re looking at\",\n",
        "]\n",
        "today_str = datetime.now().strftime(\"%B %d, %Y\")\n",
        "\n",
        "prompt = f\"\"\"\n",
        "You are a Professional Breaking News Script Generator for DailyNewsMax. Create an urgent, high-energy dialogue between the host and the audience for a {clip_duration}-second YouTube Short video. Ensure there is enough generated text to fill out a narrated clip of {clip_duration} seconds, using:\n",
        "\n",
        "**STORY CONTEXT**\n",
        "- HEADLINE: \"{background_topic}\"\n",
        "- SOURCE: \"{article_url}\"\n",
        "- BODY: \"{article_text}\"\n",
        "\n",
        "**FORMAT RULES**\n",
        "1. NO SPEAKER LABELS\n",
        "2. Use VIRAL HOOK TECHNIQUES:\n",
        "   - Start with a shocking statistic or phrase.\n",
        "3. STRUCTURE LIKE TOP NEWS SHORTS:\n",
        "   [OPENING 0–3s] Attention-grabbing hook, beginning with one of:\n",
        "     \"{random.choice(intros)} {background_topic}.\"\n",
        "   [TEASE 3–7s] Tease with urgency and date:\n",
        "     \"This just broke on {today_str} from {article_url.split('/')[2]}...\"\n",
        "   [PAYOFF 7–{clip_duration}s] Rapid-fire facts + CTA\n",
        "     - Alternate perspectives (Fact → Reaction)\n",
        "     - End with \"Tap follow NOW for updates\"\n",
        "\n",
        "4. Include enough relevant detail from the body to inform the viewer.\n",
        "5. Keep it concise—no more than 20 words per chunk, natural breakpoints.\n",
        "\n",
        "Return ONLY a JSON array of three arrays—one per segment—like:\n",
        "[\n",
        "  [\"Hook chunk 1\", \"Hook chunk 2\"],\n",
        "  [\"Tease chunk 1\", \"Tease chunk 2\"],\n",
        "  [\"Payoff chunk 1\", \"Payoff chunk 2\", ...]\n",
        "]\n",
        "\"\"\"\n",
        "\n",
        "resp = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    temperature=0.9,\n",
        "    max_tokens=760\n",
        ")\n",
        "\n",
        "raw = resp.choices[0].message.content.strip()\n",
        "json_text = raw[raw.find('['):raw.rfind(']')+1]\n",
        "json_text = re.sub(r',\\s*(\\])', r'\\1', json_text)\n",
        "\n",
        "try:\n",
        "    texts_nested = json.loads(json_text)\n",
        "except json.JSONDecodeError as e:\n",
        "    raise ValueError(f\"Failed to parse JSON:\\n{json_text}\\n\\nOriginal response:\\n{raw}\") from e\n",
        "\n",
        "print(\"✅ Generated nested text segments:\", texts_nested)"
      ],
      "metadata": {
        "id": "VRpCc9ojoN0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔧 4.2 Generate NARRATION for Text Segments Cell"
      ],
      "metadata": {
        "id": "tPYwhyzoIUEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── 4 .2  Flatten text & generate TTS narration ───────────────────────\n",
        "# MoviePy ≥ 2.x no longer provides the `moviepy.editor` aggregator.\n",
        "# Import AudioFileClip directly from the new audio sub-package:\n",
        "from moviepy.audio.io.AudioFileClip import AudioFileClip\n",
        "\n",
        "def generate_tts(text: str, filename: str) -> str:\n",
        "    \"\"\"Generate text-to-speech using OpenAI TTS and save to *filename*.\"\"\"\n",
        "    response = client.audio.speech.create(        # uses the global `client`\n",
        "        model=\"tts-1\",\n",
        "        voice=\"echo\",\n",
        "        input=text\n",
        "    )\n",
        "    response.stream_to_file(filename)\n",
        "    return filename\n",
        "\n",
        "def calculate_precise_timings(flat_segments):\n",
        "    \"\"\"Back-propagate precise timings once we know exact audio durations.\"\"\"\n",
        "    current_start = 0.0\n",
        "    for segment in flat_segments:\n",
        "        segment[\"start\"] = current_start\n",
        "        segment[\"end\"]   = current_start + segment[\"duration\"]\n",
        "        current_start    = segment[\"end\"]\n",
        "    return flat_segments\n",
        "\n",
        "# ─── 1) Flatten the nested text into sequential segments ───────────────\n",
        "segment_word_counts = [\n",
        "    sum(len(chunk.split()) for chunk in seg) for seg in texts_nested\n",
        "]\n",
        "total_words      = sum(segment_word_counts)\n",
        "seconds_per_word = clip_duration / total_words\n",
        "\n",
        "flat_segments, t = [], 0.0\n",
        "for seg in texts_nested:\n",
        "    for chunk in seg:\n",
        "        dur_est = len(chunk.split()) * seconds_per_word\n",
        "        flat_segments.append({\"text\": chunk, \"start\": t, \"duration\": dur_est})\n",
        "        t += dur_est\n",
        "\n",
        "# ─── 2) Generate individual TTS files ───────────────────────────────────\n",
        "narration_files = []\n",
        "for idx, seg in enumerate(flat_segments):\n",
        "    fn = f\"narr_{idx}.mp3\"\n",
        "    print(f\"🔈 TTS chunk {idx}: “{seg['text']}” → {fn}\")\n",
        "    generate_tts(seg[\"text\"], fn)\n",
        "    narration_files.append((fn, seg[\"start\"]))\n",
        "\n",
        "# ─── 3) Re-measure each clip’s real duration, then fix timings ──────────\n",
        "for i, (fn, _) in enumerate(narration_files):\n",
        "    audio_clip = AudioFileClip(fn)\n",
        "    flat_segments[i][\"duration\"] = audio_clip.duration\n",
        "\n",
        "flat_segments   = calculate_precise_timings(flat_segments)\n",
        "narration_files = [\n",
        "    (fn, seg[\"start\"])\n",
        "    for fn, seg in zip([f[0] for f in narration_files], flat_segments)\n",
        "]\n",
        "\n",
        "print(\"✅ Synced narration segments:\", flat_segments)\n"
      ],
      "metadata": {
        "id": "cyCJEkTiTYHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5-7 Video Editing"
      ],
      "metadata": {
        "id": "bup9cn-QHSqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── 0) ✱ NEW – fetch gameplay from URL (runs once) ──────────────────────\n",
        "import os, pathlib, subprocess, shlex\n",
        "\n",
        "dst = pathlib.Path(\"gameplay_trimmed.mp4\")\n",
        "if not dst.exists():\n",
        "    file_id = os.environ[\"GAMEPLAY_URL\"].split(\"id=\")[-1]\n",
        "    subprocess.run(shlex.split(f\"gdown --id {file_id} -O {dst}\"), check=True)\n",
        "print(\"✓ gameplay at\", dst.resolve())\n",
        "\n",
        "# ─── 5–7 Video Editing + Composite Narration ─────────────────────────────\n",
        "import random, textwrap\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# ⬇️ NEW — universal MoviePy ≥/≤ 2.0 helpers & imports\n",
        "# ── editing code block start ─────────────────────────────────────────────\n",
        "from moviepy import (\n",
        "    VideoFileClip, CompositeVideoClip, concatenate_videoclips,\n",
        "    ColorClip, ImageClip, AudioFileClip, CompositeAudioClip,\n",
        "    vfx, afx\n",
        ")\n",
        "\n",
        "# ─── Generic helper to apply an *effect* on any MoviePy version ──────────\n",
        "def _apply_fx(clip, effect):\n",
        "    \"\"\"\n",
        "    Safely apply an *effect* object on *clip* across MoviePy versions.\n",
        "    Works with:\n",
        "      • clip.fx(...)                – MoviePy ≤ 1.x and most 2.x builds\n",
        "      • clip.with_effect(...)       – some 2.x snapshots\n",
        "      • clip.with_fx(...)           – rare alt name that appeared briefly\n",
        "      • clip.with_effects([effect]) – MoviePy ≥ 2.0 official\n",
        "    \"\"\"\n",
        "    if hasattr(clip, \"fx\"):\n",
        "        return clip.fx(effect)\n",
        "    if hasattr(clip, \"with_effect\"):\n",
        "        return clip.with_effect(effect)\n",
        "    if hasattr(clip, \"with_fx\"):\n",
        "        return clip.with_fx(effect)\n",
        "    if hasattr(clip, \"with_effects\"):\n",
        "        return clip.with_effects([effect])\n",
        "    raise RuntimeError(\n",
        "        \"No recognised method to apply effects on this MoviePy build.\"\n",
        "    )\n",
        "\n",
        "# ─── 1) audio_loop (works on any version) ───────────────────────────────\n",
        "def audio_loop(clip, *, duration=None, n=None):\n",
        "    \"\"\"Repeat *clip* until it reaches *duration* seconds or *n* loops.\"\"\"\n",
        "    # MoviePy ≤ 1.x still ships the old helper in afx\n",
        "    if getattr(afx, \"audio_loop\", None):\n",
        "        return afx.audio_loop(clip, duration=duration, n=n)\n",
        "\n",
        "    # MoviePy ≥ 2.0 effect class\n",
        "    try:\n",
        "        from moviepy.audio.fx.AudioLoop import AudioLoop\n",
        "        return _apply_fx(clip, AudioLoop(duration=duration, n=n))\n",
        "    except ModuleNotFoundError:\n",
        "        # Fallback: rely on the generic vfx.Loop (works on audio too)\n",
        "        return _apply_fx(clip, vfx.Loop(duration=duration, n=n))\n",
        "\n",
        "# ─── 2) resize_fx  (handles .resize ⇆ .resized rename)  ─────────────────\n",
        "def resize_fx(clip, newsize):\n",
        "    \"\"\"Version-agnostic resize effect.\"\"\"\n",
        "    if hasattr(clip, \"resized\"):      # MoviePy ≥ 2.0\n",
        "        return clip.resized(newsize)\n",
        "    return clip.resize(newsize)       # MoviePy ≤ 1.x\n",
        "\n",
        "# ─── 3) loop_fx  (video or audio) ───────────────────────────────────────\n",
        "def loop_fx(clip, *, duration=None, n=None):\n",
        "    \"\"\"Loop *clip* via the vfx.Loop effect, regardless of version.\"\"\"\n",
        "    return _apply_fx(clip, vfx.Loop(duration=duration, n=n))\n",
        "\n",
        "# ─── 4) subclip_fx  (max-compat temporal trimming) ──────────────────────\n",
        "def subclip_fx(clip, start, end):\n",
        "    \"\"\"\n",
        "    Return a slice of *clip* between *start* – *end* seconds, whatever\n",
        "    MoviePy version is installed.\n",
        "    \"\"\"\n",
        "    # A) Classic API  (MoviePy ≤ 1.x   & most early 2.x dev builds)\n",
        "    if hasattr(clip, \"subclip\"):\n",
        "        return clip.subclip(start, end)\n",
        "\n",
        "    # B) Official 2.0+ method name\n",
        "    if hasattr(clip, \"time_slice\"):\n",
        "        return clip.time_slice(start_time=start, end_time=end)\n",
        "\n",
        "    # C) 2.0 snapshots that expose a Trim/Subclip *effect* class instead\n",
        "    try:\n",
        "        from moviepy.video.fx.Subclip import Subclip as _Subclip\n",
        "        return _apply_fx(clip, _Subclip(start_time=start, end_time=end))\n",
        "    except ModuleNotFoundError:\n",
        "        pass\n",
        "    try:\n",
        "        from moviepy.video.fx.trim import trim as _trim\n",
        "        return _trim(clip, start_time=start, end_time=end)\n",
        "    except ModuleNotFoundError:\n",
        "        pass\n",
        "\n",
        "    # D) Last-ditch fallback – we're on some exotic build that renamed the API\n",
        "    if start == 0:\n",
        "        # 1) most historical versions\n",
        "        if hasattr(clip, \"set_duration\"):\n",
        "            return clip.set_duration(end)\n",
        "        # 2) MoviePy 2.0+ renamed setter\n",
        "        if hasattr(clip, \"with_duration\"):\n",
        "            return clip.with_duration(end)\n",
        "        # 3) extremely early 2.x snapshots used `with_end`\n",
        "        if hasattr(clip, \"with_end\"):\n",
        "            return clip.with_end(end)\n",
        "        # 4) give up – at least return the original clip rather than crash\n",
        "        return clip\n",
        "    raise RuntimeError(\"No compatible subclip/time-slice implementation found\")\n",
        "\n",
        "# ─── 5) crop_fx  (covers every naming convention so far) ────────────────\n",
        "def crop_fx(clip, **kwargs):\n",
        "    \"\"\"\n",
        "    Universal crop that works with MoviePy 1.x and 2.x.\n",
        "    Accepts the classic keyword args (x1, y1, x2, y2, width, height…).\n",
        "    \"\"\"\n",
        "    # (a) Native instance methods first\n",
        "    if hasattr(clip, \"cropped\"):      # MoviePy ≥ 2.0 preferred\n",
        "        return clip.cropped(**kwargs)\n",
        "    if hasattr(clip, \"crop\"):         # MoviePy ≤ 1.x\n",
        "        return clip.crop(**kwargs)\n",
        "\n",
        "    # (b) New effect class (MoviePy ≥ 2.0 snapshots)\n",
        "    try:\n",
        "        from moviepy.video.fx.Crop import Crop as _Crop\n",
        "        return _apply_fx(clip, _Crop(**kwargs))\n",
        "    except ModuleNotFoundError:\n",
        "        pass\n",
        "\n",
        "    # (c) Very old functional helper\n",
        "    try:\n",
        "        from moviepy.video.fx.crop import crop as _crop_func\n",
        "        return _crop_func(clip, **kwargs)\n",
        "    except ModuleNotFoundError as e:\n",
        "        raise RuntimeError(\"No compatible crop implementation found\") from e\n",
        "\n",
        "# ── editing code block end ───────────────────────────────────────────────\n",
        "\n",
        "# ── imports needed by text-clip generator ───────────────────────────────\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from freesound import FreesoundClient\n",
        "import requests\n",
        "\n",
        "# ─── Font, canvas & divider settings ────────────────────────────────────\n",
        "text_font      = \"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\"\n",
        "text_fontsize  = 60\n",
        "W, H           = output_width, output_height\n",
        "half_h         = H // 2\n",
        "divider_height = 30                     # white bar thickness\n",
        "\n",
        "# ─── 1) Top half: gameplay with 12 % crop, resize & loop ────────────────\n",
        "gameplay = VideoFileClip(\"gameplay_trimmed.mp4\")\n",
        "h_crop   = int(gameplay.h * 0.12)\n",
        "gameplay = crop_fx(gameplay, y1=h_crop, y2=gameplay.h - h_crop)\n",
        "gameplay = loop_fx(resize_fx(gameplay, (W, half_h)), duration=clip_duration)\n",
        "\n",
        "# ─── 2) Bottom half: Pexels background – squash to fit ──────────────────\n",
        "videos  = search_pexels_videos(background_topic, per_page=pexels_per_search)\n",
        "paths   = [f\"clip_{i}.mp4\" for i, _ in enumerate(videos)]\n",
        "with ThreadPoolExecutor() as ex:\n",
        "    ex.map(lambda args: download_pexels_video(*args), zip(videos, paths))\n",
        "\n",
        "subclips, acc = [], 0\n",
        "for p in paths:\n",
        "    clip    = VideoFileClip(p)\n",
        "    remain  = clip_duration - acc\n",
        "    if remain <= 0:\n",
        "        break\n",
        "    take    = min(clip.duration, remain)\n",
        "    resized = resize_fx(clip, (W, half_h))\n",
        "    subclip = subclip_fx(resized, 0, take)  # Removed .set_duration()\n",
        "\n",
        "    # Version-agnostic duration setting\n",
        "    if hasattr(subclip, \"with_duration\"):\n",
        "        subclip = subclip.with_duration(take)\n",
        "    elif hasattr(subclip, \"set_duration\"):\n",
        "        subclip = subclip.set_duration(take)\n",
        "\n",
        "    subclips.append(subclip)\n",
        "    acc += take\n",
        "\n",
        "background_bottom = concatenate_videoclips(subclips, method=\"compose\") \\\n",
        "                    .set_duration(clip_duration)\n",
        "\n",
        "# ─── 3) Divider: 30 px white bar at the seam ────────────────────────────\n",
        "divider = ColorClip((W, divider_height), color=(255, 255, 255),\n",
        "                    duration=clip_duration).set_position(\n",
        "                    (\"center\", half_h - divider_height // 2))\n",
        "\n",
        "# ─── 4) Text-clip generator  (now defined **before** first use) ─────────\n",
        "def make_text_clip(txt, duration, frame_size, font_path, fontsize,\n",
        "                   fill, position):\n",
        "    \"\"\"\n",
        "    Renders *txt* to a semi-transparent boxed overlay and returns a\n",
        "    MoviePy ImageClip sized to *frame_size*.\n",
        "    \"\"\"\n",
        "    font   = ImageFont.truetype(font_path, fontsize)\n",
        "    max_w  = int(frame_size[0] * 0.9)\n",
        "    avg_w  = font.getbbox(\"A\")[2]\n",
        "    wrap_w = max_w // avg_w\n",
        "    lines  = textwrap.wrap(txt, width=wrap_w)\n",
        "\n",
        "    # measure multiline block\n",
        "    dummy   = ImageDraw.Draw(Image.new(\"RGB\", (1, 1)))\n",
        "    bboxes  = [dummy.textbbox((0, 0), ln, font=font) for ln in lines]\n",
        "    widths  = [x1 - x0 for x0, _, x1, _ in bboxes]\n",
        "    heights = [y1 - y0 for _, y0, _, y1 in bboxes]\n",
        "    block_w = max(widths)  + 20\n",
        "    block_h = sum(heights) + 5 * (len(lines) - 1) + 20\n",
        "\n",
        "    # transparent RGBA canvas\n",
        "    img   = Image.new(\"RGBA\", frame_size, (0, 0, 0, 0))\n",
        "    draw  = ImageDraw.Draw(img)\n",
        "    x0,y0 = (frame_size[0] - block_w)//2, (frame_size[1] - block_h)//2\n",
        "    draw.rectangle([x0, y0, x0 + block_w, y0 + block_h], fill=(0, 0, 0, 128))\n",
        "\n",
        "    y = y0 + 10\n",
        "    for ln in lines:\n",
        "        w = draw.textbbox((0, 0), ln, font=font)[2]\n",
        "        draw.text((x0 + (block_w - w)//2, y), ln, font=font, fill=fill)\n",
        "        y += font.getbbox(ln)[3] - font.getbbox(ln)[1] + 5\n",
        "\n",
        "    return ImageClip(np.asarray(img)).set_duration(duration).set_position(position)\n",
        "\n",
        "# ─── (the “Build Synced Text Clips” loop begins right after this) ───────\n",
        "\n",
        "# (build text_clips → outro → composite → background music → export)\n",
        "# ─── 5) Build Synced Text Clips ────────────────────────────────────────\n",
        "text_clips = []\n",
        "for idx, (fn, start) in enumerate(narration_files):\n",
        "    audio = AudioFileClip(fn)\n",
        "    duration = audio.duration\n",
        "    tc = make_text_clip(\n",
        "        flat_segments[idx][\"text\"],\n",
        "        duration,\n",
        "        (W, H),\n",
        "        text_font, text_fontsize,\n",
        "        \"white\", (\"center\",\"center\")\n",
        "    ).set_start(start).set_duration(duration)\n",
        "    text_clips.append(tc)\n",
        "\n",
        "# ─── 6) Outro Clip ─────────────────────────────────────────────────────\n",
        "outro_txt_clip = make_text_clip(\n",
        "    outro_text, outro_duration, (W, H),\n",
        "    text_font, text_fontsize, \"white\", (\"center\",\"center\")\n",
        ")\n",
        "outro_bg = ColorClip((W, H), (0,0,0), duration=outro_duration)\n",
        "outro_clip = CompositeVideoClip([outro_bg, outro_txt_clip]).set_duration(outro_duration)\n",
        "\n",
        "# ─── 7) Composite Split Screen ─────────────────────────────────────────\n",
        "split = CompositeVideoClip(\n",
        "    [gameplay.set_position((\"center\",\"top\")),\n",
        "     background_bottom.set_position((\"center\",\"bottom\")),\n",
        "     divider] + text_clips,\n",
        "    size=(W, H)\n",
        ")\n",
        "video_final = concatenate_videoclips([split, outro_clip], method=\"compose\")\n",
        "\n",
        "# ─── 8) Background Music ───────────────────────────────────────────────\n",
        "fs = FreesoundClient(); fs.set_token(\"SvkdYKjMtv5lFj5ojxbJ8MPA9dmr8okzsU9pOQIi\")\n",
        "def find_tracks(q, lic):\n",
        "    return fs.text_search(\n",
        "        query=f\"{q} music\", filter=f'license:\"{lic}\"',\n",
        "        sort=\"rating_desc\", fields=\"id,name,license,previews\",\n",
        "        per_page=10\n",
        "    ).results\n",
        "\n",
        "tracks = (\n",
        "    find_tracks(background_topic, \"Creative Commons 0\")\n",
        "    or find_tracks(background_topic, \"Creative Commons Attribution\")\n",
        "    or find_tracks(\"background music\", \"Creative Commons 0\")\n",
        ")\n",
        "\n",
        "if tracks:\n",
        "    snd = random.choice(tracks)\n",
        "    url = snd[\"previews\"].get(\"preview-hq-mp3\") or snd[\"previews\"].get(\"preview_hq_mp3\")\n",
        "    resp = requests.get(url)\n",
        "    with open(\"music.mp3\",\"wb\") as f:\n",
        "        f.write(resp.content)\n",
        "    bg_music = audio_loop(\n",
        "        AudioFileClip(\"music.mp3\").volumex(0.2),\n",
        "        duration=video_final.duration\n",
        "    )\n",
        "else:\n",
        "    bg_music = None\n",
        "\n",
        "# ─── 9) Final Audio Mix ───────────────────────────────────────────────\n",
        "narr_clips = [AudioFileClip(fn).set_start(start) for fn, start in narration_files]\n",
        "audio_layers = narr_clips + ([bg_music] if bg_music else [])\n",
        "final_audio = CompositeAudioClip(audio_layers)\n",
        "final = video_final.set_audio(final_audio)\n",
        "\n",
        "# ─── 10) Export ───────────────────────────────────────────────────────\n",
        "final.write_videofile(\n",
        "    \"shorts_final.mp4\",\n",
        "    codec=\"libx264\",\n",
        "    audio_codec=\"aac\",\n",
        "    threads=4,\n",
        "    preset=\"ultrafast\",\n",
        "    ffmpeg_params=[\"-crf\",\"23\"]\n",
        ")\n"
      ],
      "metadata": {
        "id": "WBCeHr1aHU1E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "d0eddc63-77f8-4f04-b74d-08135d4e0d54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'GAMEPLAY_URL'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-cfa752bcd110>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gameplay_trimmed.mp4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mfile_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"GAMEPLAY_URL\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"id=\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"gdown {file_id} -O {dst}\"\u001b[0m          \u001b[0;31m# --id flag deprecated in gdown ≥5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshlex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'GAMEPLAY_URL'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#@📝 8. Generate Metadata"
      ],
      "metadata": {
        "id": "gQxaYloyApEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── 8. Generate Metadata (title ≠ background_topic) ───────────────────────\n",
        "def generate_metadata(topic):\n",
        "    prompt = (\n",
        "        f\"Generate a YouTube Short title that is about '{topic}' \"\n",
        "        f\"but does NOT exactly match it. The title should be captivating or catchy and be a generalized title of the '{topic}'.  Then provide a concise description \"\n",
        "        f\"(under 100 words) and 5-6 relevant SEO‑friendly tags, but always #trending, #fyp and #viral #viralshorts included (comma‑separated).\"\n",
        "    )\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\":\"user\",\"content\":prompt}],\n",
        "        temperature=0.7, max_tokens=200\n",
        "    )\n",
        "    text = resp.choices[0].message.content.strip()\n",
        "\n",
        "    # Parse metadata\n",
        "    title, desc, tags = None, None, []\n",
        "    for line in text.splitlines():\n",
        "        low = line.lower()\n",
        "        if low.startswith(\"title:\"):\n",
        "            title = line.split(\":\",1)[1].strip()\n",
        "        if low.startswith(\"description:\"):\n",
        "            desc = line.split(\":\",1)[1].strip()\n",
        "        if low.startswith(\"tags:\"):\n",
        "            tags = [t.strip() for t in line.split(\":\",1)[1].split(\",\")]\n",
        "\n",
        "    # Ensure Shorts requirements\n",
        "    if \"#shorts\" not in [t.lower() for t in tags]:\n",
        "        tags.append(\"#shorts\")\n",
        "    if any(len(tag) > 25 for tag in tags):\n",
        "        tags = [tag[:25] for tag in tags]\n",
        "\n",
        "    return title, desc, tags\n",
        "\n",
        "title, description, tags = generate_metadata(background_topic)\n",
        "print(\"📝 Metadata:\\n \", title, \"\\n \", description, \"\\n \", tags)"
      ],
      "metadata": {
        "id": "EC2-DOmwApZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "📤 9. Upload to YouTube"
      ],
      "metadata": {
        "id": "Po9hWorbAtHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── 9. Upload to YouTube ───────────────────────────────────────────────\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "from googleapiclient.errors import HttpError\n",
        "import time, os\n",
        "\n",
        "def upload_video_to_youtube(\n",
        "    file_path, title, description, tags,\n",
        "    category_id=22, privacy=\"public\",\n",
        "    chunk_size=1024*1024, max_retries=5\n",
        "):\n",
        "    # Enforce Shorts requirements\n",
        "    if not any(t.lower() == \"#shorts\" for t in tags):\n",
        "        tags.append(\"#shorts\")\n",
        "\n",
        "    body = {\n",
        "        \"snippet\": {\n",
        "            \"title\": f\"{title} #shorts\",\n",
        "            \"description\": f\"{description}\\n\\n#shorts\",\n",
        "            \"tags\": tags,\n",
        "            \"categoryId\": str(category_id)\n",
        "        },\n",
        "        \"status\": {\n",
        "            \"privacyStatus\": privacy,\n",
        "            \"selfDeclaredMadeForKids\": False\n",
        "        },\n",
        "        \"contentDetails\": {\n",
        "            \"duration\": \"PT60S\"  # Force recognition as Short\n",
        "        }\n",
        "    }\n",
        "\n",
        "    media = MediaFileUpload(\n",
        "        file_path,\n",
        "        mimetype='video/mp4',\n",
        "        chunksize=chunk_size,\n",
        "        resumable=True\n",
        "    )\n",
        "\n",
        "    req = youtube.videos().insert(\n",
        "        part=\"snippet,status,contentDetails\",\n",
        "        body=body,\n",
        "        media_body=media\n",
        "    )\n",
        "\n",
        "    done = False\n",
        "    retry = 0\n",
        "    while not done:\n",
        "        try:\n",
        "            status, resp = req.next_chunk()\n",
        "            if status:\n",
        "                print(f\"🟢 {int(status.progress()*100)}% uploaded\")\n",
        "            else:\n",
        "                done = True\n",
        "        except HttpError as e:\n",
        "            if e.resp.status in [500,502,503,504] and retry < max_retries:\n",
        "                retry += 1\n",
        "                time.sleep(2**retry)\n",
        "                print(f\"⚠️ Retry {retry}\")\n",
        "            else:\n",
        "                raise\n",
        "\n",
        "    print(\"✅ Upload complete! Video ID:\", resp[\"id\"])\n",
        "    return resp\n",
        "\n",
        "response = upload_video_to_youtube(\"shorts_final.mp4\", title, description, tags)\n",
        "print(\"🎉 Done! https://youtu.be/\" + response[\"id\"])"
      ],
      "metadata": {
        "id": "6Oy8j6CEAtcp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}