{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1ï¸âƒ£ Secrets & API-key bootstrap"
      ],
      "metadata": {
        "id": "Rnt1zYKUtYy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "#  SECRETS â†’ LOCAL FILES  |  runs before any other import\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "import os, base64, pathlib\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "\n",
        "def _decode(secret_name: str, out_file: str):\n",
        "    \"\"\"Decode a Base-64 GitHub secret onto disk.\"\"\"\n",
        "    pathlib.Path(out_file).write_bytes(\n",
        "        base64.b64decode(os.environ[secret_name])\n",
        "    )\n",
        "\n",
        "_decode(\"CLIENT_SECRETS_JSON\", \"client_secrets.json\")\n",
        "_decode(\"TOKEN_JSON\",          \"token.json\")\n",
        "\n",
        "# OpenAI key comes from the repo secret\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        "client = OpenAI()                              # <- used later for chat + TTS\n",
        "\n",
        "print(\"âœ… Secrets decoded, OpenAI client ready.\")\n"
      ],
      "metadata": {
        "id": "mGMYG1pYtZ2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2ï¸âƒ£ Parameter cell"
      ],
      "metadata": {
        "id": "zMHzrGLkuV5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PARAMETERS  (Papermill / run-notebook overwrites these at run-time)\n",
        "GAMEPLAY_URL = None                         # GitHub secret injects real link\n",
        "TITLE_TEXT   = \"Daily DALLE Short\"          # you can override this too\n",
        "OPENAI_MODEL = \"gpt-4o\"\n"
      ],
      "metadata": {
        "id": "7LF15yK-ucTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ” 3. Authenticate with YouTube"
      ],
      "metadata": {
        "id": "SHzZ3v0lAbeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ” 2. Authenticate with YouTube (automatic â€“ no browser needed)\n",
        "from google.oauth2.credentials import Credentials\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "SCOPES = [\n",
        "    \"https://www.googleapis.com/auth/youtube.upload\",\n",
        "    \"https://www.googleapis.com/auth/youtube.force-ssl\",\n",
        "]\n",
        "\n",
        "creds = Credentials.from_authorized_user_file(\"token.json\", SCOPES)\n",
        "youtube = build(\"youtube\", \"v3\", credentials=creds)\n",
        "\n",
        "print(\"âœ… YouTube Data API authenticated via refresh-token.\")\n"
      ],
      "metadata": {
        "id": "MPFDRFqu9iiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸš€ 4.0 Cockpit: Your Customizable Inputs"
      ],
      "metadata": {
        "id": "CfoX-MBVAXVl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2kM69qQ9EbI"
      },
      "outputs": [],
      "source": [
        "# â”€â”€â”€ 0. Cockpit: Autoâ€‘Generated News Topic via Reddit r/worldnews â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "import random, time\n",
        "import praw\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# 1) Initialize PRAW Reddit client\n",
        "reddit = praw.Reddit(\n",
        "    client_id=\"IPF2FtGAO8sLhzTUbEGSsQ\",\n",
        "    client_secret=\"RLO_IjGT9qIjnaYPxlVctFF3XL4Cjg\",\n",
        "    user_agent=\"DailyNewsMax by /u/Rexxus25\"\n",
        ")\n",
        "\n",
        "# 2) Fetch top submissions from r/worldnews in the past 48â€¯hours\n",
        "sub = reddit.subreddit(\"worldnews\")\n",
        "now = time.time()\n",
        "two_days_ago = now - 48 * 3600\n",
        "\n",
        "# Grab the top 50 from the past week, filter to last 48â€¯h, sort by score\n",
        "posts = list(sub.top(time_filter=\"week\", limit=50))\n",
        "recent = [p for p in posts if p.created_utc >= two_days_ago]\n",
        "recent_sorted = sorted(recent, key=lambda p: p.score, reverse=True)\n",
        "top10 = recent_sorted[:20] if recent_sorted else posts[:20]\n",
        "\n",
        "# 3) Pick one at random\n",
        "selected = random.choice(top10)\n",
        "background_topic = selected.title\n",
        "article_url      = selected.url\n",
        "\n",
        "# â”€â”€â”€ NEW: Fetch the full article text â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "resp = requests.get(article_url, timeout=10)\n",
        "soup = BeautifulSoup(resp.text, \"html.parser\")\n",
        "paragraphs = soup.find_all(\"p\")\n",
        "article_text = \"\\n\".join(p.get_text() for p in paragraphs)\n",
        "\n",
        "print(\"ğŸ”„ Autoâ€‘selected news topic:\", background_topic)\n",
        "print(\"ğŸ”— Article URL:\", article_url)\n",
        "print(\"ğŸ“„ Article snippet:\", article_text[:200].replace(\"\\n\", \" \"), \"â€¦\")\n",
        "\n",
        "# === COCKPIT SETTINGS ===\n",
        "clip_duration   = 61   # seconds (you can adjust for testing)\n",
        "outro_text      = \"That's it for today! Follow for more news tomorrow.\"\n",
        "outro_fontsize  = 55\n",
        "outro_position  = (\"center\",\"center\")\n",
        "outro_duration  = 3    # seconds\n",
        "\n",
        "output_width, output_height = 1080, 1920\n",
        "pexels_per_search = 15\n",
        "\n",
        "print(\"âœ… Cockpit configured:\")\n",
        "print(f\"   â€¢ Topic         = {background_topic!r}\")\n",
        "print(f\"   â€¢ URL           = {article_url}\")\n",
        "print(f\"   â€¢ Clip duration = {clip_duration}s (+ outro {outro_duration}s)\")\n",
        "print(f\"   â€¢ Resolution    = {output_width}Ã—{output_height}\")\n",
        "print(f\"   â€¢ Pexels search = {pexels_per_search} clips tested\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ¥ 4.05 Pexels Search & Download Helpers"
      ],
      "metadata": {
        "id": "YM3DO5ESAeCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "PEXELS_API_KEY = \"dF2GrslU19FhJYkOVLWNLO4Mz8Bk5UPDcmVILSCPeQDForUFqnRvX5yH\"\n",
        "\n",
        "def search_pexels_videos(query, per_page=5):\n",
        "    url = \"https://api.pexels.com/videos/search\"\n",
        "    headers = {\"Authorization\": PEXELS_API_KEY}\n",
        "    params = {\"query\": query, \"per_page\": per_page}\n",
        "    r = requests.get(url, headers=headers, params=params)\n",
        "    r.raise_for_status()\n",
        "    return r.json()[\"videos\"]\n",
        "\n",
        "def download_pexels_video(video_json, fname):\n",
        "    files = video_json.get(\"video_files\", [])\n",
        "    if not files:\n",
        "        raise RuntimeError(\"No video_files in JSON\")\n",
        "    # pick highest resolution\n",
        "    files.sort(key=lambda f: f.get(\"width\",0)*f.get(\"height\",0), reverse=True)\n",
        "    url = files[0][\"link\"]\n",
        "    with requests.get(url, stream=True) as r:\n",
        "        r.raise_for_status()\n",
        "        with open(fname, \"wb\") as f:\n",
        "            for chunk in r.iter_content(8192):\n",
        "                if chunk:\n",
        "                    f.write(chunk)\n",
        "    return fname"
      ],
      "metadata": {
        "id": "iYDB20xd9nMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ”§ 4.1 Generate Text Segments Cell"
      ],
      "metadata": {
        "id": "xg4ExlVZoNk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€ 4.1 Generate Chunked Text Segments via ChatGPT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "import json, re, random\n",
        "from datetime import datetime\n",
        "\n",
        "intros = [\n",
        "    \"Hey everyone, welcome to DailyNewsMax! Todayâ€™s story is about\",\n",
        "    \"Hello and thanks for tuning inâ€”DailyNewsMax here with todayâ€™s headline:\",\n",
        "    \"Good day, folks! This is DailyNewsMax, covering todayâ€™s top story about\",\n",
        "    \"Whatâ€™s up, NewsMaxers? Today weâ€™re looking at\",\n",
        "]\n",
        "today_str = datetime.now().strftime(\"%B %d, %Y\")\n",
        "\n",
        "prompt = f\"\"\"\n",
        "You are a Professional Breaking News Script Generator for DailyNewsMax. Create an urgent, high-energy dialogue between the host and the audience for a {clip_duration}-second YouTube Short video. Ensure there is enough generated text to fill out a narrated clip of {clip_duration} seconds, using:\n",
        "\n",
        "**STORY CONTEXT**\n",
        "- HEADLINE: \"{background_topic}\"\n",
        "- SOURCE: \"{article_url}\"\n",
        "- BODY: \"{article_text}\"\n",
        "\n",
        "**FORMAT RULES**\n",
        "1. NO SPEAKER LABELS\n",
        "2. Use VIRAL HOOK TECHNIQUES:\n",
        "   - Start with a shocking statistic or phrase.\n",
        "3. STRUCTURE LIKE TOP NEWS SHORTS:\n",
        "   [OPENING 0â€“3s] Attention-grabbing hook, beginning with one of:\n",
        "     \"{random.choice(intros)} {background_topic}.\"\n",
        "   [TEASE 3â€“7s] Tease with urgency and date:\n",
        "     \"This just broke on {today_str} from {article_url.split('/')[2]}...\"\n",
        "   [PAYOFF 7â€“{clip_duration}s] Rapid-fire facts + CTA\n",
        "     - Alternate perspectives (Fact â†’ Reaction)\n",
        "     - End with \"Tap follow NOW for updates\"\n",
        "\n",
        "4. Include enough relevant detail from the body to inform the viewer.\n",
        "5. Keep it conciseâ€”no more than 20 words per chunk, natural breakpoints.\n",
        "\n",
        "Return ONLY a JSON array of three arraysâ€”one per segmentâ€”like:\n",
        "[\n",
        "  [\"Hook chunk 1\", \"Hook chunk 2\"],\n",
        "  [\"Tease chunk 1\", \"Tease chunk 2\"],\n",
        "  [\"Payoff chunk 1\", \"Payoff chunk 2\", ...]\n",
        "]\n",
        "\"\"\"\n",
        "\n",
        "resp = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    temperature=0.9,\n",
        "    max_tokens=760\n",
        ")\n",
        "\n",
        "raw = resp.choices[0].message.content.strip()\n",
        "json_text = raw[raw.find('['):raw.rfind(']')+1]\n",
        "json_text = re.sub(r',\\s*(\\])', r'\\1', json_text)\n",
        "\n",
        "try:\n",
        "    texts_nested = json.loads(json_text)\n",
        "except json.JSONDecodeError as e:\n",
        "    raise ValueError(f\"Failed to parse JSON:\\n{json_text}\\n\\nOriginal response:\\n{raw}\") from e\n",
        "\n",
        "print(\"âœ… Generated nested text segments:\", texts_nested)"
      ],
      "metadata": {
        "id": "VRpCc9ojoN0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ”§ 4.2 Generate NARRATION for Text Segments Cell"
      ],
      "metadata": {
        "id": "tPYwhyzoIUEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€ 4 .2  Flatten text & generate TTS narration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# MoviePy â‰¥ 2.x no longer provides the `moviepy.editor` aggregator.\n",
        "# Import AudioFileClip directly from the new audio sub-package:\n",
        "from moviepy.audio.io.AudioFileClip import AudioFileClip\n",
        "\n",
        "def generate_tts(text: str, filename: str) -> str:\n",
        "    \"\"\"Generate text-to-speech using OpenAI TTS and save to *filename*.\"\"\"\n",
        "    response = client.audio.speech.create(        # uses the global `client`\n",
        "        model=\"tts-1\",\n",
        "        voice=\"echo\",\n",
        "        input=text\n",
        "    )\n",
        "    response.stream_to_file(filename)\n",
        "    return filename\n",
        "\n",
        "def calculate_precise_timings(flat_segments):\n",
        "    \"\"\"Back-propagate precise timings once we know exact audio durations.\"\"\"\n",
        "    current_start = 0.0\n",
        "    for segment in flat_segments:\n",
        "        segment[\"start\"] = current_start\n",
        "        segment[\"end\"]   = current_start + segment[\"duration\"]\n",
        "        current_start    = segment[\"end\"]\n",
        "    return flat_segments\n",
        "\n",
        "# â”€â”€â”€ 1) Flatten the nested text into sequential segments â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "segment_word_counts = [\n",
        "    sum(len(chunk.split()) for chunk in seg) for seg in texts_nested\n",
        "]\n",
        "total_words      = sum(segment_word_counts)\n",
        "seconds_per_word = clip_duration / total_words\n",
        "\n",
        "flat_segments, t = [], 0.0\n",
        "for seg in texts_nested:\n",
        "    for chunk in seg:\n",
        "        dur_est = len(chunk.split()) * seconds_per_word\n",
        "        flat_segments.append({\"text\": chunk, \"start\": t, \"duration\": dur_est})\n",
        "        t += dur_est\n",
        "\n",
        "# â”€â”€â”€ 2) Generate individual TTS files â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "narration_files = []\n",
        "for idx, seg in enumerate(flat_segments):\n",
        "    fn = f\"narr_{idx}.mp3\"\n",
        "    print(f\"ğŸ”ˆ TTS chunk {idx}: â€œ{seg['text']}â€ â†’ {fn}\")\n",
        "    generate_tts(seg[\"text\"], fn)\n",
        "    narration_files.append((fn, seg[\"start\"]))\n",
        "\n",
        "# â”€â”€â”€ 3) Re-measure each clipâ€™s real duration, then fix timings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "for i, (fn, _) in enumerate(narration_files):\n",
        "    audio_clip = AudioFileClip(fn)\n",
        "    flat_segments[i][\"duration\"] = audio_clip.duration\n",
        "\n",
        "flat_segments   = calculate_precise_timings(flat_segments)\n",
        "narration_files = [\n",
        "    (fn, seg[\"start\"])\n",
        "    for fn, seg in zip([f[0] for f in narration_files], flat_segments)\n",
        "]\n",
        "\n",
        "print(\"âœ… Synced narration segments:\", flat_segments)\n"
      ],
      "metadata": {
        "id": "cyCJEkTiTYHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5-7 Video Editing"
      ],
      "metadata": {
        "id": "bup9cn-QHSqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€ 0) âœ± NEW â€“ fetch gameplay from URL (runs once) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "import os, pathlib, subprocess, shlex\n",
        "\n",
        "dst = pathlib.Path(\"gameplay_trimmed.mp4\")\n",
        "if not dst.exists():\n",
        "    file_id = os.environ[\"GAMEPLAY_URL\"].split(\"id=\")[-1]\n",
        "    subprocess.run(shlex.split(f\"gdown --id {file_id} -O {dst}\"), check=True)\n",
        "print(\"âœ“ gameplay at\", dst.resolve())\n",
        "\n",
        "# â”€â”€â”€ 5â€“7 Video Editing + Composite Narration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "import random, textwrap\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# â¬‡ï¸ NEW â€” universal MoviePy â‰¥/â‰¤ 2.0 helpers & imports\n",
        "# â”€â”€ editing code block start â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "from moviepy import (\n",
        "    VideoFileClip, CompositeVideoClip, concatenate_videoclips,\n",
        "    ColorClip, ImageClip, AudioFileClip, CompositeAudioClip,\n",
        "    vfx, afx\n",
        ")\n",
        "\n",
        "# â”€â”€â”€ Generic helper to apply an *effect* on any MoviePy version â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def _apply_fx(clip, effect):\n",
        "    \"\"\"\n",
        "    Safely apply an *effect* object on *clip* across MoviePy versions.\n",
        "    Works with:\n",
        "      â€¢ clip.fx(...)                â€“ MoviePy â‰¤ 1.x and most 2.x builds\n",
        "      â€¢ clip.with_effect(...)       â€“ some 2.x snapshots\n",
        "      â€¢ clip.with_fx(...)           â€“ rare alt name that appeared briefly\n",
        "      â€¢ clip.with_effects([effect]) â€“ MoviePy â‰¥ 2.0 official\n",
        "    \"\"\"\n",
        "    if hasattr(clip, \"fx\"):\n",
        "        return clip.fx(effect)\n",
        "    if hasattr(clip, \"with_effect\"):\n",
        "        return clip.with_effect(effect)\n",
        "    if hasattr(clip, \"with_fx\"):\n",
        "        return clip.with_fx(effect)\n",
        "    if hasattr(clip, \"with_effects\"):\n",
        "        return clip.with_effects([effect])\n",
        "    raise RuntimeError(\n",
        "        \"No recognised method to apply effects on this MoviePy build.\"\n",
        "    )\n",
        "\n",
        "# â”€â”€â”€ 1) audio_loop (works on any version) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def audio_loop(clip, *, duration=None, n=None):\n",
        "    \"\"\"Repeat *clip* until it reaches *duration* seconds or *n* loops.\"\"\"\n",
        "    # MoviePy â‰¤ 1.x still ships the old helper in afx\n",
        "    if getattr(afx, \"audio_loop\", None):\n",
        "        return afx.audio_loop(clip, duration=duration, n=n)\n",
        "\n",
        "    # MoviePy â‰¥ 2.0 effect class\n",
        "    try:\n",
        "        from moviepy.audio.fx.AudioLoop import AudioLoop\n",
        "        return _apply_fx(clip, AudioLoop(duration=duration, n=n))\n",
        "    except ModuleNotFoundError:\n",
        "        # Fallback: rely on the generic vfx.Loop (works on audio too)\n",
        "        return _apply_fx(clip, vfx.Loop(duration=duration, n=n))\n",
        "\n",
        "# â”€â”€â”€ 2) resize_fx  (handles .resize â‡† .resized rename)  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def resize_fx(clip, newsize):\n",
        "    \"\"\"Version-agnostic resize effect.\"\"\"\n",
        "    if hasattr(clip, \"resized\"):      # MoviePy â‰¥ 2.0\n",
        "        return clip.resized(newsize)\n",
        "    return clip.resize(newsize)       # MoviePy â‰¤ 1.x\n",
        "\n",
        "# â”€â”€â”€ 3) loop_fx  (video or audio) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def loop_fx(clip, *, duration=None, n=None):\n",
        "    \"\"\"Loop *clip* via the vfx.Loop effect, regardless of version.\"\"\"\n",
        "    return _apply_fx(clip, vfx.Loop(duration=duration, n=n))\n",
        "\n",
        "# â”€â”€â”€ 4) subclip_fx  (max-compat temporal trimming) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def subclip_fx(clip, start, end):\n",
        "    \"\"\"\n",
        "    Return a slice of *clip* between *start* â€“ *end* seconds, whatever\n",
        "    MoviePy version is installed.\n",
        "    \"\"\"\n",
        "    # A) Classic API  (MoviePy â‰¤â€†1.x   & most early 2.x dev builds)\n",
        "    if hasattr(clip, \"subclip\"):\n",
        "        return clip.subclip(start, end)\n",
        "\n",
        "    # B) Official 2.0+ method name\n",
        "    if hasattr(clip, \"time_slice\"):\n",
        "        return clip.time_slice(start_time=start, end_time=end)\n",
        "\n",
        "    # C) 2.0 snapshots that expose a Trim/Subclip *effect* class instead\n",
        "    try:\n",
        "        from moviepy.video.fx.Subclip import Subclip as _Subclip\n",
        "        return _apply_fx(clip, _Subclip(start_time=start, end_time=end))\n",
        "    except ModuleNotFoundError:\n",
        "        pass\n",
        "    try:\n",
        "        from moviepy.video.fx.trim import trim as _trim\n",
        "        return _trim(clip, start_time=start, end_time=end)\n",
        "    except ModuleNotFoundError:\n",
        "        pass\n",
        "\n",
        "    # D) Last-ditch fallback â€“ we're on some exotic build that renamed the API\n",
        "    if start == 0:\n",
        "        # 1) most historical versions\n",
        "        if hasattr(clip, \"set_duration\"):\n",
        "            return clip.set_duration(end)\n",
        "        # 2) MoviePy 2.0+ renamed setter\n",
        "        if hasattr(clip, \"with_duration\"):\n",
        "            return clip.with_duration(end)\n",
        "        # 3) extremely early 2.x snapshots used `with_end`\n",
        "        if hasattr(clip, \"with_end\"):\n",
        "            return clip.with_end(end)\n",
        "        # 4) give up â€“ at least return the original clip rather than crash\n",
        "        return clip\n",
        "    raise RuntimeError(\"No compatible subclip/time-slice implementation found\")\n",
        "\n",
        "# â”€â”€â”€ 5) crop_fx  (covers every naming convention so far) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def crop_fx(clip, **kwargs):\n",
        "    \"\"\"\n",
        "    Universal crop that works with MoviePy 1.x and 2.x.\n",
        "    Accepts the classic keyword args (x1, y1, x2, y2, width, heightâ€¦).\n",
        "    \"\"\"\n",
        "    # (a) Native instance methods first\n",
        "    if hasattr(clip, \"cropped\"):      # MoviePy â‰¥ 2.0 preferred\n",
        "        return clip.cropped(**kwargs)\n",
        "    if hasattr(clip, \"crop\"):         # MoviePy â‰¤ 1.x\n",
        "        return clip.crop(**kwargs)\n",
        "\n",
        "    # (b) New effect class (MoviePy â‰¥ 2.0 snapshots)\n",
        "    try:\n",
        "        from moviepy.video.fx.Crop import Crop as _Crop\n",
        "        return _apply_fx(clip, _Crop(**kwargs))\n",
        "    except ModuleNotFoundError:\n",
        "        pass\n",
        "\n",
        "    # (c) Very old functional helper\n",
        "    try:\n",
        "        from moviepy.video.fx.crop import crop as _crop_func\n",
        "        return _crop_func(clip, **kwargs)\n",
        "    except ModuleNotFoundError as e:\n",
        "        raise RuntimeError(\"No compatible crop implementation found\") from e\n",
        "\n",
        "# â”€â”€ editing code block end â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "# â”€â”€ imports needed by text-clip generator â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from freesound import FreesoundClient\n",
        "import requests\n",
        "\n",
        "# â”€â”€â”€ Font, canvas & divider settings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "text_font      = \"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\"\n",
        "text_fontsize  = 60\n",
        "W, H           = output_width, output_height\n",
        "half_h         = H // 2\n",
        "divider_height = 30                     # white bar thickness\n",
        "\n",
        "# â”€â”€â”€ 1) Top half: gameplay with 12 % crop, resize & loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "gameplay = VideoFileClip(\"gameplay_trimmed.mp4\")\n",
        "h_crop   = int(gameplay.h * 0.12)\n",
        "gameplay = crop_fx(gameplay, y1=h_crop, y2=gameplay.h - h_crop)\n",
        "gameplay = loop_fx(resize_fx(gameplay, (W, half_h)), duration=clip_duration)\n",
        "\n",
        "# â”€â”€â”€ 2) Bottom half: Pexels background â€“ squash to fit â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "videos  = search_pexels_videos(background_topic, per_page=pexels_per_search)\n",
        "paths   = [f\"clip_{i}.mp4\" for i, _ in enumerate(videos)]\n",
        "with ThreadPoolExecutor() as ex:\n",
        "    ex.map(lambda args: download_pexels_video(*args), zip(videos, paths))\n",
        "\n",
        "subclips, acc = [], 0\n",
        "for p in paths:\n",
        "    clip    = VideoFileClip(p)\n",
        "    remain  = clip_duration - acc\n",
        "    if remain <= 0:\n",
        "        break\n",
        "    take    = min(clip.duration, remain)\n",
        "    resized = resize_fx(clip, (W, half_h))\n",
        "    subclip = subclip_fx(resized, 0, take)  # Removed .set_duration()\n",
        "\n",
        "    # Version-agnostic duration setting\n",
        "    if hasattr(subclip, \"with_duration\"):\n",
        "        subclip = subclip.with_duration(take)\n",
        "    elif hasattr(subclip, \"set_duration\"):\n",
        "        subclip = subclip.set_duration(take)\n",
        "\n",
        "    subclips.append(subclip)\n",
        "    acc += take\n",
        "\n",
        "background_bottom = concatenate_videoclips(subclips, method=\"compose\") \\\n",
        "                    .set_duration(clip_duration)\n",
        "\n",
        "# â”€â”€â”€ 3) Divider: 30 px white bar at the seam â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "divider = ColorClip((W, divider_height), color=(255, 255, 255),\n",
        "                    duration=clip_duration).set_position(\n",
        "                    (\"center\", half_h - divider_height // 2))\n",
        "\n",
        "# â”€â”€â”€ 4) Text-clip generator  (now defined **before** first use) â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def make_text_clip(txt, duration, frame_size, font_path, fontsize,\n",
        "                   fill, position):\n",
        "    \"\"\"\n",
        "    Renders *txt* to a semi-transparent boxed overlay and returns a\n",
        "    MoviePy ImageClip sized to *frame_size*.\n",
        "    \"\"\"\n",
        "    font   = ImageFont.truetype(font_path, fontsize)\n",
        "    max_w  = int(frame_size[0] * 0.9)\n",
        "    avg_w  = font.getbbox(\"A\")[2]\n",
        "    wrap_w = max_w // avg_w\n",
        "    lines  = textwrap.wrap(txt, width=wrap_w)\n",
        "\n",
        "    # measure multiline block\n",
        "    dummy   = ImageDraw.Draw(Image.new(\"RGB\", (1, 1)))\n",
        "    bboxes  = [dummy.textbbox((0, 0), ln, font=font) for ln in lines]\n",
        "    widths  = [x1 - x0 for x0, _, x1, _ in bboxes]\n",
        "    heights = [y1 - y0 for _, y0, _, y1 in bboxes]\n",
        "    block_w = max(widths)  + 20\n",
        "    block_h = sum(heights) + 5 * (len(lines) - 1) + 20\n",
        "\n",
        "    # transparent RGBA canvas\n",
        "    img   = Image.new(\"RGBA\", frame_size, (0, 0, 0, 0))\n",
        "    draw  = ImageDraw.Draw(img)\n",
        "    x0,y0 = (frame_size[0] - block_w)//2, (frame_size[1] - block_h)//2\n",
        "    draw.rectangle([x0, y0, x0 + block_w, y0 + block_h], fill=(0, 0, 0, 128))\n",
        "\n",
        "    y = y0 + 10\n",
        "    for ln in lines:\n",
        "        w = draw.textbbox((0, 0), ln, font=font)[2]\n",
        "        draw.text((x0 + (block_w - w)//2, y), ln, font=font, fill=fill)\n",
        "        y += font.getbbox(ln)[3] - font.getbbox(ln)[1] + 5\n",
        "\n",
        "    return ImageClip(np.asarray(img)).set_duration(duration).set_position(position)\n",
        "\n",
        "# â”€â”€â”€ (the â€œBuild Synced Text Clipsâ€ loop begins right after this) â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "# (build text_clips â†’ outro â†’ composite â†’ background music â†’ export)\n",
        "# â”€â”€â”€ 5) Build Synced Text Clips â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "text_clips = []\n",
        "for idx, (fn, start) in enumerate(narration_files):\n",
        "    audio = AudioFileClip(fn)\n",
        "    duration = audio.duration\n",
        "    tc = make_text_clip(\n",
        "        flat_segments[idx][\"text\"],\n",
        "        duration,\n",
        "        (W, H),\n",
        "        text_font, text_fontsize,\n",
        "        \"white\", (\"center\",\"center\")\n",
        "    ).set_start(start).set_duration(duration)\n",
        "    text_clips.append(tc)\n",
        "\n",
        "# â”€â”€â”€ 6) Outro Clip â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "outro_txt_clip = make_text_clip(\n",
        "    outro_text, outro_duration, (W, H),\n",
        "    text_font, text_fontsize, \"white\", (\"center\",\"center\")\n",
        ")\n",
        "outro_bg = ColorClip((W, H), (0,0,0), duration=outro_duration)\n",
        "outro_clip = CompositeVideoClip([outro_bg, outro_txt_clip]).set_duration(outro_duration)\n",
        "\n",
        "# â”€â”€â”€ 7) Composite Split Screen â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "split = CompositeVideoClip(\n",
        "    [gameplay.set_position((\"center\",\"top\")),\n",
        "     background_bottom.set_position((\"center\",\"bottom\")),\n",
        "     divider] + text_clips,\n",
        "    size=(W, H)\n",
        ")\n",
        "video_final = concatenate_videoclips([split, outro_clip], method=\"compose\")\n",
        "\n",
        "# â”€â”€â”€ 8) Background Music â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "fs = FreesoundClient(); fs.set_token(\"SvkdYKjMtv5lFj5ojxbJ8MPA9dmr8okzsU9pOQIi\")\n",
        "def find_tracks(q, lic):\n",
        "    return fs.text_search(\n",
        "        query=f\"{q} music\", filter=f'license:\"{lic}\"',\n",
        "        sort=\"rating_desc\", fields=\"id,name,license,previews\",\n",
        "        per_page=10\n",
        "    ).results\n",
        "\n",
        "tracks = (\n",
        "    find_tracks(background_topic, \"Creative Commons 0\")\n",
        "    or find_tracks(background_topic, \"Creative Commons Attribution\")\n",
        "    or find_tracks(\"background music\", \"Creative Commons 0\")\n",
        ")\n",
        "\n",
        "if tracks:\n",
        "    snd = random.choice(tracks)\n",
        "    url = snd[\"previews\"].get(\"preview-hq-mp3\") or snd[\"previews\"].get(\"preview_hq_mp3\")\n",
        "    resp = requests.get(url)\n",
        "    with open(\"music.mp3\",\"wb\") as f:\n",
        "        f.write(resp.content)\n",
        "    bg_music = audio_loop(\n",
        "        AudioFileClip(\"music.mp3\").volumex(0.2),\n",
        "        duration=video_final.duration\n",
        "    )\n",
        "else:\n",
        "    bg_music = None\n",
        "\n",
        "# â”€â”€â”€ 9) Final Audio Mix â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "narr_clips = [AudioFileClip(fn).set_start(start) for fn, start in narration_files]\n",
        "audio_layers = narr_clips + ([bg_music] if bg_music else [])\n",
        "final_audio = CompositeAudioClip(audio_layers)\n",
        "final = video_final.set_audio(final_audio)\n",
        "\n",
        "# â”€â”€â”€ 10) Export â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "final.write_videofile(\n",
        "    \"shorts_final.mp4\",\n",
        "    codec=\"libx264\",\n",
        "    audio_codec=\"aac\",\n",
        "    threads=4,\n",
        "    preset=\"ultrafast\",\n",
        "    ffmpeg_params=[\"-crf\",\"23\"]\n",
        ")\n"
      ],
      "metadata": {
        "id": "WBCeHr1aHU1E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "d0eddc63-77f8-4f04-b74d-08135d4e0d54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'GAMEPLAY_URL'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-cfa752bcd110>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gameplay_trimmed.mp4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mfile_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"GAMEPLAY_URL\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"id=\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"gdown {file_id} -O {dst}\"\u001b[0m          \u001b[0;31m# --id flag deprecated in gdown â‰¥5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshlex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/os.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'GAMEPLAY_URL'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#@ğŸ“ 8. Generate Metadata"
      ],
      "metadata": {
        "id": "gQxaYloyApEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€ 8. Generate Metadata (title â‰  background_topic) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def generate_metadata(topic):\n",
        "    prompt = (\n",
        "        f\"Generate a YouTube Short title that is about '{topic}' \"\n",
        "        f\"but does NOT exactly match it. The title should be captivating or catchy and be a generalized title of the '{topic}'.  Then provide a concise description \"\n",
        "        f\"(under 100 words) and 5-6 relevant SEOâ€‘friendly tags, but always #trending, #fyp and #viral #viralshorts included (commaâ€‘separated).\"\n",
        "    )\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\":\"user\",\"content\":prompt}],\n",
        "        temperature=0.7, max_tokens=200\n",
        "    )\n",
        "    text = resp.choices[0].message.content.strip()\n",
        "\n",
        "    # Parse metadata\n",
        "    title, desc, tags = None, None, []\n",
        "    for line in text.splitlines():\n",
        "        low = line.lower()\n",
        "        if low.startswith(\"title:\"):\n",
        "            title = line.split(\":\",1)[1].strip()\n",
        "        if low.startswith(\"description:\"):\n",
        "            desc = line.split(\":\",1)[1].strip()\n",
        "        if low.startswith(\"tags:\"):\n",
        "            tags = [t.strip() for t in line.split(\":\",1)[1].split(\",\")]\n",
        "\n",
        "    # Ensure Shorts requirements\n",
        "    if \"#shorts\" not in [t.lower() for t in tags]:\n",
        "        tags.append(\"#shorts\")\n",
        "    if any(len(tag) > 25 for tag in tags):\n",
        "        tags = [tag[:25] for tag in tags]\n",
        "\n",
        "    return title, desc, tags\n",
        "\n",
        "title, description, tags = generate_metadata(background_topic)\n",
        "print(\"ğŸ“ Metadata:\\n \", title, \"\\n \", description, \"\\n \", tags)"
      ],
      "metadata": {
        "id": "EC2-DOmwApZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ“¤ 9. Upload to YouTube"
      ],
      "metadata": {
        "id": "Po9hWorbAtHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€ 9. Upload to YouTube â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "from googleapiclient.errors import HttpError\n",
        "import time, os\n",
        "\n",
        "def upload_video_to_youtube(\n",
        "    file_path, title, description, tags,\n",
        "    category_id=22, privacy=\"public\",\n",
        "    chunk_size=1024*1024, max_retries=5\n",
        "):\n",
        "    # Enforce Shorts requirements\n",
        "    if not any(t.lower() == \"#shorts\" for t in tags):\n",
        "        tags.append(\"#shorts\")\n",
        "\n",
        "    body = {\n",
        "        \"snippet\": {\n",
        "            \"title\": f\"{title} #shorts\",\n",
        "            \"description\": f\"{description}\\n\\n#shorts\",\n",
        "            \"tags\": tags,\n",
        "            \"categoryId\": str(category_id)\n",
        "        },\n",
        "        \"status\": {\n",
        "            \"privacyStatus\": privacy,\n",
        "            \"selfDeclaredMadeForKids\": False\n",
        "        },\n",
        "        \"contentDetails\": {\n",
        "            \"duration\": \"PT60S\"  # Force recognition as Short\n",
        "        }\n",
        "    }\n",
        "\n",
        "    media = MediaFileUpload(\n",
        "        file_path,\n",
        "        mimetype='video/mp4',\n",
        "        chunksize=chunk_size,\n",
        "        resumable=True\n",
        "    )\n",
        "\n",
        "    req = youtube.videos().insert(\n",
        "        part=\"snippet,status,contentDetails\",\n",
        "        body=body,\n",
        "        media_body=media\n",
        "    )\n",
        "\n",
        "    done = False\n",
        "    retry = 0\n",
        "    while not done:\n",
        "        try:\n",
        "            status, resp = req.next_chunk()\n",
        "            if status:\n",
        "                print(f\"ğŸŸ¢ {int(status.progress()*100)}% uploaded\")\n",
        "            else:\n",
        "                done = True\n",
        "        except HttpError as e:\n",
        "            if e.resp.status in [500,502,503,504] and retry < max_retries:\n",
        "                retry += 1\n",
        "                time.sleep(2**retry)\n",
        "                print(f\"âš ï¸ Retry {retry}\")\n",
        "            else:\n",
        "                raise\n",
        "\n",
        "    print(\"âœ… Upload complete! Video ID:\", resp[\"id\"])\n",
        "    return resp\n",
        "\n",
        "response = upload_video_to_youtube(\"shorts_final.mp4\", title, description, tags)\n",
        "print(\"ğŸ‰ Done! https://youtu.be/\" + response[\"id\"])"
      ],
      "metadata": {
        "id": "6Oy8j6CEAtcp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}