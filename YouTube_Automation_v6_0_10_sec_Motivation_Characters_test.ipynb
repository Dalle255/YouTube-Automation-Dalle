{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1️⃣ Secrets & API-key bootstrap"
      ],
      "metadata": {
        "id": "Rnt1zYKUtYy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ────────────────────────────────────────────────────────────────────────\n",
        "#  SECRETS → LOCAL FILES  |  runs before any other import\n",
        "# ────────────────────────────────────────────────────────────────────────\n",
        "import os, base64, pathlib, json\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "\n",
        "def _decode_and_validate(secret_name: str, out_file: str):\n",
        "    \"\"\"Decode Base64 GitHub secret and validate JSON structure.\"\"\"\n",
        "    try:\n",
        "        decoded = base64.b64decode(os.environ[secret_name]).decode('utf-8')\n",
        "        data = json.loads(decoded)\n",
        "\n",
        "        # For token.json, verify required fields\n",
        "        if out_file == \"token.json\":\n",
        "            required_fields = {'token', 'refresh_token', 'scopes'}\n",
        "            if not required_fields.issubset(data.keys()):\n",
        "                missing = required_fields - set(data.keys())\n",
        "                raise ValueError(f\"Missing required fields in token: {missing}\")\n",
        "\n",
        "        pathlib.Path(out_file).write_text(decoded)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error processing {secret_name}: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "try:\n",
        "    _decode_and_validate(\"CLIENT_SECRETS_JSON\", \"client_secrets.json\")\n",
        "    _decode_and_validate(\"TOKEN_JSON\", \"token.json\")\n",
        "except Exception as e:\n",
        "    print(\"❌ Failed to initialize secrets\")\n",
        "    raise\n",
        "\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]  # <-- add this line\n",
        "client = OpenAI()\n",
        "print(\"✅ Secrets decoded and validated, OpenAI client ready.\")\n"
      ],
      "metadata": {
        "id": "mGMYG1pYtZ2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2️⃣ Parameter cell"
      ],
      "metadata": {
        "id": "zMHzrGLkuV5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PARAMETERS  (Papermill / run-notebook overwrites these at run-time)\n",
        "GAMEPLAY_URL = None                         # GitHub secret injects real link\n",
        "TITLE_TEXT   = \"Daily DALLE Short\"          # you can override this too\n",
        "OPENAI_MODEL = \"gpt-4o\"\n"
      ],
      "metadata": {
        "id": "7LF15yK-ucTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔐 3. Authenticate with YouTube"
      ],
      "metadata": {
        "id": "SHzZ3v0lAbeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔐 2. Authenticate with YouTube (automatic – no browser needed)\n",
        "from google.oauth2.credentials import Credentials\n",
        "from google.auth.transport.requests import Request\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "import json\n",
        "\n",
        "# Use only the essential scope needed for uploads\n",
        "SCOPE = \"https://www.googleapis.com/auth/youtube.upload\"\n",
        "\n",
        "def get_authenticated_service():\n",
        "    \"\"\"Create authenticated YouTube client with scope validation.\"\"\"\n",
        "    try:\n",
        "        # Load token data\n",
        "        with open(\"token.json\") as f:\n",
        "            token_data = json.load(f)\n",
        "\n",
        "        # Verify the token has our required scope\n",
        "        if 'scopes' not in token_data or SCOPE not in token_data['scopes']:\n",
        "            raise ValueError(f\"Token missing required scope: {SCOPE}\")\n",
        "\n",
        "        creds = Credentials.from_authorized_user_info(token_data, [SCOPE])\n",
        "\n",
        "        # Refresh token if needed\n",
        "        if creds and creds.expired and creds.refresh_token:\n",
        "            try:\n",
        "                creds.refresh(Request())\n",
        "                # Update token file with refreshed credentials\n",
        "                with open(\"token.json\", \"w\") as f:\n",
        "                    json.dump(json.loads(creds.to_json()), f)\n",
        "            except Exception as refresh_error:\n",
        "                print(f\"⚠️ Token refresh failed: {refresh_error}\")\n",
        "                # Continue with expired token if we have one\n",
        "                if not creds.token:\n",
        "                    raise\n",
        "\n",
        "        return build(\"youtube\", \"v3\", credentials=creds)\n",
        "    except HttpError as e:\n",
        "        print(f\"❌ YouTube API error: {e}\")\n",
        "        raise\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Authentication failed: {e}\")\n",
        "        raise\n",
        "\n",
        "try:\n",
        "    youtube = get_authenticated_service()\n",
        "    print(f\"✅ YouTube API authenticated with scope: {SCOPE}\")\n",
        "except Exception as e:\n",
        "    print(\"❌ Failed to initialize YouTube client\")\n",
        "    raise"
      ],
      "metadata": {
        "id": "MPFDRFqu9iiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4-7: THIS IS WHERE WE BUILD OUR SHORTS DRAMA STORIES GENERATION CODE BLOCKS"
      ],
      "metadata": {
        "id": "_hFbm_U9oov0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BLOCK 1: QUOTES AND CHARACTERS LISTS"
      ],
      "metadata": {
        "id": "k0PAeTxubCRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOCK 1: QUOTES AND CHARACTERS LISTS\n",
        "\n",
        "import random\n",
        "\n",
        "# A long list of popular, meaningful, or motivational quotes (add more as you wish!)\n",
        "QUOTES_LIST = [\n",
        "    \"The only way to do great work is to love what you do.\",\n",
        "    \"Fall seven times, stand up eight.\",\n",
        "    \"The journey of a thousand miles begins with one step.\",\n",
        "    \"Success is not final, failure is not fatal: It is the courage to continue that counts.\",\n",
        "    \"You miss 100% of the shots you don’t take.\",\n",
        "    \"Believe you can and you’re halfway there.\",\n",
        "    \"Don’t watch the clock; do what it does. Keep going.\",\n",
        "    \"It does not matter how slowly you go as long as you do not stop.\",\n",
        "    \"Tough times never last, but tough people do.\",\n",
        "    \"Dream big and dare to fail.\",\n",
        "    \"Our greatest glory is not in never falling, but in rising every time we fall.\",\n",
        "    \"Your life does not get better by chance, it gets better by change.\",\n",
        "    \"Act as if what you do makes a difference. It does.\",\n",
        "    \"Happiness is not something ready made. It comes from your own actions.\",\n",
        "    \"When you arise in the morning, think of what a precious privilege it is to be alive.\",\n",
        "    \"Age is an issue of mind over matter. If you don't mind, it doesn't matter.\",\n",
        "    \"It's not the years in your life that count. It's the life in your years.\",\n",
        "    \"Strength does not come from physical capacity. It comes from an indomitable will.\",\n",
        "    \"To love and be loved is to feel the sun from both sides.\",\n",
        "    \"The best way to get started is to quit talking and begin doing.\",\n",
        "    \"Never let the fear of striking out keep you from playing the game.\",\n",
        "    \"Difficulties in life are intended to make us better, not bitter.\",\n",
        "    \"If you’re going through hell, keep going.\",\n",
        "    \"It always seems impossible until it’s done.\",\n",
        "    \"Grow through what you go through.\",\n",
        "    \"You must be the change you wish to see in the world.\",\n",
        "    \"The harder you work for something, the greater you’ll feel when you achieve it.\",\n",
        "    \"Let your smile change the world, but don’t let the world change your smile.\",\n",
        "    \"You don’t have to be great to start, but you have to start to be great.\",\n",
        "    \"Be yourself; everyone else is already taken.\",\n",
        "    # Add more as needed!\n",
        "]\n",
        "\n",
        "# A long, diverse list of characters (feel free to add or change)\n",
        "CHARACTERS_LIST = [\n",
        "    \"Yoda (Star Wars)\",\n",
        "    \"Pikachu (Pokémon)\",\n",
        "    \"Tony Soprano (The Sopranos, mafia boss)\",\n",
        "    \"Optimus Prime (Transformers)\",\n",
        "    \"Gandalf (Lord of the Rings)\",\n",
        "    \"SpongeBob SquarePants\",\n",
        "    \"Walter White (Breaking Bad)\",\n",
        "    \"Darth Vader\",\n",
        "    \"Sailor Moon\",\n",
        "    \"Bart Simpson\",\n",
        "    \"Iron Man\",\n",
        "    \"Dwayne 'The Rock' Johnson\",\n",
        "    \"Mickey Mouse\",\n",
        "    \"Mario (Super Mario Bros)\",\n",
        "    \"Batman\",\n",
        "    \"Shrek\",\n",
        "    \"Homer Simpson\",\n",
        "    \"Elsa (Frozen)\",\n",
        "    \"Rick Sanchez (Rick and Morty)\",\n",
        "    \"Naruto Uzumaki\",\n",
        "    \"Michael Scott (The Office)\",\n",
        "    \"Freddy Mercury\",\n",
        "    \"Vito Corleone (The Godfather, mafia boss)\",\n",
        "    \"Goku (Dragon Ball)\",\n",
        "    \"Scarlett O’Hara (Gone with the Wind)\",\n",
        "    \"Jack Sparrow\",\n",
        "    \"Hermione Granger (Harry Potter)\",\n",
        "    \"Mr. Bean\",\n",
        "    \"Bugs Bunny\",\n",
        "    \"Deadpool\",\n",
        "    \"Thanos\",\n",
        "    # Feel free to expand with more fun or niche characters!\n",
        "]\n",
        "\n",
        "# Function to select random quote and character\n",
        "def pick_random_quote_and_character():\n",
        "    quote = random.choice(QUOTES_LIST)\n",
        "    character = random.choice(CHARACTERS_LIST)\n",
        "    return quote, character\n",
        "\n",
        "selected_quote, selected_character = pick_random_quote_and_character()\n",
        "print(f\"Quote: {selected_quote}\\nCharacter: {selected_character}\")\n"
      ],
      "metadata": {
        "id": "757vuTPsgPBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BLOCK 2: GENERATE PERSONALIZED SCRIPT WITH GPT API"
      ],
      "metadata": {
        "id": "z2QKYSlPgSx8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_character_name(character):\n",
        "    return character.split('(')[0].strip()\n",
        "\n",
        "def generate_personalized_script(quote, character):\n",
        "    character_short = format_character_name(character)\n",
        "    system_prompt = (\n",
        "        f\"You are {character}, a famous character from media. You speak in their typical voice and style, \"\n",
        "        \"adapting advice and quotes to sound just like them. Your audience loves both wisdom and a bit of fun!\"\n",
        "    )\n",
        "    user_prompt = (\n",
        "        f'Intro: \"Hi there... Are you doing okay? Let {character_short} give you some advice.\"\\n\\n'\n",
        "        f'Please rephrase or remix the following motivational quote so it fits the personality, mood, '\n",
        "        f'speech pattern, and sense of humor (if any) of {character}. Use references, phrases, or quirks that fans will recognize.\\n\\n'\n",
        "        f'Quote: \"{quote}\"\\n\\n'\n",
        "        f'After the quote, add an outro line:\\n'\n",
        "        f'\"That\\'s right, you hear that!? Now go out there and make a wonderful day! '\n",
        "        f'See you next time when I say: \"\\n\\n'\n",
        "        f'Keep the total script short and natural (10 seconds when spoken).'\n",
        "    )\n",
        "    response = client.chat.completions.create(\n",
        "        model=OPENAI_MODEL,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_prompt}\n",
        "        ],\n",
        "        max_tokens=200,\n",
        "        temperature=0.9,\n",
        "    )\n",
        "    script = response.choices[0].message.content\n",
        "    return script\n",
        "\n",
        "script = generate_personalized_script(selected_quote, selected_character)\n",
        "print(script)\n"
      ],
      "metadata": {
        "id": "_jNF72nfgTek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3️⃣ Generate Relevant Images with DALL·E 3 (Segmented for Story)"
      ],
      "metadata": {
        "id": "g_MA9URBu3-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_dalle_image(prompt, filename):\n",
        "    response = client.images.generate(\n",
        "        model=\"dall-e-3\",\n",
        "        prompt=prompt,\n",
        "        n=1,\n",
        "        size=\"1024x1024\"\n",
        "    )\n",
        "    image_url = response.data[0].url\n",
        "    import requests\n",
        "    from PIL import Image\n",
        "    from io import BytesIO\n",
        "    img_data = requests.get(image_url).content\n",
        "    img = Image.open(BytesIO(img_data))\n",
        "    img.save(filename)\n",
        "    return filename\n",
        "\n",
        "def make_image_prompts(character, quote):\n",
        "    character_short = format_character_name(character)\n",
        "    prompt1 = (f\"Highly detailed portrait of {character_short}, in a visually stunning, cool, and uplifting setting, \"\n",
        "               f\"expressing the character's signature personality and mood. Cinematic, inspiring, sharp focus.\")\n",
        "    prompt2 = (f\"{character_short} explaining an important life lesson in their unique style, in a scene that visually fits the quote: '{quote}'. \"\n",
        "               \"The character is expressive, perhaps gesturing or in a teaching pose, with a motivational and positive atmosphere. Cinematic, high quality.\")\n",
        "    return [prompt1, prompt2]\n",
        "\n",
        "def generate_images_for_script(character, quote):\n",
        "    prompts = make_image_prompts(character, quote)\n",
        "    image_files = []\n",
        "    for i, prompt in enumerate(prompts):\n",
        "        filename = f\"character_scene_{i+1}.png\"\n",
        "        generate_dalle_image(prompt, filename)\n",
        "        image_files.append(filename)\n",
        "    return image_files\n",
        "\n",
        "IMAGE_FILES = generate_images_for_script(selected_character, selected_quote)\n",
        "print(\"Generated images:\", IMAGE_FILES)\n"
      ],
      "metadata": {
        "id": "StzkMgseu4zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4️⃣ Generate Narration with OpenAI TTS (Echo Voice)"
      ],
      "metadata": {
        "id": "C2DdVPtuu6X1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_tts_narration(script, output_path=\"narration.mp3\"):\n",
        "    voices = [\"fable\", \"onyx\", \"echo\"]\n",
        "    selected_voice = random.choice(voices)\n",
        "    print(f\"🎤 Selected TTS voice: {selected_voice}\")\n",
        "    tts_response = client.audio.speech.create(\n",
        "        model=\"tts-1\",\n",
        "        voice=selected_voice,\n",
        "        input=script,\n",
        "        response_format=\"mp3\"\n",
        "    )\n",
        "    tts_response.stream_to_file(output_path)\n",
        "    print(f\"Narration audio saved to {output_path}\")\n",
        "    return output_path\n",
        "\n",
        "NARRATION_AUDIO_PATH = generate_tts_narration(script)\n"
      ],
      "metadata": {
        "id": "NbaFuvA0u6xX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5️⃣ Generate Synced Subtitles (GPT for Chunks Matching Narration Timing)"
      ],
      "metadata": {
        "id": "zis51G8Ju-Hs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from aeneas.executetask import ExecuteTask\n",
        "from aeneas.task import Task\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "def split_text_into_max_lines(text, max_width_chars=25, max_lines=4):\n",
        "    import textwrap\n",
        "    wrapper = textwrap.TextWrapper(\n",
        "        width=max_width_chars,\n",
        "        break_long_words=True,\n",
        "        break_on_hyphens=True\n",
        "    )\n",
        "    lines = wrapper.wrap(text)\n",
        "    chunks = []\n",
        "    for i in range(0, len(lines), max_lines):\n",
        "        chunk = \"\\n\".join(lines[i:i + max_lines])\n",
        "        chunks.append(chunk)\n",
        "    return chunks\n",
        "\n",
        "def chunk_script_for_subtitles(script, narration_audio_path, max_width_chars=25, max_lines=4):\n",
        "    import json\n",
        "    with tempfile.NamedTemporaryFile(mode='w+', delete=False, suffix='.txt') as tf:\n",
        "        tf.write(script)\n",
        "        transcript_path = tf.name\n",
        "    config_string = u\"task_language=eng|is_text_type=plain|os_task_file_format=json\"\n",
        "    task = Task(config_string=config_string)\n",
        "    task.audio_file_path_absolute = narration_audio_path\n",
        "    task.text_file_path_absolute = transcript_path\n",
        "    task.sync_map_file_path_absolute = transcript_path + \".json\"\n",
        "    ExecuteTask(task).execute()\n",
        "    task.output_sync_map_file()\n",
        "    with open(task.sync_map_file_path_absolute, 'r') as f:\n",
        "        sync_map = json.load(f)\n",
        "    subtitle_timings = []\n",
        "    for fragment in sync_map[\"fragments\"]:\n",
        "        if not fragment[\"lines\"]: continue\n",
        "        text = fragment[\"lines\"][0].strip()\n",
        "        start = float(fragment[\"begin\"])\n",
        "        end = float(fragment[\"end\"])\n",
        "        duration = end - start\n",
        "        chunks = split_text_into_max_lines(text, max_width_chars=max_width_chars, max_lines=max_lines)\n",
        "        chunks = [chunk for chunk in chunks if chunk.strip()]\n",
        "        if not chunks:\n",
        "            continue\n",
        "        elif len(chunks) == 1:\n",
        "            subtitle_timings.append({\"text\": chunks[0], \"start\": start, \"end\": end})\n",
        "        else:\n",
        "            chunk_duration = duration / len(chunks)\n",
        "            for i, chunk in enumerate(chunks):\n",
        "                chunk_start = start + i * chunk_duration\n",
        "                chunk_end = chunk_start + chunk_duration\n",
        "                subtitle_timings.append({\"text\": chunk, \"start\": chunk_start, \"end\": chunk_end})\n",
        "    os.remove(transcript_path)\n",
        "    os.remove(task.sync_map_file_path_absolute)\n",
        "    return subtitle_timings\n",
        "\n",
        "SUBTITLES = chunk_script_for_subtitles(script, NARRATION_AUDIO_PATH)\n"
      ],
      "metadata": {
        "id": "ddfDpm_8u-5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6️⃣ Combine All Into Shorts Video (Images + Narration + Subtitles)"
      ],
      "metadata": {
        "id": "V9qTqlW5vAiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BLOCK 6: COMBINE EVERYTHING INTO SHORTS VIDEO WITH PERFECT SUBTITLES\n",
        "\n",
        "import sys\n",
        "\n",
        "if sys.platform.startswith(\"linux\"):\n",
        "    TEXT_FONT_PATH = \"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\"\n",
        "elif sys.platform.startswith(\"win\"):\n",
        "    TEXT_FONT_PATH = \"C:/Windows/Fonts/DejaVuSans-Bold.ttf\"\n",
        "else:\n",
        "    TEXT_FONT_PATH = \"DejaVuSans-Bold.ttf\"\n",
        "TEXT_FONTSIZE = 52\n",
        "\n",
        "def _set_duration(clip, duration):\n",
        "    if hasattr(clip, \"with_duration\"): return clip.with_duration(duration)\n",
        "    return clip.set_duration(duration)\n",
        "\n",
        "def _set_audio(clip, audio):\n",
        "    if hasattr(clip, \"with_audio\"): return clip.with_audio(audio)\n",
        "    return clip.set_audio(audio)\n",
        "\n",
        "def _set_position(clip, pos):\n",
        "    if hasattr(clip, \"with_position\"): return clip.with_position(pos)\n",
        "    return clip.set_position(pos)\n",
        "\n",
        "def _set_start(clip, start):\n",
        "    if hasattr(clip, \"with_start\"): return clip.with_start(start)\n",
        "    return clip.set_start(start)\n",
        "\n",
        "def resize_fx(clip, newsize):\n",
        "    if hasattr(clip, \"resized\"):\n",
        "        return clip.resized(newsize)\n",
        "    return clip.resize(newsize)\n",
        "\n",
        "from moviepy.editor import ImageClip, TextClip, CompositeVideoClip, concatenate_videoclips, AudioFileClip\n",
        "import textwrap\n",
        "\n",
        "def wrap_text_for_width(text, max_width_chars=25, max_lines=4):\n",
        "    \"\"\"Wrap text to fit within video frame width and limit to max_lines.\"\"\"\n",
        "    wrapper = textwrap.TextWrapper(\n",
        "        width=max_width_chars,\n",
        "        break_long_words=True,\n",
        "        break_on_hyphens=True,\n",
        "        max_lines=max_lines,\n",
        "        placeholder=' [...]'\n",
        "    )\n",
        "    return \"\\n\".join(wrapper.wrap(text))\n",
        "\n",
        "def robust_textclip(text, start, end, font_path, fontsize):\n",
        "    \"\"\"\n",
        "    Create a TextClip for subtitles, ensuring consistent formatting.\n",
        "    \"\"\"\n",
        "    duration = end - start\n",
        "    txt = None\n",
        "\n",
        "    # Wrap text to ensure it fits within frame and limits to max lines\n",
        "    wrapped_text = wrap_text_for_width(text, max_width_chars=25, max_lines=4)\n",
        "\n",
        "    # Try caption mode with proper size constraints\n",
        "    try:\n",
        "        txt = TextClip(\n",
        "            wrapped_text,\n",
        "            font_size=fontsize,\n",
        "            color='white',\n",
        "            method='caption',\n",
        "            size=(900, None)  # Max width for 1080px frame with margins\n",
        "        )\n",
        "        return txt\n",
        "    except Exception as e:\n",
        "        print(f\"[Subtitle/caption failover] {e}\")\n",
        "\n",
        "    # Try label mode with font, fontsize\n",
        "    try:\n",
        "        txt = TextClip(\n",
        "            wrapped_text,\n",
        "            fontsize=fontsize,\n",
        "            color='white',\n",
        "            font=font_path,\n",
        "            method='label'\n",
        "        )\n",
        "        return txt\n",
        "    except Exception as e:\n",
        "        print(f\"[Subtitle/label failover] {e}\")\n",
        "\n",
        "    # Try plain text, no font specified\n",
        "    try:\n",
        "        txt = TextClip(wrapped_text)\n",
        "        return txt\n",
        "    except Exception as e:\n",
        "        print(f\"[Subtitle/plain failover] {e}\")\n",
        "\n",
        "    # Last resort: Render text with Pillow, use ImageClip\n",
        "    try:\n",
        "        from PIL import Image, ImageDraw, ImageFont\n",
        "        import numpy as np\n",
        "\n",
        "        W, H = 900, 200  # Subtitle box (width, height)\n",
        "        bg_color = (0, 0, 0, 90)  # Semi-transparent background\n",
        "        fg_color = (255, 255, 255, 255)\n",
        "\n",
        "        # Load font, fallback to default PIL font if error\n",
        "        try:\n",
        "            font = ImageFont.truetype(font_path, fontsize)\n",
        "        except Exception as e:\n",
        "            print(f\"[Subtitle/Pillow] Can't load '{font_path}', using default font: {e}\")\n",
        "            font = ImageFont.load_default()\n",
        "\n",
        "        # Use the pre-wrapped text\n",
        "        final_text = wrapped_text\n",
        "\n",
        "        # Dummy image for measuring\n",
        "        dummy_img = Image.new(\"RGBA\", (W, H))\n",
        "        draw = ImageDraw.Draw(dummy_img)\n",
        "        bbox = draw.textbbox((0, 0), final_text, font=font)\n",
        "        text_width, text_height = bbox[2] - bbox[0], bbox[3] - bbox[1]\n",
        "\n",
        "        # Ensure text fits within our box width\n",
        "        if text_width > W - 40:  # 40px total margin\n",
        "            # If still too wide, try smaller font or more aggressive wrapping\n",
        "            scale_factor = (W - 40) / text_width\n",
        "            adjusted_fontsize = int(fontsize * scale_factor)\n",
        "            try:\n",
        "                font = ImageFont.truetype(font_path, adjusted_fontsize)\n",
        "            except:\n",
        "                font = ImageFont.load_default()\n",
        "\n",
        "        # Now render actual image with proper dimensions\n",
        "        margin_px = 60\n",
        "        img_height = max(H, text_height + 40 + margin_px)\n",
        "        img = Image.new('RGBA', (W, img_height), bg_color)\n",
        "        draw = ImageDraw.Draw(img)\n",
        "\n",
        "        # Center the text horizontally and vertically within the box\n",
        "        text_x = (W - text_width) // 2\n",
        "        text_y = (img_height - text_height - margin_px) // 2\n",
        "\n",
        "        draw.text(\n",
        "            (text_x, text_y),\n",
        "            final_text,\n",
        "            font=font,\n",
        "            fill=fg_color,\n",
        "            align='center'\n",
        "        )\n",
        "\n",
        "        np_img = np.array(img)\n",
        "        txt = ImageClip(np_img, duration=duration)\n",
        "        return txt\n",
        "    except Exception as e:\n",
        "        print(f\"[Subtitle/Pillow ultimate fail] {e}\")\n",
        "        raise RuntimeError(\"Subtitle TextClip/ImageClip creation failed with all methods.\")\n",
        "\n",
        "def create_shorts_video(IMAGE_FILES, NARRATION_AUDIO_PATH, SUBTITLES, output_path=\"shorts_final.mp4\"):\n",
        "    \"\"\"\n",
        "    Creates a 1080x1920 shorts video using your DALL·E images, TTS narration,\n",
        "    and perfectly synced subtitle overlays (top bar). Ready for YouTube Shorts.\n",
        "    \"\"\"\n",
        "    audio = AudioFileClip(NARRATION_AUDIO_PATH)\n",
        "    total_duration = audio.duration\n",
        "    num_images = len(IMAGE_FILES)\n",
        "    img_duration = total_duration / num_images\n",
        "\n",
        "    # Prepare image clips (robust resize for 1080x1920)\n",
        "    clips = []\n",
        "    for idx, img in enumerate(IMAGE_FILES):\n",
        "        base_clip = ImageClip(img)\n",
        "        base_clip = resize_fx(base_clip, (1080, 1920))\n",
        "        base_clip = _set_duration(base_clip, img_duration)\n",
        "        base_clip = _set_position(base_clip, 'center')\n",
        "        clips.append(base_clip)\n",
        "    video = concatenate_videoclips(clips, method=\"compose\")\n",
        "    video = _set_audio(video, audio)\n",
        "\n",
        "    # Prepare subtitle clips (positioned at top with small margin)\n",
        "    subtitle_clips = []\n",
        "    for sub in SUBTITLES:\n",
        "        txt = robust_textclip(\n",
        "            sub[\"text\"],\n",
        "            sub[\"start\"],\n",
        "            sub[\"end\"],\n",
        "            TEXT_FONT_PATH,\n",
        "            TEXT_FONTSIZE\n",
        "        )\n",
        "        txt = _set_start(txt, sub[\"start\"])\n",
        "        txt = _set_duration(txt, sub[\"end\"] - sub[\"start\"])\n",
        "        # Top bar position: 120px from top, centered\n",
        "        txt = _set_position(txt, (\"center\", 120))\n",
        "        # Only call margin if TextClip (not ImageClip)\n",
        "        if isinstance(txt, TextClip):\n",
        "            txt = txt.margin(top=10, opacity=0)\n",
        "        subtitle_clips.append(txt)\n",
        "\n",
        "    # Overlay subtitles on video\n",
        "    final = CompositeVideoClip([video] + subtitle_clips)\n",
        "    final.write_videofile(output_path, fps=24, codec=\"libx264\", audio_codec=\"aac\")\n",
        "    print(f\"Final shorts video saved to {output_path}\")\n",
        "    return output_path\n",
        "\n",
        "SHORTS_VIDEO_PATH = create_shorts_video(IMAGE_FILES, NARRATION_AUDIO_PATH, SUBTITLES)\n"
      ],
      "metadata": {
        "id": "r0sX0Rg7vCOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#@📝 8. Generate Metadata"
      ],
      "metadata": {
        "id": "gQxaYloyApEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_metadata_response(text):\n",
        "    title, desc, tags = None, None, []\n",
        "    for line in text.splitlines():\n",
        "        low = line.lower()\n",
        "        if low.startswith(\"title:\"):\n",
        "            title = line.split(\":\",1)[1].strip().strip(' \"\\'')\n",
        "            if title and not title[-1] in ('!', '?', '.'):\n",
        "                title += '!'\n",
        "        if low.startswith(\"description:\"):\n",
        "            desc = line.split(\":\",1)[1].strip()\n",
        "        if low.startswith(\"tags:\"):\n",
        "            tags = [t.strip() for t in line.split(\":\",1)[1].split(\",\")]\n",
        "    required_tags = [\"#shorts\", \"#short\",\"#Shortsviral\", \"fyp\", \"viralshorts\", \"viralnews\", \"globalnews\", \"#trending\", \"#youtubeshorts\"]\n",
        "    tags = [tag for tag in tags if tag]\n",
        "    for req_tag in required_tags:\n",
        "        if req_tag.lower() not in [t.lower() for t in tags]:\n",
        "            tags.append(req_tag)\n",
        "    tags = [tag[:25] for tag in tags if tag]\n",
        "    tags = list(set(tags))[:30]\n",
        "    return title, desc, tags\n",
        "\n",
        "def generate_metadata_from_story(story_text):\n",
        "    prompt = (\n",
        "        f\"You are an expert at viral YouTube Shorts. Given the following short story, create:\\n\"\n",
        "        \"1. A clickworthy, emotional TITLE (<85 chars) based on the most powerful moment, surprise, or twist (NO bland summaries, NO boring names, must create curiosity!) and include 2-3 relevant hashtags\\n\"\n",
        "        \"2. A DESCRIPTION (<3500 characters) of the story, opening with a main keyword, includes a call to action (Like/Comment/Share), ends with a question. Then add 20-30 relevant hashtags at the end.\\n\"\n",
        "        \"3. Around 30 SEO TAGS (comma-separated), mixing story keywords, emotional triggers, setting, and all required viral tags (#shorts, #youtubeshorts, etc).\\n\"\n",
        "        \"\\nStory:\\n\"\n",
        "        f\"{story_text}\\n\"\n",
        "        \"\\nFormat:\\n\"\n",
        "        \"Title: ...\\nDescription: ...\\nTags: ...\\n\"\n",
        "    )\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\":\"user\",\"content\":prompt}],\n",
        "        temperature=0.8,\n",
        "        max_tokens=3000\n",
        "    )\n",
        "    text = resp.choices[0].message.content.strip()\n",
        "    return parse_metadata_response(text)\n",
        "\n",
        "title, description, tags = generate_metadata_from_story(script)\n",
        "print(\"📝 Metadata:\\n \", title, \"\\n \", description, \"\\n \", tags)\n"
      ],
      "metadata": {
        "id": "EC2-DOmwApZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "📤 9. Upload to YouTube"
      ],
      "metadata": {
        "id": "Po9hWorbAtHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.http import MediaFileUpload\n",
        "from googleapiclient.errors import HttpError\n",
        "import time, os\n",
        "\n",
        "def upload_video_to_youtube(\n",
        "    file_path, title, description, tags,\n",
        "    category_id=22, privacy=\"public\",\n",
        "    chunk_size=1024*1024, max_retries=5\n",
        "):\n",
        "    if isinstance(tags, str):\n",
        "        tags = [t.strip() for t in tags.split(\",\") if t.strip()]\n",
        "    if not any(t.lower() == \"#shorts\" for t in tags):\n",
        "        tags.append(\"#shorts\")\n",
        "    body = {\n",
        "        \"snippet\": {\n",
        "            \"title\": title,\n",
        "            \"description\": f\"{description}\\n\\n#shorts\",\n",
        "            \"tags\": tags,\n",
        "            \"categoryId\": str(category_id)\n",
        "        },\n",
        "        \"status\": {\n",
        "            \"privacyStatus\": privacy,\n",
        "            \"selfDeclaredMadeForKids\": False\n",
        "        }\n",
        "    }\n",
        "    media = MediaFileUpload(\n",
        "        file_path,\n",
        "        mimetype='video/mp4',\n",
        "        chunksize=chunk_size,\n",
        "        resumable=True\n",
        "    )\n",
        "    req = youtube.videos().insert(\n",
        "        part=\"snippet,status\",\n",
        "        body=body,\n",
        "        media_body=media\n",
        "    )\n",
        "    done = False\n",
        "    retry = 0\n",
        "    while not done:\n",
        "        try:\n",
        "            status, resp = req.next_chunk()\n",
        "            if status:\n",
        "                print(f\"🟢 {int(status.progress()*100)}% uploaded\")\n",
        "            else:\n",
        "                done = True\n",
        "        except HttpError as e:\n",
        "            if e.resp.status in [500,502,503,504] and retry < max_retries:\n",
        "                retry += 1\n",
        "                time.sleep(2**retry)\n",
        "                print(f\"⚠️ Retry {retry}\")\n",
        "            else:\n",
        "                raise\n",
        "    print(\"✅ Upload complete! Video ID:\", resp['id'])\n",
        "    return resp\n",
        "\n",
        "response = upload_video_to_youtube(SHORTS_VIDEO_PATH, title, description, tags)\n",
        "print(\"🎉 Done! https://youtu.be/\" + response[\"id\"])\n"
      ],
      "metadata": {
        "id": "6Oy8j6CEAtcp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}