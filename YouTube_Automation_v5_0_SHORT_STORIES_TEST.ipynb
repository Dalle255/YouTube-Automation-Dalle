{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1️⃣ Secrets & API-key bootstrap"
      ],
      "metadata": {
        "id": "Rnt1zYKUtYy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ────────────────────────────────────────────────────────────────────────\n",
        "#  SECRETS → LOCAL FILES  |  runs before any other import\n",
        "# ────────────────────────────────────────────────────────────────────────\n",
        "import os, base64, pathlib, json\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "\n",
        "def _decode_and_validate(secret_name: str, out_file: str):\n",
        "    \"\"\"Decode Base64 GitHub secret and validate JSON structure.\"\"\"\n",
        "    try:\n",
        "        decoded = base64.b64decode(os.environ[secret_name]).decode('utf-8')\n",
        "        data = json.loads(decoded)\n",
        "\n",
        "        # For token.json, verify required fields\n",
        "        if out_file == \"token.json\":\n",
        "            required_fields = {'token', 'refresh_token', 'scopes'}\n",
        "            if not required_fields.issubset(data.keys()):\n",
        "                missing = required_fields - set(data.keys())\n",
        "                raise ValueError(f\"Missing required fields in token: {missing}\")\n",
        "\n",
        "        pathlib.Path(out_file).write_text(decoded)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error processing {secret_name}: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "try:\n",
        "    _decode_and_validate(\"CLIENT_SECRETS_JSON\", \"client_secrets.json\")\n",
        "    _decode_and_validate(\"TOKEN_JSON\", \"token.json\")\n",
        "except Exception as e:\n",
        "    print(\"❌ Failed to initialize secrets\")\n",
        "    raise\n",
        "\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]  # <-- add this line\n",
        "client = OpenAI()\n",
        "print(\"✅ Secrets decoded and validated, OpenAI client ready.\")\n"
      ],
      "metadata": {
        "id": "mGMYG1pYtZ2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2️⃣ Parameter cell"
      ],
      "metadata": {
        "id": "zMHzrGLkuV5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PARAMETERS  (Papermill / run-notebook overwrites these at run-time)\n",
        "GAMEPLAY_URL = None                         # GitHub secret injects real link\n",
        "TITLE_TEXT   = \"Daily DALLE Short\"          # you can override this too\n",
        "OPENAI_MODEL = \"gpt-4o\"\n"
      ],
      "metadata": {
        "id": "7LF15yK-ucTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔐 3. Authenticate with YouTube"
      ],
      "metadata": {
        "id": "SHzZ3v0lAbeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔐 2. Authenticate with YouTube (automatic – no browser needed)\n",
        "from google.oauth2.credentials import Credentials\n",
        "from google.auth.transport.requests import Request\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "import json\n",
        "\n",
        "# Use only the essential scope needed for uploads\n",
        "SCOPE = \"https://www.googleapis.com/auth/youtube.upload\"\n",
        "\n",
        "def get_authenticated_service():\n",
        "    \"\"\"Create authenticated YouTube client with scope validation.\"\"\"\n",
        "    try:\n",
        "        # Load token data\n",
        "        with open(\"token.json\") as f:\n",
        "            token_data = json.load(f)\n",
        "\n",
        "        # Verify the token has our required scope\n",
        "        if 'scopes' not in token_data or SCOPE not in token_data['scopes']:\n",
        "            raise ValueError(f\"Token missing required scope: {SCOPE}\")\n",
        "\n",
        "        creds = Credentials.from_authorized_user_info(token_data, [SCOPE])\n",
        "\n",
        "        # Refresh token if needed\n",
        "        if creds and creds.expired and creds.refresh_token:\n",
        "            try:\n",
        "                creds.refresh(Request())\n",
        "                # Update token file with refreshed credentials\n",
        "                with open(\"token.json\", \"w\") as f:\n",
        "                    json.dump(json.loads(creds.to_json()), f)\n",
        "            except Exception as refresh_error:\n",
        "                print(f\"⚠️ Token refresh failed: {refresh_error}\")\n",
        "                # Continue with expired token if we have one\n",
        "                if not creds.token:\n",
        "                    raise\n",
        "\n",
        "        return build(\"youtube\", \"v3\", credentials=creds)\n",
        "    except HttpError as e:\n",
        "        print(f\"❌ YouTube API error: {e}\")\n",
        "        raise\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Authentication failed: {e}\")\n",
        "        raise\n",
        "\n",
        "try:\n",
        "    youtube = get_authenticated_service()\n",
        "    print(f\"✅ YouTube API authenticated with scope: {SCOPE}\")\n",
        "except Exception as e:\n",
        "    print(\"❌ Failed to initialize YouTube client\")\n",
        "    raise"
      ],
      "metadata": {
        "id": "MPFDRFqu9iiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4-7: THIS IS WHERE WE BUILD OUR SHORTS DRAMA STORIES GENERATION CODE BLOCKS"
      ],
      "metadata": {
        "id": "_hFbm_U9oov0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1️⃣ Generate a Unique Story Seed (Topic)"
      ],
      "metadata": {
        "id": "FjxmsRiHux6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ───────────────────────────────────────────────────────────────\n",
        "# 1️⃣ Generate a unique seed/topic for each short story run\n",
        "\n",
        "import random\n",
        "\n",
        "def generate_story_seed():\n",
        "    # You can replace/expand this later with API calls or trending topic scrapers!\n",
        "    seed_topics = [\n",
        "        \"A young girl discovers a mysterious letter in her attic.\",\n",
        "        \"Two strangers meet on a train and share a secret.\",\n",
        "        \"A lost dog finds its way back home against all odds.\",\n",
        "        \"An old man recalls the day he saved a child's life.\",\n",
        "        \"A chance encounter changes the fate of an entire village.\",\n",
        "        \"A child finds an ancient artifact in the woods.\",\n",
        "        \"A teacher faces a dilemma after discovering a student's secret.\",\n",
        "        \"A musician hears a melody that no one else can.\",\n",
        "        \"A family reunites after years apart due to an unexpected event.\",\n",
        "        \"A janitor uncovers a hidden talent during a school talent show.\",\n",
        "        \"A shopkeeper helps a mysterious customer late at night.\"\n",
        "    ]\n",
        "    seed = random.choice(seed_topics)\n",
        "    print(f\"Selected story seed: {seed}\")\n",
        "    return seed\n",
        "\n",
        "STORY_SEED = generate_story_seed()\n"
      ],
      "metadata": {
        "id": "sVX2sFWeuzLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2️⃣ Generate a Short Story Script Using GPT-4o-mini"
      ],
      "metadata": {
        "id": "XFCg4YXou0hM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ───────────────────────────────────────────────────────────────\n",
        "# 2️⃣ Generate a short story script (30-40 seconds) with GPT-4o-mini (NEW API)\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "def generate_short_story(seed, example_story=None):\n",
        "    system_prompt = (\n",
        "        \"You are a creative short story writer. \"\n",
        "        \"Write a dramatic, emotional story suitable for a 30-40 second narration. \"\n",
        "        \"Your writing should be concise, with vivid imagery and a clear buildup and resolution. \"\n",
        "        \"Use simple language and dialogue where appropriate.\"\n",
        "    )\n",
        "    few_shot_example = (\n",
        "        example_story or\n",
        "    \"\"\"\n",
        "A boy was chased by the police. He ran very quickly into his house. His older brother saw him—his shirt and hands stained with blood. He was shocked. His brother was shaking in fear and could not speak.\n",
        "\n",
        "The older brother looked down from the window and saw a fleet of police cars, their sirens blaring.\n",
        "\n",
        "\"We're giving you five minutes to surrender!\" said a voice.\n",
        "\n",
        "He told his younger brother, \"Give me your shirt. I need to wash off the bloodstains.\"\n",
        "\n",
        "A few minutes later, the younger brother heard their back door slam. He looked and saw his older brother walking toward the police, wearing his shirt with hands in the air.\n",
        "\n",
        "He screamed with tears, \"What are you doing? No, Brother, no!\"\n",
        "\n",
        "They took him away.\n",
        "\n",
        "Days passed. It was his trial. His younger brother sat in the courtroom, tear-filled eyes watching his older brother being sentenced for life for a crime he knew nothing about.\n",
        "\n",
        "He couldn’t hold himself back. He ran to the judge and screamed, \"It was me! Please, leave my brother—he’s innocent!\" Tears streamed from his eyes.\n",
        "\n",
        "Then, suddenly, the police rushed in and showed CCTV footage proving the boy’s innocence. The real culprit had been caught.\n",
        "\n",
        "\"Why did you do that?\" he asked his older brother.\n",
        "\n",
        "He replied, \"I am your big brother. I’d give my life for you.\"\n",
        "    \"\"\"\n",
        "    )\n",
        "\n",
        "    prompt = (\n",
        "        f\"{system_prompt}\\n\"\n",
        "        f\"Example structure:\\n{few_shot_example}\\n\\n\"\n",
        "        f\"Now, write a unique story based on this topic:\\n\\\"{seed}\\\"\"\n",
        "    )\n",
        "\n",
        "    # Use the OpenAI client instance, with your API key already set via environment/secrets\n",
        "    client = OpenAI()  # This picks up your API key from the env\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        max_tokens=600,\n",
        "        temperature=1.0,\n",
        "    )\n",
        "    story_script = response.choices[0].message.content.strip()\n",
        "    print(f\"Generated short story:\\n{story_script}\")\n",
        "    return story_script\n",
        "\n",
        "STORY_SCRIPT = generate_short_story(STORY_SEED)\n"
      ],
      "metadata": {
        "id": "e2dL_Pbcu1rP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3️⃣ Generate Relevant Images with DALL·E 3 (Segmented for Story)"
      ],
      "metadata": {
        "id": "g_MA9URBu3-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ───────────────────────────────────────────────────────────────\n",
        "# 3️⃣ Generate relevant images for story segments using DALL·E 3 (NEW API + GPT prompt shortener)\n",
        "\n",
        "import math\n",
        "from PIL import Image, ImageOps\n",
        "import requests\n",
        "from openai import OpenAI\n",
        "import re\n",
        "\n",
        "def pad_to_vertical(img_path, target_size=(1080, 1920), fill_color=(0,0,0)):\n",
        "    img = Image.open(img_path)\n",
        "    img = ImageOps.contain(img, (target_size[0], target_size[1]), method=Image.LANCZOS)\n",
        "    pad_img = Image.new(\"RGB\", target_size, fill_color)\n",
        "    offset_x = (target_size[0] - img.width) // 2\n",
        "    offset_y = (target_size[1] - img.height) // 2\n",
        "    pad_img.paste(img, (offset_x, offset_y))\n",
        "    pad_img.save(img_path)\n",
        "    return img_path\n",
        "\n",
        "def split_script_for_images(script, num_images=1):\n",
        "    # Split by sentence, but group if short.\n",
        "    sentences = re.split(r'(?<=[.!?]) +', script)\n",
        "    avg = math.ceil(len(sentences) / num_images)\n",
        "    segments = [' '.join(sentences[i:i+avg]) for i in range(0, len(sentences), avg)]\n",
        "    if len(segments) > num_images:\n",
        "        segments = segments[:num_images]\n",
        "    return segments\n",
        "\n",
        "def get_visual_prompt(client, chunk):\n",
        "    \"\"\"Use GPT-4o-mini to generate a short, DALL·E-3-safe prompt.\"\"\"\n",
        "    prompt = (\n",
        "        \"Summarize the following story segment into a short, visually descriptive DALL·E-3 prompt. \"\n",
        "        \"Avoid names, violence, or explicit actions. Focus on the main scene, setting, and mood, under 15 words:\\n\"\n",
        "        f\"{chunk}\"\n",
        "    )\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an expert at generating concise, visual art prompts.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        max_tokens=50,\n",
        "        temperature=0.4,\n",
        "    )\n",
        "    short_prompt = resp.choices[0].message.content.strip()\n",
        "    short_prompt = short_prompt.strip('\"')\n",
        "    return short_prompt\n",
        "\n",
        "def generate_dalle3_images(story_script, num_images=6):\n",
        "    client = OpenAI()\n",
        "    segments = split_script_for_images(story_script, num_images)\n",
        "    image_files = []\n",
        "    for i, segment in enumerate(segments):\n",
        "        visual_prompt = get_visual_prompt(client, segment)\n",
        "        dalle_prompt = f\"Digital art, cinematic style, {visual_prompt}\"\n",
        "        print(f\"🖼️ Prompt for DALL·E image {i+1}: {dalle_prompt}\")\n",
        "        try:\n",
        "            response = client.images.generate(\n",
        "                model=\"dall-e-3\",\n",
        "                prompt=dalle_prompt,\n",
        "                n=1,\n",
        "                size=\"1024x1024\",\n",
        "                quality=\"standard\",\n",
        "                response_format=\"url\"\n",
        "            )\n",
        "            img_url = response.data[0].url\n",
        "            img_data = requests.get(img_url).content\n",
        "            img_path = f\"story_img_{i+1}.png\"\n",
        "            with open(img_path, \"wb\") as f:\n",
        "                f.write(img_data)\n",
        "            pad_to_vertical(img_path)\n",
        "            image_files.append(img_path)\n",
        "            print(f\"Generated image for segment {i+1}: {img_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ DALL·E image generation failed for segment {i+1}: {e}\")\n",
        "            continue  # Optionally: skip or use placeholder\n",
        "    return image_files, segments\n",
        "\n",
        "IMAGE_FILES, STORY_SEGMENTS = generate_dalle3_images(STORY_SCRIPT, num_images=6)\n"
      ],
      "metadata": {
        "id": "StzkMgseu4zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4️⃣ Generate Narration with OpenAI TTS (Echo Voice)"
      ],
      "metadata": {
        "id": "C2DdVPtuu6X1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ───────────────────────────────────────────────────────────────\n",
        "# 4️⃣ Generate TTS narration using OpenAI tts-1 (echo voice, NEW API)\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "def generate_tts_narration(story_script, output_path=\"narration.mp3\"):\n",
        "    client = OpenAI()  # Uses API key from environment\n",
        "    tts_response = client.audio.speech.create(\n",
        "        model=\"tts-1\",\n",
        "        voice=\"echo\",\n",
        "        input=story_script,\n",
        "        response_format=\"mp3\"\n",
        "    )\n",
        "    tts_response.stream_to_file(output_path)\n",
        "    print(f\"Narration audio saved to {output_path}\")\n",
        "    return output_path\n",
        "\n",
        "NARRATION_AUDIO_PATH = generate_tts_narration(STORY_SCRIPT)\n"
      ],
      "metadata": {
        "id": "NbaFuvA0u6xX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5️⃣ Generate Synced Subtitles (GPT for Chunks Matching Narration Timing)"
      ],
      "metadata": {
        "id": "zis51G8Ju-Hs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ───────────────────────────────────────────────────────────────\n",
        "# 5️⃣ Generate subtitle chunks using GPT and sync to narration (NEW API)\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "def chunk_script_for_subtitles(story_script, narration_path, max_words=8):\n",
        "    client = OpenAI()  # Uses your env API key\n",
        "\n",
        "    # First, split script into small chunks using GPT\n",
        "    chunk_prompt = (\n",
        "        \"Split the following story into short, natural subtitle lines, \"\n",
        "        f\"each with no more than {max_words} words. \"\n",
        "        \"Return the result as a Python list of strings.\"\n",
        "    )\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"{chunk_prompt}\\n\\nStory:\\n{story_script}\"}\n",
        "        ],\n",
        "        max_tokens=512,\n",
        "        temperature=0.2,\n",
        "    )\n",
        "    import ast\n",
        "    raw_chunks = response.choices[0].message.content.strip()\n",
        "    try:\n",
        "        subtitle_chunks = ast.literal_eval(raw_chunks)\n",
        "    except Exception:\n",
        "        # fallback: naive split\n",
        "        subtitle_chunks = story_script.split('. ')\n",
        "    print(\"Subtitle chunks generated:\", subtitle_chunks)\n",
        "    # Now, get narration duration and assign times\n",
        "    from mutagen.mp3 import MP3\n",
        "    audio = MP3(narration_path)\n",
        "    total_duration = audio.info.length\n",
        "    per_chunk = total_duration / len(subtitle_chunks)\n",
        "    subtitle_timings = []\n",
        "    for idx, chunk in enumerate(subtitle_chunks):\n",
        "        start = idx * per_chunk\n",
        "        end = start + per_chunk\n",
        "        subtitle_timings.append({\"text\": chunk, \"start\": start, \"end\": end})\n",
        "    return subtitle_timings\n",
        "\n",
        "# Install mutagen for MP3 duration reading if needed\n",
        "!pip install mutagen --quiet\n",
        "\n",
        "SUBTITLES = chunk_script_for_subtitles(STORY_SCRIPT, NARRATION_AUDIO_PATH)\n"
      ],
      "metadata": {
        "id": "ddfDpm_8u-5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6️⃣ Combine All Into Shorts Video (Images + Narration + Subtitles)"
      ],
      "metadata": {
        "id": "V9qTqlW5vAiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ───────────────────────────────────────────────────────────────\n",
        "# Font & Size setup (insert above video function, can go right at the top of this cell)\n",
        "import sys\n",
        "\n",
        "if sys.platform.startswith(\"linux\"):\n",
        "    TEXT_FONT_PATH = \"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\"\n",
        "elif sys.platform.startswith(\"win\"):\n",
        "    TEXT_FONT_PATH = \"C:/Windows/Fonts/DejaVuSans-Bold.ttf\"\n",
        "else:\n",
        "    TEXT_FONT_PATH = \"DejaVuSans-Bold.ttf\"\n",
        "TEXT_FONTSIZE = 60\n",
        "\n",
        "# Robust timeline and resize helpers for MoviePy 1.x and 2.x\n",
        "def _set_duration(clip, duration):\n",
        "    if hasattr(clip, \"with_duration\"): return clip.with_duration(duration)\n",
        "    return clip.set_duration(duration)\n",
        "\n",
        "def _set_audio(clip, audio):\n",
        "    if hasattr(clip, \"with_audio\"): return clip.with_audio(audio)\n",
        "    return clip.set_audio(audio)\n",
        "\n",
        "def _set_position(clip, pos):\n",
        "    if hasattr(clip, \"with_position\"): return clip.with_position(pos)\n",
        "    return clip.set_position(pos)\n",
        "\n",
        "def _set_start(clip, start):\n",
        "    if hasattr(clip, \"with_start\"): return clip.with_start(start)\n",
        "    return clip.set_start(start)\n",
        "\n",
        "def resize_fx(clip, newsize):\n",
        "    # newsize: (width, height)\n",
        "    if hasattr(clip, \"resized\"):\n",
        "        return clip.resized(newsize)\n",
        "    return clip.resize(newsize)\n",
        "\n",
        "# --- Robust imports ---\n",
        "from moviepy import ImageClip, TextClip, CompositeVideoClip, concatenate_videoclips, AudioFileClip\n",
        "\n",
        "def create_shorts_video(image_files, narration_path, subtitles, output_path=\"shorts_final.mp4\"):\n",
        "    audio = AudioFileClip(narration_path)\n",
        "    total_duration = audio.duration\n",
        "    num_images = len(image_files)\n",
        "    img_duration = total_duration / num_images\n",
        "\n",
        "    # Prepare image clips (robust resize)\n",
        "    clips = []\n",
        "    for idx, img in enumerate(image_files):\n",
        "        base_clip = ImageClip(img)\n",
        "        base_clip = resize_fx(base_clip, (1080, 1920))\n",
        "        base_clip = _set_duration(base_clip, img_duration)\n",
        "        base_clip = _set_position(base_clip, 'center')\n",
        "        clips.append(base_clip)\n",
        "    video = concatenate_videoclips(clips, method=\"compose\")\n",
        "    video = _set_audio(video, audio)\n",
        "\n",
        "    # Prepare subtitle clips (fade in/out for nicer effect)\n",
        "    subtitle_clips = []\n",
        "    for sub in subtitles:\n",
        "        txt = TextClip(\n",
        "            sub[\"text\"],\n",
        "            fontsize=TEXT_FONTSIZE,\n",
        "            color='white',\n",
        "            bg_color=\"black\",\n",
        "            method='caption',\n",
        "            size=(1000, None),\n",
        "            align='center'\n",
        "        )\n",
        "        # Note: Removed 'font=TEXT_FONT_PATH' for 'caption' mode compatibility!\n",
        "        txt = _set_start(txt, sub[\"start\"])\n",
        "        txt = _set_duration(txt, sub[\"end\"] - sub[\"start\"])\n",
        "        txt = _set_position(txt, (\"center\", \"bottom\")).margin(bottom=60, opacity=0)\n",
        "        subtitle_clips.append(txt)\n",
        "\n",
        "    # Overlay subtitles\n",
        "    final = CompositeVideoClip([video] + subtitle_clips)\n",
        "    final.write_videofile(output_path, fps=24, codec=\"libx264\", audio_codec=\"aac\")\n",
        "    print(f\"Final shorts video saved to {output_path}\")\n",
        "    return output_path\n",
        "\n",
        "SHORTS_VIDEO_PATH = create_shorts_video(IMAGE_FILES, NARRATION_AUDIO_PATH, SUBTITLES)\n"
      ],
      "metadata": {
        "id": "r0sX0Rg7vCOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#@📝 8. Generate Metadata"
      ],
      "metadata": {
        "id": "gQxaYloyApEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── 8. Generate Metadata (title ≠ background_topic) ───────────────────────\n",
        "def generate_metadata(topic):\n",
        "    prompt = (\n",
        "        f\"Generate a YouTube Short title about '{topic}' that follows these rules:\\n\"\n",
        "        \"1. Use emotional triggers (shock, curiosity, awe) and keep under 40 characters\\n\"\n",
        "        \"2. Include numbers/superlatives when possible without being clickbaity\\n\"\n",
        "        \"3. Don't exactly match the topic but remain highly relevant\\n\\n\"\n",
        "        \"Then provide a description that:\\n\"\n",
        "        \"1. Starts with the most important keyword\\n\"\n",
        "        \"2. Includes a CTA (Like/Follow/Comment)\\n\"\n",
        "        \"3. Is under 100 words with 2-3 hashtags in first line\\n\\n\"\n",
        "        \"Finally provide 20-30 specific SEO tags (comma-separated) including:\\n\"\n",
        "        \"1. 2-3 exact match keyword phrases\\n\"\n",
        "        \"2. 2-3 related niche terms\\n\"\n",
        "        \"3. These required tags: #shorts #short #youtubeshorts #viralshorts #shortsfeed\"\n",
        "    )\n",
        "\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\":\"user\",\"content\":prompt}],\n",
        "        temperature=0.85,  # Slightly more creative\n",
        "        max_tokens=300,    # Allow more length\n",
        "        presence_penalty=0.5  # Encourages diverse terms\n",
        "    )\n",
        "    text = resp.choices[0].message.content.strip()\n",
        "\n",
        "    # Parse metadata (keeping same structure)\n",
        "    title, desc, tags = None, None, []\n",
        "    for line in text.splitlines():\n",
        "        low = line.lower()\n",
        "        if low.startswith(\"title:\"):\n",
        "            title = line.split(\":\",1)[1].strip()\n",
        "            # Remove surrounding quotes if present\n",
        "            title = title.strip(' \"\\'')\n",
        "            # Add engagement punctuation if missing\n",
        "            if title and not title[-1] in ('!', '?', '.'):\n",
        "                title += '!'\n",
        "        if low.startswith(\"description:\"):\n",
        "            desc = line.split(\":\",1)[1].strip()\n",
        "            # Enhance description format if exists\n",
        "            if desc:\n",
        "                desc = f\"{desc}\\n\\n🔥 Like for more!\\n💬 Comment your thoughts!\"\n",
        "                desc = desc[:500]  # Ensure under character limit\n",
        "        if low.startswith(\"tags:\"):\n",
        "            tags = [t.strip() for t in line.split(\":\",1)[1].split(\",\")]\n",
        "\n",
        "    # Ensure Shorts requirements (maintaining same checks)\n",
        "    tags = [tag for tag in tags if tag]  # Remove empty tags\n",
        "    required_tags = [\"#shorts\", \"#short\",\"#Shortsviral\", \"fyp\", \"viralshorts\", \"viralnews\", \"globalnews\", \"#trending\", \"#youtubeshorts\"]\n",
        "    for req_tag in required_tags:\n",
        "        if req_tag not in [t.lower() for t in tags]:\n",
        "            tags.append(req_tag)\n",
        "    # Clean tags\n",
        "    tags = [tag[:25] for tag in tags if tag]  # Length limit and remove empties\n",
        "    tags = list(set(tags))[:30]  # Deduplicate and limit to 30 tags\n",
        "\n",
        "    return title, desc, tags\n",
        "\n",
        "title, description, tags = generate_metadata(background_topic)\n",
        "print(\"📝 Metadata:\\n \", title, \"\\n \", description, \"\\n \", tags)\n"
      ],
      "metadata": {
        "id": "EC2-DOmwApZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "📤 9. Upload to YouTube"
      ],
      "metadata": {
        "id": "Po9hWorbAtHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── 9. Upload to YouTube ───────────────────────────────────────────────\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "from googleapiclient.errors import HttpError\n",
        "import time, os\n",
        "\n",
        "def upload_video_to_youtube(\n",
        "    file_path, title, description, tags,\n",
        "    category_id=22, privacy=\"public\",\n",
        "    chunk_size=1024*1024, max_retries=5\n",
        "):\n",
        "    # Enforce Shorts requirements\n",
        "    if not any(t.lower() == \"#shorts\" for t in tags):\n",
        "        tags.append(\"#shorts\")\n",
        "\n",
        "    body = {\n",
        "        \"snippet\": {\n",
        "            \"title\": title,  # Removed #shorts append\n",
        "            \"description\": f\"{description}\\n\\n#shorts\",  # Kept in description\n",
        "            \"tags\": tags,\n",
        "            \"categoryId\": str(category_id)\n",
        "        },\n",
        "        \"status\": {\n",
        "            \"privacyStatus\": privacy,\n",
        "            \"selfDeclaredMadeForKids\": False\n",
        "        },\n",
        "        \"contentDetails\": {\n",
        "            \"duration\": \"PT60S\"  # Force recognition as Short\n",
        "        }\n",
        "    }\n",
        "\n",
        "    media = MediaFileUpload(\n",
        "        file_path,\n",
        "        mimetype='video/mp4',\n",
        "        chunksize=chunk_size,\n",
        "        resumable=True\n",
        "    )\n",
        "\n",
        "    req = youtube.videos().insert(\n",
        "        part=\"snippet,status,contentDetails\",\n",
        "        body=body,\n",
        "        media_body=media\n",
        "    )\n",
        "\n",
        "    done = False\n",
        "    retry = 0\n",
        "    while not done:\n",
        "        try:\n",
        "            status, resp = req.next_chunk()\n",
        "            if status:\n",
        "                print(f\"🟢 {int(status.progress()*100)}% uploaded\")\n",
        "            else:\n",
        "                done = True\n",
        "        except HttpError as e:\n",
        "            if e.resp.status in [500,502,503,504] and retry < max_retries:\n",
        "                retry += 1\n",
        "                time.sleep(2**retry)\n",
        "                print(f\"⚠️ Retry {retry}\")\n",
        "            else:\n",
        "                raise\n",
        "\n",
        "    print(\"✅ Upload complete! Video ID:\", resp[\"id\"])\n",
        "    return resp\n",
        "\n",
        "response = upload_video_to_youtube(\"shorts_final.mp4\", title, description, tags)\n",
        "print(\"🎉 Done! https://youtu.be/\" + response[\"id\"])"
      ],
      "metadata": {
        "id": "6Oy8j6CEAtcp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}