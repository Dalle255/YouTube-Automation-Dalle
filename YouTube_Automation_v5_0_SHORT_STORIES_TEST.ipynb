{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1️⃣ Secrets & API-key bootstrap"
      ],
      "metadata": {
        "id": "Rnt1zYKUtYy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ────────────────────────────────────────────────────────────────────────\n",
        "#  SECRETS → LOCAL FILES  |  runs before any other import\n",
        "# ────────────────────────────────────────────────────────────────────────\n",
        "import os, base64, pathlib, json\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "\n",
        "def _decode_and_validate(secret_name: str, out_file: str):\n",
        "    \"\"\"Decode Base64 GitHub secret and validate JSON structure.\"\"\"\n",
        "    try:\n",
        "        decoded = base64.b64decode(os.environ[secret_name]).decode('utf-8')\n",
        "        data = json.loads(decoded)\n",
        "\n",
        "        # For token.json, verify required fields\n",
        "        if out_file == \"token.json\":\n",
        "            required_fields = {'token', 'refresh_token', 'scopes'}\n",
        "            if not required_fields.issubset(data.keys()):\n",
        "                missing = required_fields - set(data.keys())\n",
        "                raise ValueError(f\"Missing required fields in token: {missing}\")\n",
        "\n",
        "        pathlib.Path(out_file).write_text(decoded)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error processing {secret_name}: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "try:\n",
        "    _decode_and_validate(\"CLIENT_SECRETS_JSON\", \"client_secrets.json\")\n",
        "    _decode_and_validate(\"TOKEN_JSON\", \"token.json\")\n",
        "except Exception as e:\n",
        "    print(\"❌ Failed to initialize secrets\")\n",
        "    raise\n",
        "\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]  # <-- add this line\n",
        "client = OpenAI()\n",
        "print(\"✅ Secrets decoded and validated, OpenAI client ready.\")\n"
      ],
      "metadata": {
        "id": "mGMYG1pYtZ2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2️⃣ Parameter cell"
      ],
      "metadata": {
        "id": "zMHzrGLkuV5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PARAMETERS  (Papermill / run-notebook overwrites these at run-time)\n",
        "GAMEPLAY_URL = None                         # GitHub secret injects real link\n",
        "TITLE_TEXT   = \"Daily DALLE Short\"          # you can override this too\n",
        "OPENAI_MODEL = \"gpt-4o\"\n"
      ],
      "metadata": {
        "id": "7LF15yK-ucTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔐 3. Authenticate with YouTube"
      ],
      "metadata": {
        "id": "SHzZ3v0lAbeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔐 2. Authenticate with YouTube (automatic – no browser needed)\n",
        "from google.oauth2.credentials import Credentials\n",
        "from google.auth.transport.requests import Request\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "import json\n",
        "\n",
        "# Use only the essential scope needed for uploads\n",
        "SCOPE = \"https://www.googleapis.com/auth/youtube.upload\"\n",
        "\n",
        "def get_authenticated_service():\n",
        "    \"\"\"Create authenticated YouTube client with scope validation.\"\"\"\n",
        "    try:\n",
        "        # Load token data\n",
        "        with open(\"token.json\") as f:\n",
        "            token_data = json.load(f)\n",
        "\n",
        "        # Verify the token has our required scope\n",
        "        if 'scopes' not in token_data or SCOPE not in token_data['scopes']:\n",
        "            raise ValueError(f\"Token missing required scope: {SCOPE}\")\n",
        "\n",
        "        creds = Credentials.from_authorized_user_info(token_data, [SCOPE])\n",
        "\n",
        "        # Refresh token if needed\n",
        "        if creds and creds.expired and creds.refresh_token:\n",
        "            try:\n",
        "                creds.refresh(Request())\n",
        "                # Update token file with refreshed credentials\n",
        "                with open(\"token.json\", \"w\") as f:\n",
        "                    json.dump(json.loads(creds.to_json()), f)\n",
        "            except Exception as refresh_error:\n",
        "                print(f\"⚠️ Token refresh failed: {refresh_error}\")\n",
        "                # Continue with expired token if we have one\n",
        "                if not creds.token:\n",
        "                    raise\n",
        "\n",
        "        return build(\"youtube\", \"v3\", credentials=creds)\n",
        "    except HttpError as e:\n",
        "        print(f\"❌ YouTube API error: {e}\")\n",
        "        raise\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Authentication failed: {e}\")\n",
        "        raise\n",
        "\n",
        "try:\n",
        "    youtube = get_authenticated_service()\n",
        "    print(f\"✅ YouTube API authenticated with scope: {SCOPE}\")\n",
        "except Exception as e:\n",
        "    print(\"❌ Failed to initialize YouTube client\")\n",
        "    raise"
      ],
      "metadata": {
        "id": "MPFDRFqu9iiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4-7: THIS IS WHERE WE BUILD OUR SHORTS DRAMA STORIES GENERATION CODE BLOCKS"
      ],
      "metadata": {
        "id": "_hFbm_U9oov0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1️⃣ Generate a Unique Story Seed (Topic)"
      ],
      "metadata": {
        "id": "FjxmsRiHux6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ───────────────────────────────────────────────────────────────\n",
        "# 1️⃣ Generate a unique seed/topic for each short story run\n",
        "\n",
        "import random\n",
        "\n",
        "def generate_story_seed():\n",
        "    # You can replace/expand this later with API calls or trending topic scrapers!\n",
        "    seed_topics = [\n",
        "        \"A young girl discovers a mysterious letter in her attic.\",\n",
        "        \"Two strangers meet on a train and share a secret.\",\n",
        "        \"A lost dog finds its way back home against all odds.\",\n",
        "        \"An old man recalls the day he saved a child's life.\",\n",
        "        \"A chance encounter changes the fate of an entire village.\",\n",
        "        \"A child finds an ancient artifact in the woods.\",\n",
        "        \"A teacher faces a dilemma after discovering a student's secret.\",\n",
        "        \"A musician hears a melody that no one else can.\",\n",
        "        \"A family reunites after years apart due to an unexpected event.\",\n",
        "        \"A janitor uncovers a hidden talent during a school talent show.\",\n",
        "        \"A shopkeeper helps a mysterious customer late at night.\"\n",
        "    ]\n",
        "    seed = random.choice(seed_topics)\n",
        "    print(f\"Selected story seed: {seed}\")\n",
        "    return seed\n",
        "\n",
        "STORY_SEED = generate_story_seed()\n"
      ],
      "metadata": {
        "id": "sVX2sFWeuzLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2️⃣ Generate a Short Story Script Using GPT-4o-mini"
      ],
      "metadata": {
        "id": "XFCg4YXou0hM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ───────────────────────────────────────────────────────────────\n",
        "# 2️⃣ Generate a short story script (30-40 seconds) with GPT-4o-mini (NEW API)\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "def generate_short_story(seed, example_story=None):\n",
        "    system_prompt = (\n",
        "        \"You are a creative short story writer. \"\n",
        "        \"Write a dramatic, emotional story suitable for a 30-40 second narration. \"\n",
        "        \"Your writing should be concise, with vivid imagery and a clear buildup and resolution. \"\n",
        "        \"Use simple language and dialogue where appropriate.\"\n",
        "    )\n",
        "    few_shot_example = (\n",
        "        example_story or\n",
        "    \"\"\"\n",
        "A boy was chased by the police. He ran very quickly into his house. His older brother saw him—his shirt and hands stained with blood. He was shocked. His brother was shaking in fear and could not speak.\n",
        "\n",
        "The older brother looked down from the window and saw a fleet of police cars, their sirens blaring.\n",
        "\n",
        "\"We're giving you five minutes to surrender!\" said a voice.\n",
        "\n",
        "He told his younger brother, \"Give me your shirt. I need to wash off the bloodstains.\"\n",
        "\n",
        "A few minutes later, the younger brother heard their back door slam. He looked and saw his older brother walking toward the police, wearing his shirt with hands in the air.\n",
        "\n",
        "He screamed with tears, \"What are you doing? No, Brother, no!\"\n",
        "\n",
        "They took him away.\n",
        "\n",
        "Days passed. It was his trial. His younger brother sat in the courtroom, tear-filled eyes watching his older brother being sentenced for life for a crime he knew nothing about.\n",
        "\n",
        "He couldn’t hold himself back. He ran to the judge and screamed, \"It was me! Please, leave my brother—he’s innocent!\" Tears streamed from his eyes.\n",
        "\n",
        "Then, suddenly, the police rushed in and showed CCTV footage proving the boy’s innocence. The real culprit had been caught.\n",
        "\n",
        "\"Why did you do that?\" he asked his older brother.\n",
        "\n",
        "He replied, \"I am your big brother. I’d give my life for you.\"\n",
        "    \"\"\"\n",
        "    )\n",
        "\n",
        "    prompt = (\n",
        "        f\"{system_prompt}\\n\"\n",
        "        f\"Example structure:\\n{few_shot_example}\\n\\n\"\n",
        "        f\"Now, write a unique story based on this topic:\\n\\\"{seed}\\\"\"\n",
        "    )\n",
        "\n",
        "    # Use the OpenAI client instance, with your API key already set via environment/secrets\n",
        "    client = OpenAI()  # This picks up your API key from the env\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        max_tokens=600,\n",
        "        temperature=1.0,\n",
        "    )\n",
        "    story_script = response.choices[0].message.content.strip()\n",
        "    print(f\"Generated short story:\\n{story_script}\")\n",
        "    return story_script\n",
        "\n",
        "STORY_SCRIPT = generate_short_story(STORY_SEED)\n"
      ],
      "metadata": {
        "id": "e2dL_Pbcu1rP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3️⃣ Generate Relevant Images with DALL·E 3 (Segmented for Story)"
      ],
      "metadata": {
        "id": "g_MA9URBu3-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ───────────────────────────────────────────────────────────────\n",
        "# 3️⃣ Generate relevant images for story segments using DALL·E 3 (NEW API + GPT prompt shortener)\n",
        "\n",
        "import math\n",
        "from PIL import Image, ImageOps\n",
        "import requests\n",
        "from openai import OpenAI\n",
        "import re\n",
        "\n",
        "def pad_to_vertical(img_path, target_size=(1080, 1920), fill_color=(0,0,0)):\n",
        "    img = Image.open(img_path)\n",
        "    img = ImageOps.contain(img, (target_size[0], target_size[1]), method=Image.LANCZOS)\n",
        "    pad_img = Image.new(\"RGB\", target_size, fill_color)\n",
        "    offset_x = (target_size[0] - img.width) // 2\n",
        "    offset_y = (target_size[1] - img.height) // 2\n",
        "    pad_img.paste(img, (offset_x, offset_y))\n",
        "    pad_img.save(img_path)\n",
        "    return img_path\n",
        "\n",
        "def split_script_for_images(script, num_images=2):\n",
        "    # Split by sentence, but group if short.\n",
        "    sentences = re.split(r'(?<=[.!?]) +', script)\n",
        "    avg = math.ceil(len(sentences) / num_images)\n",
        "    segments = [' '.join(sentences[i:i+avg]) for i in range(0, len(sentences), avg)]\n",
        "    if len(segments) > num_images:\n",
        "        segments = segments[:num_images]\n",
        "    return segments\n",
        "\n",
        "def get_visual_prompt(client, chunk):\n",
        "    \"\"\"Use GPT-4o-mini to generate a short, DALL·E-3-safe prompt.\"\"\"\n",
        "    prompt = (\n",
        "        \"Summarize the following story segment into a short, visually descriptive DALL·E-3 prompt. \"\n",
        "        \"Avoid names, violence, or explicit actions. Focus on the main scene, setting, and mood, under 15 words:\\n\"\n",
        "        f\"{chunk}\"\n",
        "    )\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an expert at generating concise, visual art prompts.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        max_tokens=50,\n",
        "        temperature=0.4,\n",
        "    )\n",
        "    short_prompt = resp.choices[0].message.content.strip()\n",
        "    short_prompt = short_prompt.strip('\"')\n",
        "    return short_prompt\n",
        "\n",
        "def generate_dalle3_images(story_script, num_images=2):\n",
        "    client = OpenAI()\n",
        "    segments = split_script_for_images(story_script, num_images)\n",
        "    image_files = []\n",
        "    for i, segment in enumerate(segments):\n",
        "        visual_prompt = get_visual_prompt(client, segment)\n",
        "        dalle_prompt = f\"Digital art, cinematic style, {visual_prompt}\"\n",
        "        print(f\"🖼️ Prompt for DALL·E image {i+1}: {dalle_prompt}\")\n",
        "        try:\n",
        "            response = client.images.generate(\n",
        "                model=\"dall-e-3\",\n",
        "                prompt=dalle_prompt,\n",
        "                n=1,\n",
        "                size=\"1024x1024\",\n",
        "                quality=\"standard\",\n",
        "                response_format=\"url\"\n",
        "            )\n",
        "            img_url = response.data[0].url\n",
        "            img_data = requests.get(img_url).content\n",
        "            img_path = f\"story_img_{i+1}.png\"\n",
        "            with open(img_path, \"wb\") as f:\n",
        "                f.write(img_data)\n",
        "            pad_to_vertical(img_path)\n",
        "            image_files.append(img_path)\n",
        "            print(f\"Generated image for segment {i+1}: {img_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ DALL·E image generation failed for segment {i+1}: {e}\")\n",
        "            continue  # Optionally: skip or use placeholder\n",
        "    return image_files, segments\n",
        "\n",
        "IMAGE_FILES, STORY_SEGMENTS = generate_dalle3_images(STORY_SCRIPT, num_images=2)\n"
      ],
      "metadata": {
        "id": "StzkMgseu4zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4️⃣ Generate Narration with OpenAI TTS (Echo Voice)"
      ],
      "metadata": {
        "id": "C2DdVPtuu6X1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ───────────────────────────────────────────────────────────────\n",
        "# 4️⃣ Generate TTS narration using OpenAI tts-1 (echo voice, NEW API)\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "def generate_tts_narration(story_script, output_path=\"narration.mp3\"):\n",
        "    client = OpenAI()  # Uses API key from environment\n",
        "    tts_response = client.audio.speech.create(\n",
        "        model=\"tts-1\",\n",
        "        voice=\"echo\",\n",
        "        input=story_script,\n",
        "        response_format=\"mp3\"\n",
        "    )\n",
        "    tts_response.stream_to_file(output_path)\n",
        "    print(f\"Narration audio saved to {output_path}\")\n",
        "    return output_path\n",
        "\n",
        "NARRATION_AUDIO_PATH = generate_tts_narration(STORY_SCRIPT)\n"
      ],
      "metadata": {
        "id": "NbaFuvA0u6xX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5️⃣ Generate Synced Subtitles (GPT for Chunks Matching Narration Timing)"
      ],
      "metadata": {
        "id": "zis51G8Ju-Hs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ───────────────────────────────────────────────────────────────\n",
        "# 5️⃣ Generate subtitle chunks using GPT and sync to narration (NEW API)\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "def chunk_script_for_subtitles(story_script, narration_path, max_words=8):\n",
        "    client = OpenAI()  # Uses your env API key\n",
        "\n",
        "    # First, split script into small chunks using GPT\n",
        "    chunk_prompt = (\n",
        "        \"Split the following story into short, natural subtitle lines, \"\n",
        "        f\"each with no more than {max_words} words. \"\n",
        "        \"Return the result as a Python list of strings.\"\n",
        "    )\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"{chunk_prompt}\\n\\nStory:\\n{story_script}\"}\n",
        "        ],\n",
        "        max_tokens=512,\n",
        "        temperature=0.2,\n",
        "    )\n",
        "    import ast\n",
        "    raw_chunks = response.choices[0].message.content.strip()\n",
        "    try:\n",
        "        subtitle_chunks = ast.literal_eval(raw_chunks)\n",
        "    except Exception:\n",
        "        # fallback: naive split\n",
        "        subtitle_chunks = story_script.split('. ')\n",
        "    print(\"Subtitle chunks generated:\", subtitle_chunks)\n",
        "    # Now, get narration duration and assign times\n",
        "    from mutagen.mp3 import MP3\n",
        "    audio = MP3(narration_path)\n",
        "    total_duration = audio.info.length\n",
        "    per_chunk = total_duration / len(subtitle_chunks)\n",
        "    subtitle_timings = []\n",
        "    for idx, chunk in enumerate(subtitle_chunks):\n",
        "        start = idx * per_chunk\n",
        "        end = start + per_chunk\n",
        "        subtitle_timings.append({\"text\": chunk, \"start\": start, \"end\": end})\n",
        "    return subtitle_timings\n",
        "\n",
        "# Install mutagen for MP3 duration reading if needed\n",
        "!pip install mutagen --quiet\n",
        "\n",
        "SUBTITLES = chunk_script_for_subtitles(STORY_SCRIPT, NARRATION_AUDIO_PATH)\n"
      ],
      "metadata": {
        "id": "ddfDpm_8u-5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6️⃣ Combine All Into Shorts Video (Images + Narration + Subtitles)"
      ],
      "metadata": {
        "id": "V9qTqlW5vAiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ───────────────────────────────────────────────────────────────\n",
        "import sys\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import textwrap\n",
        "\n",
        "# Font path configuration\n",
        "if sys.platform.startswith(\"linux\"):\n",
        "    TEXT_FONT_PATH = \"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\"\n",
        "elif sys.platform.startswith(\"win\"):\n",
        "    TEXT_FONT_PATH = \"C:/Windows/Fonts/arial.ttf\"  # More reliable on Windows\n",
        "else:\n",
        "    TEXT_FONT_PATH = \"DejaVuSans-Bold.ttf\"\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════\n",
        "# 🎨 SUBTITLE CUSTOMIZATION COCKPIT\n",
        "# ═══════════════════════════════════════════════════════════════\n",
        "\n",
        "class SubtitleStyle:\n",
        "    def __init__(self):\n",
        "        # Text styling\n",
        "        self.font_size = 48\n",
        "        self.font_color = (255, 255, 255, 255)  # White\n",
        "        self.stroke_width = 3\n",
        "        self.stroke_color = (0, 0, 0, 255)  # Black outline\n",
        "        self.shadow_offset = (2, 2)\n",
        "        self.shadow_color = (0, 0, 0, 180)\n",
        "\n",
        "        # Background styling\n",
        "        self.bg_enabled = True\n",
        "        self.bg_color = (0, 0, 0, 180)  # Semi-transparent black\n",
        "        self.bg_padding = (20, 12)  # horizontal, vertical padding\n",
        "        self.bg_radius = 15  # rounded corners\n",
        "\n",
        "        # Positioning\n",
        "        self.position = \"bottom\"  # \"top\", \"center\", \"bottom\"\n",
        "        self.margin_bottom = 120\n",
        "        self.margin_top = 120\n",
        "        self.margin_sides = 40\n",
        "\n",
        "        # Animation/Effects\n",
        "        self.highlight_color = (255, 255, 0, 255)  # Yellow highlight\n",
        "        self.enable_word_highlight = True\n",
        "\n",
        "        # Text wrapping\n",
        "        self.max_width = 1000\n",
        "        self.max_chars_per_line = 35\n",
        "        self.line_spacing = 1.2\n",
        "\n",
        "# Create your custom style\n",
        "SUBTITLE_STYLE = SubtitleStyle()\n",
        "\n",
        "# Quick style presets\n",
        "def apply_modern_style(style):\n",
        "    \"\"\"Modern YouTube style with bold text and subtle background\"\"\"\n",
        "    style.font_size = 52\n",
        "    style.font_color = (255, 255, 255, 255)\n",
        "    style.stroke_width = 4\n",
        "    style.stroke_color = (0, 0, 0, 255)\n",
        "    style.bg_enabled = True\n",
        "    style.bg_color = (0, 0, 0, 160)\n",
        "    style.bg_radius = 20\n",
        "    style.margin_bottom = 150\n",
        "\n",
        "def apply_minimal_style(style):\n",
        "    \"\"\"Clean minimal style with just text and outline\"\"\"\n",
        "    style.font_size = 46\n",
        "    style.font_color = (255, 255, 255, 255)\n",
        "    style.stroke_width = 3\n",
        "    style.stroke_color = (0, 0, 0, 255)\n",
        "    style.bg_enabled = False\n",
        "    style.margin_bottom = 100\n",
        "\n",
        "def apply_vibrant_style(style):\n",
        "    \"\"\"Eye-catching style with colored background\"\"\"\n",
        "    style.font_size = 50\n",
        "    style.font_color = (255, 255, 255, 255)\n",
        "    style.stroke_width = 2\n",
        "    style.stroke_color = (0, 0, 0, 255)\n",
        "    style.bg_enabled = True\n",
        "    style.bg_color = (255, 69, 0, 200)  # Orange-red background\n",
        "    style.bg_radius = 25\n",
        "    style.bg_padding = (30, 15)\n",
        "    style.margin_bottom = 140\n",
        "\n",
        "# Apply your preferred style (uncomment one)\n",
        "apply_modern_style(SUBTITLE_STYLE)\n",
        "# apply_minimal_style(SUBTITLE_STYLE)\n",
        "# apply_vibrant_style(SUBTITLE_STYLE)\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════\n",
        "# 🎬 ADVANCED SUBTITLE RENDERER\n",
        "# ═══════════════════════════════════════════════════════════════\n",
        "\n",
        "def create_rounded_rectangle(draw, coords, radius, fill):\n",
        "    \"\"\"Create a rounded rectangle\"\"\"\n",
        "    x1, y1, x2, y2 = coords\n",
        "\n",
        "    # Draw main rectangle\n",
        "    draw.rectangle([x1 + radius, y1, x2 - radius, y2], fill=fill)\n",
        "    draw.rectangle([x1, y1 + radius, x2, y2 - radius], fill=fill)\n",
        "\n",
        "    # Draw corners\n",
        "    draw.pieslice([x1, y1, x1 + 2*radius, y1 + 2*radius], 180, 270, fill=fill)\n",
        "    draw.pieslice([x2 - 2*radius, y1, x2, y1 + 2*radius], 270, 360, fill=fill)\n",
        "    draw.pieslice([x1, y2 - 2*radius, x1 + 2*radius, y2], 90, 180, fill=fill)\n",
        "    draw.pieslice([x2 - 2*radius, y2 - 2*radius, x2, y2], 0, 90, fill=fill)\n",
        "\n",
        "def wrap_text_smart(text, font, max_width, max_chars_per_line):\n",
        "    \"\"\"Smart text wrapping that considers both pixel width and character count\"\"\"\n",
        "    # First wrap by character count\n",
        "    wrapper = textwrap.TextWrapper(width=max_chars_per_line, break_long_words=False)\n",
        "    lines = wrapper.wrap(text)\n",
        "\n",
        "    # Then check if any line exceeds pixel width and re-wrap if needed\n",
        "    final_lines = []\n",
        "    dummy_img = Image.new('RGB', (1, 1))\n",
        "    draw = ImageDraw.Draw(dummy_img)\n",
        "\n",
        "    for line in lines:\n",
        "        bbox = draw.textbbox((0, 0), line, font=font)\n",
        "        line_width = bbox[2] - bbox[0]\n",
        "\n",
        "        if line_width <= max_width:\n",
        "            final_lines.append(line)\n",
        "        else:\n",
        "            # Re-wrap this line with fewer characters\n",
        "            chars = int(len(line) * max_width / line_width * 0.9)  # 90% safety margin\n",
        "            sub_wrapper = textwrap.TextWrapper(width=chars, break_long_words=False)\n",
        "            final_lines.extend(sub_wrapper.wrap(line))\n",
        "\n",
        "    return final_lines\n",
        "\n",
        "def create_modern_subtitle(text, style, canvas_size=(1080, 1920)):\n",
        "    \"\"\"Create a modern subtitle image using PIL\"\"\"\n",
        "    width, height = canvas_size\n",
        "\n",
        "    # Create transparent image\n",
        "    img = Image.new('RGBA', canvas_size, (0, 0, 0, 0))\n",
        "    draw = ImageDraw.Draw(img)\n",
        "\n",
        "    # Load font with fallbacks\n",
        "    font = None\n",
        "    font_paths_to_try = [\n",
        "        TEXT_FONT_PATH,\n",
        "        \"/System/Library/Fonts/Arial.ttf\",  # macOS\n",
        "        \"C:/Windows/Fonts/arial.ttf\",       # Windows\n",
        "        \"/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf\",  # Linux\n",
        "    ]\n",
        "\n",
        "    for font_path in font_paths_to_try:\n",
        "        try:\n",
        "            font = ImageFont.truetype(font_path, style.font_size)\n",
        "            break\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    if font is None:\n",
        "        font = ImageFont.load_default()\n",
        "        print(\"Warning: Using default font for subtitles\")\n",
        "\n",
        "    # Wrap text\n",
        "    lines = wrap_text_smart(text, font, style.max_width, style.max_chars_per_line)\n",
        "    text_content = '\\n'.join(lines)\n",
        "\n",
        "    # Calculate text dimensions\n",
        "    bbox = draw.multiline_textbbox((0, 0), text_content, font=font, spacing=style.font_size * (style.line_spacing - 1))\n",
        "    text_width = bbox[2] - bbox[0]\n",
        "    text_height = bbox[3] - bbox[1]\n",
        "\n",
        "    # Calculate position\n",
        "    if style.position == \"bottom\":\n",
        "        text_y = height - style.margin_bottom - text_height\n",
        "    elif style.position == \"top\":\n",
        "        text_y = style.margin_top\n",
        "    else:  # center\n",
        "        text_y = (height - text_height) // 2\n",
        "\n",
        "    text_x = (width - text_width) // 2\n",
        "\n",
        "    # Draw background if enabled\n",
        "    if style.bg_enabled:\n",
        "        bg_x1 = text_x - style.bg_padding[0]\n",
        "        bg_y1 = text_y - style.bg_padding[1]\n",
        "        bg_x2 = text_x + text_width + style.bg_padding[0]\n",
        "        bg_y2 = text_y + text_height + style.bg_padding[1]\n",
        "\n",
        "        # Ensure background doesn't go outside canvas\n",
        "        bg_x1 = max(style.margin_sides, bg_x1)\n",
        "        bg_x2 = min(width - style.margin_sides, bg_x2)\n",
        "\n",
        "        if style.bg_radius > 0:\n",
        "            create_rounded_rectangle(draw, (bg_x1, bg_y1, bg_x2, bg_y2), style.bg_radius, style.bg_color)\n",
        "        else:\n",
        "            draw.rectangle([bg_x1, bg_y1, bg_x2, bg_y2], fill=style.bg_color)\n",
        "\n",
        "    # Draw shadow if enabled\n",
        "    if style.shadow_offset != (0, 0):\n",
        "        shadow_x = text_x + style.shadow_offset[0]\n",
        "        shadow_y = text_y + style.shadow_offset[1]\n",
        "        draw.multiline_text(\n",
        "            (shadow_x, shadow_y),\n",
        "            text_content,\n",
        "            font=font,\n",
        "            fill=style.shadow_color,\n",
        "            spacing=style.font_size * (style.line_spacing - 1),\n",
        "            align=\"center\"\n",
        "        )\n",
        "\n",
        "    # Draw stroke/outline\n",
        "    if style.stroke_width > 0:\n",
        "        for adj_x in range(-style.stroke_width, style.stroke_width + 1):\n",
        "            for adj_y in range(-style.stroke_width, style.stroke_width + 1):\n",
        "                if adj_x != 0 or adj_y != 0:\n",
        "                    draw.multiline_text(\n",
        "                        (text_x + adj_x, text_y + adj_y),\n",
        "                        text_content,\n",
        "                        font=font,\n",
        "                        fill=style.stroke_color,\n",
        "                        spacing=style.font_size * (style.line_spacing - 1),\n",
        "                        align=\"center\"\n",
        "                    )\n",
        "\n",
        "    # Draw main text\n",
        "    draw.multiline_text(\n",
        "        (text_x, text_y),\n",
        "        text_content,\n",
        "        font=font,\n",
        "        fill=style.font_color,\n",
        "        spacing=style.font_size * (style.line_spacing - 1),\n",
        "        align=\"center\"\n",
        "    )\n",
        "\n",
        "    return img\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════\n",
        "# 🎥 MOVIEPY COMPATIBILITY FUNCTIONS\n",
        "# ═══════════════════════════════════════════════════════════════\n",
        "\n",
        "def _set_duration(clip, duration):\n",
        "    if hasattr(clip, \"with_duration\"): return clip.with_duration(duration)\n",
        "    return clip.set_duration(duration)\n",
        "\n",
        "def _set_audio(clip, audio):\n",
        "    if hasattr(clip, \"with_audio\"): return clip.with_audio(audio)\n",
        "    return clip.set_audio(audio)\n",
        "\n",
        "def _set_position(clip, pos):\n",
        "    if hasattr(clip, \"with_position\"): return clip.with_position(pos)\n",
        "    return clip.set_position(pos)\n",
        "\n",
        "def _set_start(clip, start):\n",
        "    if hasattr(clip, \"with_start\"): return clip.with_start(start)\n",
        "    return clip.set_start(start)\n",
        "\n",
        "def resize_fx(clip, newsize):\n",
        "    if hasattr(clip, \"resized\"):\n",
        "        return clip.resized(newsize)\n",
        "    return clip.resize(newsize)\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════\n",
        "# 🎬 MAIN VIDEO CREATION FUNCTION\n",
        "# ═══════════════════════════════════════════════════════════════\n",
        "\n",
        "from moviepy import ImageClip, CompositeVideoClip, concatenate_videoclips, AudioFileClip\n",
        "\n",
        "def create_shorts_video(image_files, narration_path, subtitles, output_path=\"shorts_final.mp4\", subtitle_style=None):\n",
        "    \"\"\"\n",
        "    Create a YouTube Shorts video with modern subtitles\n",
        "\n",
        "    Args:\n",
        "        image_files: List of image file paths\n",
        "        narration_path: Path to audio narration file\n",
        "        subtitles: List of subtitle dictionaries with 'text', 'start', 'end'\n",
        "        output_path: Output video file path\n",
        "        subtitle_style: SubtitleStyle object for customization\n",
        "    \"\"\"\n",
        "    if subtitle_style is None:\n",
        "        subtitle_style = SUBTITLE_STYLE\n",
        "\n",
        "    print(\"🎬 Creating YouTube Shorts video...\")\n",
        "\n",
        "    # Load audio and calculate timing\n",
        "    audio = AudioFileClip(narration_path)\n",
        "    total_duration = audio.duration\n",
        "    num_images = len(image_files)\n",
        "    img_duration = total_duration / num_images\n",
        "\n",
        "    # Prepare image clips\n",
        "    print(\"📸 Processing images...\")\n",
        "    clips = []\n",
        "    for idx, img in enumerate(image_files):\n",
        "        base_clip = ImageClip(img)\n",
        "        base_clip = resize_fx(base_clip, (1080, 1920))\n",
        "        base_clip = _set_duration(base_clip, img_duration)\n",
        "        base_clip = _set_position(base_clip, 'center')\n",
        "        clips.append(base_clip)\n",
        "\n",
        "    video = concatenate_videoclips(clips, method=\"compose\")\n",
        "    video = _set_audio(video, audio)\n",
        "\n",
        "    # Create subtitle clips with modern styling\n",
        "    print(\"📝 Creating modern subtitles...\")\n",
        "    subtitle_clips = []\n",
        "\n",
        "    for i, sub in enumerate(subtitles):\n",
        "        print(f\"   Creating subtitle {i+1}/{len(subtitles)}: '{sub['text'][:30]}...'\")\n",
        "\n",
        "        # Create subtitle image\n",
        "        subtitle_img = create_modern_subtitle(sub[\"text\"], subtitle_style)\n",
        "        subtitle_array = np.array(subtitle_img)\n",
        "\n",
        "        # Create ImageClip from subtitle\n",
        "        duration = sub[\"end\"] - sub[\"start\"]\n",
        "        subtitle_clip = ImageClip(subtitle_array, duration=duration)\n",
        "        subtitle_clip = _set_start(subtitle_clip, sub[\"start\"])\n",
        "        subtitle_clip = _set_position(subtitle_clip, 'center')\n",
        "\n",
        "        # Add fade in/out effect for smoother transitions\n",
        "        if duration > 0.5:  # Only add fades for longer subtitles\n",
        "            subtitle_clip = subtitle_clip.fadein(0.1).fadeout(0.1)\n",
        "\n",
        "        subtitle_clips.append(subtitle_clip)\n",
        "\n",
        "    # Composite final video\n",
        "    print(\"🎭 Compositing final video...\")\n",
        "    final = CompositeVideoClip([video] + subtitle_clips)\n",
        "\n",
        "    # Export video\n",
        "    print(\"💾 Exporting video...\")\n",
        "    final.write_videofile(\n",
        "        output_path,\n",
        "        fps=24,\n",
        "        codec=\"libx264\",\n",
        "        audio_codec=\"aac\",\n",
        "        temp_audiofile='temp-audio.m4a',\n",
        "        remove_temp=True\n",
        "    )\n",
        "\n",
        "    print(f\"✅ Final shorts video saved to {output_path}\")\n",
        "    return output_path\n",
        "\n",
        "# ═══════════════════════════════════════════════════════════════\n",
        "# 🚀 EXECUTE VIDEO CREATION\n",
        "# ═══════════════════────────────────────────────────────────────\n",
        "\n",
        "# Create the video (make sure your variables are defined)\n",
        "SHORTS_VIDEO_PATH = create_shorts_video(\n",
        "    IMAGE_FILES,\n",
        "    NARRATION_AUDIO_PATH,\n",
        "    SUBTITLES,\n",
        "    subtitle_style=SUBTITLE_STYLE\n",
        ")\n",
        "\n",
        "print(f\"🎉 Your YouTube Shorts video is ready: {SHORTS_VIDEO_PATH}\")"
      ],
      "metadata": {
        "id": "r0sX0Rg7vCOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#@📝 8. Generate Metadata"
      ],
      "metadata": {
        "id": "gQxaYloyApEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 8️⃣ Generate Metadata (Story-based, clickworthy, Shorts-optimized)\n",
        "def parse_metadata_response(text):\n",
        "    title, desc, tags = None, None, []\n",
        "    for line in text.splitlines():\n",
        "        low = line.lower()\n",
        "        if low.startswith(\"title:\"):\n",
        "            title = line.split(\":\",1)[1].strip().strip(' \"\\'')\n",
        "            if title and not title[-1] in ('!', '?', '.'):\n",
        "                title += '!'\n",
        "        if low.startswith(\"description:\"):\n",
        "            desc = line.split(\":\",1)[1].strip()\n",
        "            if desc:\n",
        "                desc = desc[:400]\n",
        "        if low.startswith(\"tags:\"):\n",
        "            tags = [t.strip() for t in line.split(\":\",1)[1].split(\",\")]\n",
        "    required_tags = [\"#shorts\", \"#short\",\"#Shortsviral\", \"fyp\", \"viralshorts\", \"viralnews\", \"globalnews\", \"#trending\", \"#youtubeshorts\"]\n",
        "    tags = [tag for tag in tags if tag]\n",
        "    for req_tag in required_tags:\n",
        "        if req_tag.lower() not in [t.lower() for t in tags]:\n",
        "            tags.append(req_tag)\n",
        "    tags = [tag[:25] for tag in tags if tag]\n",
        "    tags = list(set(tags))[:30]\n",
        "    return title, desc, tags\n",
        "\n",
        "def generate_metadata_from_story(story_text):\n",
        "    prompt = (\n",
        "        f\"You are an expert at viral YouTube Shorts. Given the following short story, create:\\n\"\n",
        "        \"1. A clickworthy, emotional TITLE (<45 chars) based on the most powerful moment, surprise, or twist (NO bland summaries, NO boring names, must create curiosity!)\\n\"\n",
        "        \"2. A DESCRIPTION (<80 words) opening with a main keyword and 2-3 hashtags, includes a call to action (Like/Comment/Share), ends with a question.\\n\"\n",
        "        \"3. 20-30 SEO TAGS (comma-separated), mixing story keywords, emotional triggers, setting, and all required viral tags (#shorts, #youtubeshorts, etc).\\n\"\n",
        "        \"\\nStory:\\n\"\n",
        "        f\"{story_text}\\n\"\n",
        "        \"\\nFormat:\\n\"\n",
        "        \"Title: ...\\nDescription: ...\\nTags: ...\\n\"\n",
        "    )\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\":\"user\",\"content\":prompt}],\n",
        "        temperature=1.1,\n",
        "        max_tokens=400\n",
        "    )\n",
        "    text = resp.choices[0].message.content.strip()\n",
        "    return parse_metadata_response(text)\n",
        "\n",
        "# Example usage (replace STORY_SCRIPT with your actual story variable)\n",
        "title, description, tags = generate_metadata_from_story(STORY_SCRIPT)\n",
        "print(\"📝 Metadata:\\n \", title, \"\\n \", description, \"\\n \", tags)\n"
      ],
      "metadata": {
        "id": "EC2-DOmwApZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "📤 9. Upload to YouTube"
      ],
      "metadata": {
        "id": "Po9hWorbAtHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── 9. Upload to YouTube ───────────────────────────────────────────────\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "from googleapiclient.errors import HttpError\n",
        "import time, os\n",
        "\n",
        "def upload_video_to_youtube(\n",
        "    file_path, title, description, tags,\n",
        "    category_id=22, privacy=\"public\",\n",
        "    chunk_size=1024*1024, max_retries=5\n",
        "):\n",
        "    # Ensure tags is a list (not a comma-separated string)\n",
        "    if isinstance(tags, str):\n",
        "        tags = [t.strip() for t in tags.split(\",\") if t.strip()]\n",
        "\n",
        "    # Enforce Shorts requirements\n",
        "    if not any(t.lower() == \"#shorts\" for t in tags):\n",
        "        tags.append(\"#shorts\")\n",
        "\n",
        "    body = {\n",
        "        \"snippet\": {\n",
        "            \"title\": title,\n",
        "            \"description\": f\"{description}\\n\\n#shorts\",\n",
        "            \"tags\": tags,\n",
        "            \"categoryId\": str(category_id)\n",
        "        },\n",
        "        \"status\": {\n",
        "            \"privacyStatus\": privacy,\n",
        "            \"selfDeclaredMadeForKids\": False\n",
        "        }\n",
        "        # YouTube ignores contentDetails.duration in upload, but safe to keep.\n",
        "    }\n",
        "\n",
        "    media = MediaFileUpload(\n",
        "        file_path,\n",
        "        mimetype='video/mp4',\n",
        "        chunksize=chunk_size,\n",
        "        resumable=True\n",
        "    )\n",
        "\n",
        "    req = youtube.videos().insert(\n",
        "        part=\"snippet,status\",\n",
        "        body=body,\n",
        "        media_body=media\n",
        "    )\n",
        "\n",
        "    done = False\n",
        "    retry = 0\n",
        "    while not done:\n",
        "        try:\n",
        "            status, resp = req.next_chunk()\n",
        "            if status:\n",
        "                print(f\"🟢 {int(status.progress()*100)}% uploaded\")\n",
        "            else:\n",
        "                done = True\n",
        "        except HttpError as e:\n",
        "            if e.resp.status in [500,502,503,504] and retry < max_retries:\n",
        "                retry += 1\n",
        "                time.sleep(2**retry)\n",
        "                print(f\"⚠️ Retry {retry}\")\n",
        "            else:\n",
        "                raise\n",
        "\n",
        "    print(\"✅ Upload complete! Video ID:\", resp['id'])\n",
        "    return resp\n",
        "\n",
        "# Usage with new metadata:\n",
        "response = upload_video_to_youtube(\"shorts_final.mp4\", title, description, tags)\n",
        "print(\"🎉 Done! https://youtu.be/\" + response[\"id\"])\n"
      ],
      "metadata": {
        "id": "6Oy8j6CEAtcp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}